---
title: "Diagnosing diseases using KNN- Spring 2025"
subtitle: "An application of KNN to diagnose disease"
author: "Jacqueline Razo (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!
:::

## Introduction

- Week 2: 
- Summary of research paper: DIABETES CLASSIFICATION BASED ON KNN

This paper discusses the use of different types of KNN in order to classify diabetes. It does this by using matlab and six different types of KNN algorithms to classify glucose concentrations in the blood. The paper starts of with an explanation of how KNN algorithms work by using the Euclidean distance between the different classes. The KNN algorithm takes the closes N number of neighbors and assigns the class based on the nearest neighbors. Out of the six algorithms that were used the fine KNN was the one that was the most successful at correctly classifying the data. [@ali2020diabetes]

- Summary of research paper: Efficient kNN Classification With Different
Numbers of Nearest Neighbors

This paper proposes two more efficient KNN methods called the kTree and the k*Tree methods. The authors propose using a training stage using a decision tree to select the ideal number of K values to make the KNN more efficient. The authors found their method did reduce running cost and increased classification accuracy. [@zhang2017efficient]

Week 3: 

Summary of research paper: Diagnosis of Diabetes Mellitus using K Nearest Neighbor Algorithm

The goal of this paper is to diagnose diabetes mellitus using KNN. This paper describes what diabetes mellitus is and the health problems it causes in individuals. This paper is important because it can lead doctors to use better detection tools to detect diabetes mellitus. This paper describes the way the KNN algorithm works in order to detect diabetes mellitus. The algorithm is described as taking a sample dataset with input variables and one output variable, taking a test dataset from the sample, finding the distance between each dataset in the training sample with the euclidean formula, then deciding the random variable of k where k is the number of nearest neighbors you will use to classify. Then it does the same thing to the test dataset and uses the K nearest members to find the output variable. After the classification, the authors go into detail of how they analyzed the results based on specificity. Finally, the paper describes the way they used mathlab to check for the accuracy of their results. The accuracy for a K of 3 was 70% and the accuracy for a K of 5 was 75%.  [@saxena2014diagnosis]

Summary of research paper: Efficient kNN classification algorithm for big data


The goal of this paper is to be able to use KNN in big data. This paper proposes using a k-means clustering technique to separate big data dataset into several parts to make the KNN more efficient. The reason this paper is important is because KNN traditionally work by measuring the euclidean distance between different datasets to see what the nearest k neighbors are and this can be computationally expensive with big datasets. The authors proposal would lead to a more efficient method of using knn. The authors concluded the LC-KNN worked the best because it had the highest accuracy and best time.[@deng2016efficient]


Week 4: 

A Review of Data Classification Using K-Nearest Neighbour Algorithm

This paper focused on comparing different distances in classification algorithms with a focus on the KNN algorithm. It explains the methodology used in KNN. It states the KNN algorithm uses the nearest k-neighbors in order to classify data points. The paper states KNN uses the euclidean distance by default and it compares its performance using cityblock, cosine and correlation distances. In the end it found the euclidean distance was more efficient than the others. [@kataria2013review]

Introduction to machine learning: k-nearest neighbors

The author of this paper gave the reader an introduction into how KNN works and how to run it in R studio. He describes the methodology as assigning an unlabeled observation to a class by using labeled examples that are similar to it. It also describes the euclidean distance equation and offers alternatives to it like the Manhattan distance. The author also describes the impact the k has on the algorithm. It recommends setting the k equal to the square root of the number of observations in the training dataset. [@zhang2016introduction]

The introduction should:


-   Develop a storyline that captures attention and maintains interest.

-   Your audience is your peers

-   Clearly state the problem or question you're addressing.

<!-- -->

-   Introduce why it is relevant needs.

-   Provide an overview of your approach.

Example of writing including citing references:

*This is an introduction to ..... regression, which is a non-parametric
estimator that estimates the conditional expectation of two variables
which is random. The goal of a kernel regression is to discover the
non-linear relationship between two random variables. To discover the
non-linear relationship, kernel estimator or kernel smoothing is the
main method to estimate the curve for non-parametric statistics. In
kernel estimator, weight function is known as kernel function
[@efr2008]. Cite this paper [@bro2014principal]. The GEE [@wang2014].
The PCA [@daffertshofer2004pca]*. Topology can be used in machine learning [@adams2021topology]

*This is my work and I want to add more work...*

## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*


*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
