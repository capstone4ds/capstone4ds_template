---
title: "Online Payment Fraud Detection using Machine Learning"
author: "Rahul Reddy"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Methods

## Experimental Design and Analytical Procedures

## Data Understanding and Preprocessing

First is the data assessment whereby, the details of the project dataset
are studied and analyzed. The first step is to get our raw data in the
form of using libraries specifically with python such as pandas where we
write down the data that we are reading and we are able to identify all
the relevant columns as the_geom work, transaction type, specific
amount, subsequent balance, and fraudulent transactions. This enables to
verify that all the fields have the correct data type, as well as the
structure of the dataset that is going to follow the past analyses.

We always do an exploratory data analysis, afterwards, in order to give
an overview of the analyzed dataset after data ingestion. It also scales
the transaction value, balance in accounts, and yes or no analysis
(categorical data type). By doing this, we necessarily discover the
trends which would alter model performance as transaction fraud is so
rare compared to normal ones.

Also, last but not least with data quality, cleaning and feature
engineering are also done. Any errors from this stage are corrected,
including omission, even errors in the values and any logical checks
such as the balances at the end of these changes agree with the amounts
in the transaction. On the other, we introduce new variables accounting
for important features of the transaction such as the difference between
the old and new balance as well as temporal trends derived from the
‘step’ variable. What it does is making an assurance that the other
modeling exercises are carried out using a well prearranged dataset of
the intended one.

## Model Development

In this phase we select and create suitable ML models aligned with what
can help us to clear that fraud issue (as we are detecting frauds). We
start out by looking into a selection of candidate models. In the next,
we first have such a simple model as logistic regression which we can
use as a baseline that then to see how good we are at first performance.
For this reason, we further explore more complex forms of this kind
(e.g. decision trees, random forests, and gradient boosting algorithms
(e.g. XGBoost) that can model the non-linear relationships present in
the transactional data. These models are particularly good for dealing
with imbalanced data problem due to their nature of fraud detection in
which the small part of the training set contains fraudulent cases.

Additionally, we also use robust models training to also make sure that
our models generalize as well to unseen data and to the model selection
itself. To combat with complete bagging, we employ k fold cross
validation which splits the dataset in k partitions and in each step one
of the k transactions is used for training and validation. It reduces
overfitting and the measure is also more precise. Finally, we also
investigate whether time based splits can contribute further by ensuring
there are temporal trends that are vital in fighting against fraud.

Moreover, it is also necessary to carry Hyper parameter tuning for
better model performance. Then we systematically explore many different
parameter settings with methods like grid search, random search or
Bayesian optimization. Ensemble methods are a good example of such an
case: for example, if we are tuning the number of trees, their depth,
learning rate, etc. In logistic regression we now adjust the
regularization parameters such that we may balance between bias and
variance.Indeed, such adjustments are necessary to improve the model’s
ability to tell fraudulent from legitimate transactions.

The last thing we do on the model development process is to analyze
feature importance. To begin to investigate which features (transaction
amount, change in account balances or transaction types) are best at
predicting fraud, we look at. By looking at this, we will be able review
the patterns of fraudulent behavior and look for some to better
anticipate them in the future. Not only does it facilitate modifying the
model, it has a scope to the stakeholder to incorporate critical factors
related to the fraud detection mechanism.

## Model evaluation and validation

Given this, we then develop the model in an attempt to measure its
performance by means of a thorough set of metrics known to be relevant
in similar settings. Since the dataset is inherently unbalanced
(fraudulent transactions are much less common than non fraudulent
transactions) we give much importance to precision, recall and F1 score.
Precision means that if a transaction gets flagged as a fraud, it is
actually a fraud, which means that the inconvenience for real customers
will be limited. On the other hand, measures your model’s capability of
representing as much fraudulent cases as possible. The F1 score unifies
precision and recall to provide balance on the model performance.
Furthermore, we assess the model’s ability to discriminate this trait
based on the AUC calculated for the trade off between the true and false
positive rates at various threshold settings.

In order to validate the generalizability and robustness of the model,
we apply k fold cross validation. It is a method that splits the dataset
into n partitions (or folds) and trains the model successively using it
acrossibilities where each partition will act as a validation set at
least once. Compared to such approaches, this one not only mitigates
overfitting, but also gives us the assurance of a solid performance
estimate on data unseen. Threshold tuning is carried out beyond cross
validation to optimize the balance between capturing the fraudulent
activities and minimizing false alarms. As a way to tell that our
observed improvements are really statistically meaningful, we also
perform significance testing (e.g., McNemar’s test) and generate
confidence intervals of key performance metrics. Together these steps
make sure that the model is adequate and dependable as a practical foul
defence in those real world fraud detection situations.

## Software tools

Programming Language: Python

Libraries and Frameworks:

Data Manipulation: pandas, NumPy Machine Learning and Modeling:
scikit-learn, XGBoost, TensorFlow (or PyTorch for deep learning
applications)

Visualization: matplotlib, seaborn

Development Environment: VS Code

Computational Resources:Utilize cloud platforms such as AWS or Google
Cloud if large-scale data processing or training on complex models
(e.g., neural networks) is required.

## Ethical consideration

With financial data it is imperative the project was GDPR compliant (and
100% privacy and security was enforced) because this project has ethical
considerations more than ever. Anonymization of personal identifiers is
made to to protect individual’s privacy and in line with data protection
law such as GDPR. Then, storage of the data in a secure way and only
accessing it on control in another way gives out another layer of
prevention of information leakage or breach that is unauthorized. Apart
from that, we look out for any of these biases in our model to make sure
we aren’t justifying treating any user group unfairly in our model, as
we try to strike the right balance between not allowing fraudulent
transactions to slip through while not flag certain legitimate
transactions. In this respect, we remain transparent in the way we go
about our work by writing about our methodologies, assumptions and
limitations so it’s clear what our stakeholders need to be aware of, and
that the decisions made by the model are open to audit and trust.
