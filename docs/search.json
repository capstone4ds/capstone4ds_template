[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "",
    "text": "Slides: slides.html ( Go to slides.qmd to edit)"
  },
  {
    "objectID": "index.html#aims",
    "href": "index.html#aims",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Aims",
    "text": "Aims\nThe present study aims performs Bayesian logistic regression to predict diabetes status and evaluate the associations between diabetes and predictors (body mass index (BMI), age (≥20 years), gender, and race). The study anakyzes a retrospective dataset (2013–2014 NHANES survey data). It is based on a complex sampling design, characterized by stratification, clustering, and oversampling of specific population subgroups, rather than uniform random sampling. A Bayesian analytical approach addresses challenges posed by dataset anomalies such as missing data, complete case analysis, and separation that limit the efficiency and reliability of traditional logistic regression in predicting health outcomes."
  },
  {
    "objectID": "index.html#logical-flow-for-analysis",
    "href": "index.html#logical-flow-for-analysis",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Logical Flow for Analysis",
    "text": "Logical Flow for Analysis\n\nData Preparation Preparation and analysis of the observed or imputed dataset (e.g., adult_imp1.csv) to handle missing values and ensure completeness. (2)Train-Test Split Splitting the dataset into training (to fit the model) and testing (to evaluate model performance) sets to ensures the model is generalizable and avoids overfitting.\nFrequentist Approach Fit classical regression or machine learning models on complete dataset to obtain point estimates (e.g., coefficients, odds ratios) and confidence intervals.\nBayesian Approach Fit a Bayesian model using on the imputed dataset to obtain posterior distributions (posterior draws) for parameters to quantify uncertainty. Use posterior draws to generate posterior predictive distributions on the complete data set.\nTargeted Intervention Analysis Compare the two models Use of Bayesian models to simulate or assess interventions Identify modifiable risk factors (e.g., BMI, lifestyle factors). Predict how change in a risk factor affects outcomes (e.g., diabetes risk). Bayesian analysis to quantify uncertainty in intervention effects using posterior predictive distributions.\nInference & Decision-Making Combining insights from both approaches to guide data-driven decisions or public health recommendations. Frequentist results provide point estimates, while Bayesian results provide full uncertainty quantification."
  },
  {
    "objectID": "index.html#statistical-tool",
    "href": "index.html#statistical-tool",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Statistical Tool",
    "text": "Statistical Tool\n-R packages and libraries are used to import data, perform data wrangling and analysis."
  },
  {
    "objectID": "index.html#data-pre-processing-and-cleaning",
    "href": "index.html#data-pre-processing-and-cleaning",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Data pre-processing and cleaning",
    "text": "Data pre-processing and cleaning\n\nThree datasets: demographics, exam, questionnaire in.XPT format files are imported (Haven package) in R. After selecting variables of interest, a merged dataset is created from the original weighted datasets (demographics, exam, questionnaire) and merged using ID to create a single merged dataframe.\n\n\nResponse Variable: Binary\n\n\nType 2 / diagnosed diabetes(excluding gestational diabetes) -“Doctor told you have diabetes?” DIQ010 combined with DIQ050 a secondary variable describing treatment status (insulin use) to exclude those cases\n\n\nPredictor Variables\n\n\nBody Mass Index, factor, 4 levels are analyzed after standardization).\no Underweight (&lt;5th percentile)\no Normal (5th–&lt;85th)\no Overweight (85th–&lt;95th) o Obese (≥95th percentile)\no Missing We kept it as it is as categorization provides clinically interpretable groups\n\n\nCovariates:\n\nGender (factor, 2 levels): Male: Female\nEthnicity (factor, 5 levels): Mexican American, Non-Hispanic, White Non-Hispanic, Black Other Hispanic, Other Race - Including multi-racial\nAge (number, continuous)\n\n\nMerged dataset is cleaned and exploratory data analysis conducted to report results and visualizations for 10175 observations and 10 variables where - - race categorized in 5 levels - age range (0-80 years) - gender (male and female) - Diabetes grouped from (DIQ010 and DIQ050) BMI as continuous.\n\n\nCode\n# weighted means of each variable                       \nstr(merged_data)\n\n\n'data.frame':   10175 obs. of  10 variables:\n $ SEQN    : num  73557 73558 73559 73560 73561 ...\n $ RIDAGEYR: num  69 54 72 9 73 56 0 61 42 56 ...\n $ RIAGENDR: Factor w/ 2 levels \"Male\",\"Female\": 1 1 1 1 2 1 1 2 1 2 ...\n $ RIDRETH1: Factor w/ 5 levels \"Mexican American\",..: 4 3 3 3 3 1 3 3 2 3 ...\n $ SDMVPSU : num  1 1 1 2 2 1 1 1 2 1 ...\n $ SDMVSTRA: num  112 108 109 109 116 111 105 114 106 112 ...\n $ WTMEC2YR: num  13481 24472 57193 55767 65542 ...\n $ BMXBMI  : num  26.7 28.6 28.9 17.1 19.7 41.7 NA 35.7 NA 26.5 ...\n $ DIQ010  : Factor w/ 5 levels \"Yes\",\"No\",\"Borderline\",..: 1 1 1 2 2 2 NA 2 2 2 ...\n $ DIQ050  : Factor w/ 4 levels \"Yes\",\"No\",\"Refused\",..: 1 1 1 2 2 2 NA 2 2 2 ...\n\n\nCode\nplot_str(merged_data)\nhead(merged_data)\n\n\n   SEQN RIDAGEYR RIAGENDR           RIDRETH1 SDMVPSU SDMVSTRA WTMEC2YR BMXBMI\n1 73557       69     Male Non-Hispanic Black       1      112 13481.04   26.7\n2 73558       54     Male Non-Hispanic White       1      108 24471.77   28.6\n3 73559       72     Male Non-Hispanic White       1      109 57193.29   28.9\n4 73560        9     Male Non-Hispanic White       2      109 55766.51   17.1\n5 73561       73   Female Non-Hispanic White       2      116 65541.87   19.7\n6 73562       56     Male   Mexican American       1      111 25344.99   41.7\n  DIQ010 DIQ050\n1    Yes    Yes\n2    Yes    Yes\n3    Yes    Yes\n4     No     No\n5     No     No\n6     No     No\n\n\nCode\nsummary(merged_data)\n\n\n      SEQN          RIDAGEYR       RIAGENDR   \n Min.   :73557   Min.   : 0.00   Male  :5003  \n 1st Qu.:76100   1st Qu.:10.00   Female:5172  \n Median :78644   Median :26.00                \n Mean   :78644   Mean   :31.48                \n 3rd Qu.:81188   3rd Qu.:52.00                \n Max.   :83731   Max.   :80.00                \n                                              \n                                RIDRETH1       SDMVPSU         SDMVSTRA    \n Mexican American                   :1730   Min.   :1.000   Min.   :104.0  \n Other Hispanic                     : 960   1st Qu.:1.000   1st Qu.:107.0  \n Non-Hispanic White                 :3674   Median :1.000   Median :111.0  \n Non-Hispanic Black                 :2267   Mean   :1.484   Mean   :110.9  \n Other Race - Including Multi-Racial:1544   3rd Qu.:2.000   3rd Qu.:115.0  \n                                            Max.   :2.000   Max.   :118.0  \n                                                                           \n    WTMEC2YR          BMXBMI             DIQ010            DIQ050    \n Min.   :     0   Min.   :12.10   Yes       : 737   Yes       : 220  \n 1st Qu.: 12562   1st Qu.:19.70   No        :8841   No        :9545  \n Median : 20175   Median :24.70   Borderline: 185   Refused   :   1  \n Mean   : 30585   Mean   :25.68   Refused   :   1   Don't know:   2  \n 3rd Qu.: 36748   3rd Qu.:30.20   Don't know:   5   NA's      : 407  \n Max.   :171395   Max.   :82.90   NA's      : 406                    \n                  NA's   :1120                                       \n\n\nCode\nlibrary(dplyr)\nlibrary(knitr)\n\nplot_intro(merged_data, title=\"Figure 1 (Merged dataset). Structure of variables and missing observations.\")\n\n\n\n\n\n\n\n\n\nCode\nplot_missing(merged_data, title=\"Figure 2(Merged dataset). Breakdown of missing observations.\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# print(glimpse(merged_data))\nprint(table(merged_data$BMXBMI, useNA = \"ifany\"))\n\n\n\n12.1 12.3 12.6 12.7 12.9   13 13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9   14 \n   1    1    3    1    7    3    4    5    6   12   14    6   10    9    8   19 \n14.1 14.2 14.3 14.4 14.5 14.6 14.7 14.8 14.9   15 15.1 15.2 15.3 15.4 15.5 15.6 \n  15   21   33   34   34   26   32   34   30   38   26   50   56   40   49   37 \n15.7 15.8 15.9   16 16.1 16.2 16.3 16.4 16.5 16.6 16.7 16.8 16.9   17 17.1 17.2 \n  42   41   57   49   57   46   46   43   35   57   41   43   47   36   49   45 \n17.3 17.4 17.5 17.6 17.7 17.8 17.9   18 18.1 18.2 18.3 18.4 18.5 18.6 18.7 18.8 \n  40   37   41   37   42   29   32   27   30   38   22   34   30   45   32   38 \n18.9   19 19.1 19.2 19.3 19.4 19.5 19.6 19.7 19.8 19.9   20 20.1 20.2 20.3 20.4 \n  28   32   33   40   44   27   37   37   46   39   39   39   42   40   48   42 \n20.5 20.6 20.7 20.8 20.9   21 21.1 21.2 21.3 21.4 21.5 21.6 21.7 21.8 21.9   22 \n  38   39   47   29   48   29   50   50   58   37   55   36   46   38   43   45 \n22.1 22.2 22.3 22.4 22.5 22.6 22.7 22.8 22.9   23 23.1 23.2 23.3 23.4 23.5 23.6 \n  38   33   48   46   59   44   50   51   54   47   29   48   42   50   44   42 \n23.7 23.8 23.9   24 24.1 24.2 24.3 24.4 24.5 24.6 24.7 24.8 24.9   25 25.1 25.2 \n  62   55   64   48   35   50   44   50   48   51   45   39   40   39   44   38 \n25.3 25.4 25.5 25.6 25.7 25.8 25.9   26 26.1 26.2 26.3 26.4 26.5 26.6 26.7 26.8 \n  34   54   41   47   37   55   52   37   58   47   44   50   38   49   38   49 \n26.9   27 27.1 27.2 27.3 27.4 27.5 27.6 27.7 27.8 27.9   28 28.1 28.2 28.3 28.4 \n  44   46   57   42   57   50   43   48   36   37   45   53   41   47   46   35 \n28.5 28.6 28.7 28.8 28.9   29 29.1 29.2 29.3 29.4 29.5 29.6 29.7 29.8 29.9   30 \n  49   53   35   24   41   35   39   35   27   34   26   28   22   39   34   35 \n30.1 30.2 30.3 30.4 30.5 30.6 30.7 30.8 30.9   31 31.1 31.2 31.3 31.4 31.5 31.6 \n  31   39   24   48   39   32   37   31   21   27   41   44   29   28   31   24 \n31.7 31.8 31.9   32 32.1 32.2 32.3 32.4 32.5 32.6 32.7 32.8 32.9   33 33.1 33.2 \n  31   27   32   29   17   31   24   31   25   25   20   30   19   20   28   19 \n33.3 33.4 33.5 33.6 33.7 33.8 33.9   34 34.1 34.2 34.3 34.4 34.5 34.6 34.7 34.8 \n  25   23   19   22   27   20   13   27   15   20   13   13   20   15   19   15 \n34.9   35 35.1 35.2 35.3 35.4 35.5 35.6 35.7 35.8 35.9   36 36.1 36.2 36.3 36.4 \n  15   18   17   11   23   14   17   17   15   17   14   17   22   14   11   18 \n36.5 36.6 36.7 36.8 36.9   37 37.1 37.2 37.3 37.4 37.5 37.6 37.7 37.8 37.9   38 \n  18    5    8   14   16    7   13   19   12   14   12    8    8    9    6    9 \n38.1 38.2 38.3 38.4 38.5 38.6 38.7 38.8 38.9   39 39.1 39.2 39.3 39.4 39.5 39.6 \n  11    7    5   13   10   11   13   12   10    7    6    7    8   12    7    4 \n39.7 39.8 39.9   40 40.1 40.2 40.3 40.4 40.5 40.6 40.7 40.8 40.9   41 41.1 41.2 \n   6   10    9    5    4    5    5   10    9    6    8    4    4    3    6    5 \n41.3 41.4 41.5 41.6 41.7 41.8 41.9   42 42.1 42.2 42.3 42.4 42.5 42.6 42.7 42.8 \n  10   10    8    5    6    3    6    7    8    6    5    7    5    5    4    6 \n42.9   43 43.1 43.2 43.3 43.4 43.5 43.6 43.7 43.8 43.9   44 44.1 44.2 44.3 44.4 \n   3    3    9    7    8    5    2    3    6    4    1    3    4    4    1    4 \n44.5 44.6 44.7 44.8 44.9   45 45.1 45.2 45.3 45.4 45.5 45.6 45.7 45.8 45.9   46 \n   7    4    1    4    6    1    5    4    4    2    4    1    3    4    6    1 \n46.1 46.2 46.3 46.4 46.6 46.7 46.8 46.9 47.1 47.2 47.3 47.4 47.5 47.6 47.7 47.8 \n   3    4    1    4    1    1    1    1    4    4    4    2    2    2    2    1 \n47.9   48 48.1 48.2 48.3 48.4 48.5 48.6 48.7 48.8 48.9   49 49.1 49.2 49.3 49.4 \n   1    1    2    1    2    2    1    1    1    1    2    2    1    2    1    6 \n49.5 49.6 49.9   50 50.1 50.2 50.3 50.4 50.5 50.6 50.7 50.8 50.9   51 51.1 51.2 \n   2    2    2    2    2    4    2    1    4    2    3    2    2    1    1    2 \n51.3 51.4 51.5 51.6 51.8 51.9   52 52.2 52.3 52.4 52.6 52.7   53 53.3 53.5 53.6 \n   3    1    1    1    1    5    1    1    1    2    2    1    1    1    1    1 \n53.9   54 54.2 54.3 54.9   55 55.1 55.3 55.6 55.7 56.3 56.4 56.5 56.7 56.9 57.3 \n   2    2    2    1    1    2    1    1    1    1    1    1    1    1    2    1 \n57.4 57.8 57.9 58.3 58.4 58.6 58.7 58.9 60.9 62.2   63 63.3 64.2 64.3 64.7 65.5 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n67.5 67.9 68.6 70.1 71.5 74.1 77.5 82.9 &lt;NA&gt; \n   1    1    1    1    1    1    1    1 1120 \n\n\nCode\nprint(table(merged_data$DIQ010,  useNA = \"ifany\"))\n\n\n\n       Yes         No Borderline    Refused Don't know       &lt;NA&gt; \n       737       8841        185          1          5        406 \n\n\nCode\n #  ---- Coercion helpers (handle labelled/character) ----\nto_num &lt;- function(x) {\n  if (is.numeric(x)) return(x)\n  xc &lt;- as.character(x)\n  n &lt;- suppressWarnings(readr::parse_number(xc))\n  if (mean(is.na(n)) &gt; 0.80) {\n    xlow &lt;- tolower(trimws(xc))\n    n &lt;- dplyr::case_when(\n      xlow %in% c(\"1\",\"yes\",\"yes, told\") ~ 1,\n      xlow %in% c(\"2\",\"no\",\"no, not told\") ~ 2,\n      xlow %in% c(\"3\",\"borderline\") ~ 3,\n      xlow %in% c(\"7\",\"refused\") ~ 7,\n      xlow %in% c(\"9\",\"don't know\",\"dont know\",\"unknown\") ~ 9,\n      TRUE ~ NA_real_\n    )\n  }\n  as.numeric(n)\n}\n\nmerged_data &lt;- merged_data %&gt;%\n  mutate(\n    DIQ010   = to_num(DIQ010),\n    DIQ050   = to_num(if (!\"DIQ050\" %in% names(.)) NA_real_ else DIQ050),\n    BMXBMI   = suppressWarnings(as.numeric(BMXBMI)),\n    RIDAGEYR = suppressWarnings(as.numeric(RIDAGEYR)),\n    RIAGENDR = suppressWarnings(as.numeric(RIAGENDR)),\n    RIDRETH1 = suppressWarnings(as.numeric(RIDRETH1)),\n    SDMVPSU  = suppressWarnings(as.numeric(SDMVPSU)),\n    SDMVSTRA = suppressWarnings(as.numeric(SDMVSTRA)),\n    WTMEC2YR = suppressWarnings(as.numeric(WTMEC2YR))\n  )\n\n# ---- Diagnostics BEFORE save ----\ncat(\"DIQ010 counts BEFORE save:\\n\")\n\n\nDIQ010 counts BEFORE save:\n\n\nCode\nprint(table(merged_data$DIQ010, useNA = \"ifany\"))\n\n\n\n   1    2    3    7    9 &lt;NA&gt; \n 737 8841  185    1    5  406 \n\n\nCode\ncat(\"Count with DIQ010 in {1,2}:\", sum(merged_data$DIQ010 %in% c(1,2), na.rm = TRUE), \"\\n\")\n\n\nCount with DIQ010 in {1,2}: 9578 \n\n\nCode\n# ---- Save to file for reuse ----\ndir.create(\"data\", showWarnings = FALSE)\n# ---- Save ----\ndir.create(\"data\", showWarnings = FALSE, recursive = TRUE)\nsaveRDS(merged_data, \"data/merged_2013_2014.rds\")\nmessage(\"Saved: data/merged_2013_2014.rds\")"
  },
  {
    "objectID": "index.html#exploratory-data-analysis",
    "href": "index.html#exploratory-data-analysis",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nUsing library(survey) we calculated weighted means and sd of all the variables. The BMI and age were standardized.\nAge categorized was recoded into different variables, to create age range (20-80 years) &gt;20 years\nBMI is recoded and categorized as-“18.5,18.5–&lt;25,25–&lt;30,30–&lt;35,35–&lt;40,≥40 years).\nEthnicity is recoded as “Mexican American” = “1”, “Other Hispanic” = “2”, “NH White” = “3”, “NH Black” = “4”, “Other/Multi” = “5”\nSince special codes are not random, cannot be dropped; the informative missingness if ignored (MAR or MNAR) could introduce bias.\n\nWe transformed special codes (3,7,) to NA and included all NAs in the analysis. Visualization of missing data is presented below.\nA final analytic dataset created (‘adult’) with “NH White” and “Male” as the reference group for analysis\n\n\nCode\n## \n# ---------------- Basic Exploration (adults) ----------------\n\n# Keep adults only and build analysis variables\nadult &lt;- merged_data %&gt;%\n  dplyr::filter(RIDAGEYR &gt;= 20) %&gt;%\n  dplyr::transmute(\n    # --- keep survey design variables so svydesign() can see them ---\n    SDMVPSU, SDMVSTRA, WTMEC2YR,\n\n    # --- outcome: DIQ010 (1 yes, 2 no; 3/7/9 -&gt; NA) ---\n    diabetes_dx = dplyr::case_when(\n      DIQ010 == 1 ~ 1,\n      DIQ010 == 2 ~ 0,\n      DIQ010 %in% c(3, 7, 9) ~ NA_real_,\n      TRUE ~ NA_real_\n    ),\n\n    # --- predictors (raw) ---\n    bmi  = BMXBMI,\n    age  = RIDAGEYR,\n\n    # sex (1=Male, 2=Female)\n    sex  = forcats::fct_recode(factor(RIAGENDR), Male = \"1\", Female = \"2\"),\n\n    # race (5-level)\n    race = forcats::fct_recode(\n      factor(RIDRETH1),\n      \"Mexican American\" = \"1\",\n      \"Other Hispanic\"   = \"2\",\n      \"NH White\"         = \"3\",\n      \"NH Black\"         = \"4\",\n      \"Other/Multi\"      = \"5\"\n    ),\n\n    # keep DIQ050 so we can safely reference it (may be absent/NA in some rows)\n    \n    DIQ050 = DIQ050\n  ) %&gt;%\n  # standardize continuous predictors\n  dplyr::mutate(\n    age_c = as.numeric(scale(age)),\n    bmi_c = as.numeric(scale(bmi)),\n    bmi_cat = cut(\n      bmi,\n      breaks = c(-Inf, 18.5, 25, 30, 35, 40, Inf),\n      labels = c(\"&lt;18.5\",\"18.5–&lt;25\",\"25–&lt;30\",\"30–&lt;35\",\"35–&lt;40\",\"≥40\"),\n      right = FALSE\n    )\n  ) %&gt;%\n  # adjust outcome: if female & DIQ050==1 (\"only when pregnant\"), set to 0 (not diabetes)\n  dplyr::mutate(\n    diabetes_dx = ifelse(sex == \"Female\" & !is.na(DIQ050) & DIQ050 == 1, 0, diabetes_dx)\n  )\n\n# Make NH White the reference level for race (clearer interpretation)\nadult &lt;- adult %&gt;%\n  dplyr::mutate(\n    race = forcats::fct_relevel(race, \"NH White\")\n  )\n\n# --- sanity checks ---\ncat(\"Adults n =\", nrow(adult), \"\\n\")\n\n\nAdults n = 5769 \n\n\nCode\nglimpse(adult)\n\n\nRows: 5,769\nColumns: 12\n$ SDMVPSU     &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ SDMVSTRA    &lt;dbl&gt; 112, 108, 109, 116, 111, 114, 106, 112, 112, 113, 116, 114…\n$ WTMEC2YR    &lt;dbl&gt; 13481.04, 24471.77, 57193.29, 65541.87, 25344.99, 61758.65…\n$ diabetes_dx &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ bmi         &lt;dbl&gt; 26.7, 28.6, 28.9, 19.7, 41.7, 35.7, NA, 26.5, 22.0, 20.3, …\n$ age         &lt;dbl&gt; 69, 54, 72, 73, 56, 61, 42, 56, 65, 26, 76, 33, 32, 38, 50…\n$ sex         &lt;fct&gt; Male, Male, Male, Female, Male, Female, Male, Female, Male…\n$ race        &lt;fct&gt; NH Black, NH White, NH White, NH White, Mexican American, …\n$ DIQ050      &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ age_c       &lt;dbl&gt; 1.13241831, 0.27835981, 1.30323001, 1.36016725, 0.39223428…\n$ bmi_c       &lt;dbl&gt; -0.33588609, -0.07028101, -0.02834336, -1.31443114, 1.7609…\n$ bmi_cat     &lt;fct&gt; 25–&lt;30, 25–&lt;30, 25–&lt;30, 18.5–&lt;25, ≥40, 35–&lt;40, NA, 25–&lt;30,…"
  },
  {
    "objectID": "index.html#exploratory-description-and-visualization-of-adult-dataset-20",
    "href": "index.html#exploratory-description-and-visualization-of-adult-dataset-20",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Exploratory Description and Visualization of Adult dataset (> 20",
    "text": "Exploratory Description and Visualization of Adult dataset (&gt; 20\nyears)**\nObservations - 5769 observations Survey design: SDMVPSU, SDMVSTRA, WTMEC2YR Outcome: diabetes_dx (numeric 0/1) Covariates: bmi, age, sex, race, DIQ050 Centered covariates: age_c, bmi_c BMI categories: bmi_cat\nNHANES is a national surveys based on complex sampling designs (oversampling certain groups (e.g., minorities, older adults) to ensure representation. They use multistage sampling to represent the U.S. population, so we apply sampling weights, strata, and PSU (primary sampling units) for valid estimates.\nWe use survey design in regression anlaysis to avoid - - bias prevalence estimates (e.g., mean BMI or diabetes %) - underestimation of standard errors - incorrect inference for population-level parameters.\n\n\nCode\n# data exploration\n\nprint(table(adult$diabetes_dx, useNA = \"ifany\"))\n\n\n\n   0    1 &lt;NA&gt; \n4974  618  177 \n\n\nCode\nprint(table(adult$sex, useNA = \"ifany\"))\n\n\n\n  Male Female \n  2758   3011 \n\n\nCode\nprint(table(adult$race, useNA = \"ifany\"))\n\n\n\n        NH White Mexican American   Other Hispanic         NH Black \n            2472              767              508             1177 \n     Other/Multi \n             845 \n\n\nCode\nif (sum(!is.na(adult$diabetes_dx)) == 0) {\n  stop(\"Too few non-missing outcomes for modeling (n = 0). Check DIQ010 upstream.\")\n}\n\n# (optional plots omitted for brevity)\n\n# save for downstream\nif (!dir.exists(\"data\")) dir.create(\"data\", recursive = TRUE)\nsaveRDS(adult, \"data/adult_cleaned_2013_2014.rds\")\n\n\n\n\nCode\nggplot(adult, aes(x = age)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Age &gt;20 years\",\n    x = \"Age (years)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution in &gt;20 years age group\", x=\"diabetes_dx (0=No, 1=Yes)\", y=\"Count\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(bmi_cat))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution by BMI in &gt;20 years age group\", x=\"bmi_cat\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(diabetes_dx), y = bmi)) +\n  geom_boxplot(fill = \"skyblue\") +\n  labs(\n    title = \"BMI Distribution by Diabetes Diagnosis in &gt;20 years age group\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\n# plots for adult data bmi categories and race categories\n\nggplot(adult, aes(x = factor(race), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by Race in &gt;20 years age group\",\n    x = \"Race/Ethnicity\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(bmi_cat), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by BMI in &gt;20 years age group\",\n    x = \"BMI\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nExploratory data analysis results to understand the distributions, relationships, and patterns of the before modeling\n\nDetects skewness, outliers, and general age patterns.\nGives baseline prevalence in your dataset. - counts of BMI categories.\nCompares BMI across diabetes diagnosis (0 vs 1), to identify patterns whether diabetic patients have higher BMI.\nCounts diabetes cases across race/ethnicity, to check disparities in diabetes prevalence by race."
  },
  {
    "objectID": "index.html#multiple-logistic-regression-on-survey-weighted-dataset",
    "href": "index.html#multiple-logistic-regression-on-survey-weighted-dataset",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Multiple Logistic regression on survey weighted dataset",
    "text": "Multiple Logistic regression on survey weighted dataset\nWe conducted frequentist method Multiple Logistic regression on a survey-weighted dataset, for complete case analysis and data exploration"
  },
  {
    "objectID": "index.html#multivariate-imputation-by-chained-equations",
    "href": "index.html#multivariate-imputation-by-chained-equations",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Multivariate Imputation by Chained Equations",
    "text": "Multivariate Imputation by Chained Equations\nMultiple Imputation Pooled Logistic Regression\n\nWe conducted MICE to manage missiging data as an alternative to the Bayesian Approach Buuren and Groothuis-Oudshoorn (2011)\nFlatness of the density, heavy tails, non-zero peakedness, skewness and multimodality do not hamper the good performance of multiple imputation for the mean structure in samples n &gt; 400 even for high percentages (75%) of missing data in one variable Van Buuren and Van Buuren (2012).\nMultiple Imputation (MI) can be performed using mice package in R\nIterative mice imputes missing values of one variable at a time, using regression models based on the other variables in the dataset.\nIn the chain process, each imputed variable become a predictor for the subsequent imputation, and the entire process is repeated multiple times to create several complete datasets, each reflecting different possibilities for the missing data.\n\nBelow are the rows and cloumn numbers from the three datasets created\n\nRows: 10175 and Columns: 10 (survey-weighted, merged data)\nRows: 5,769 and Columns: 12 (filtered data, adult)\nRows: 5,592 and Columns: 11 (imputed data, adult_imp1)\n\n\n\nCode\n# ----- Multiple Imputation (predictors only) \nmi_dat &lt;- adult %&gt;%\n  dplyr::select(diabetes_dx, age, bmi, sex, race, WTMEC2YR, SDMVPSU, SDMVSTRA)\n\nmeth &lt;- mice::make.method(mi_dat)\npred &lt;- mice::make.predictorMatrix(mi_dat)\n\n# Do not impute outcome\nmeth[\"diabetes_dx\"] &lt;- \"\"\npred[\"diabetes_dx\", ] &lt;- 0\npred[,\"diabetes_dx\"] &lt;- 1\n\n# Imputation methods\nmeth[\"age\"]  &lt;- \"norm\"\nmeth[\"bmi\"]  &lt;- \"pmm\"\nmeth[\"sex\"]  &lt;- \"polyreg\"\nmeth[\"race\"] &lt;- \"polyreg\"\n\n# Survey design vars as auxiliaries only\nmeth[c(\"WTMEC2YR\",\"SDMVPSU\",\"SDMVSTRA\")] &lt;- \"\"\npred[, c(\"WTMEC2YR\",\"SDMVPSU\",\"SDMVSTRA\")] &lt;- 1\n\nglimpse(mi_dat)\n\n\nRows: 5,769\nColumns: 8\n$ diabetes_dx &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age         &lt;dbl&gt; 69, 54, 72, 73, 56, 61, 42, 56, 65, 26, 76, 33, 32, 38, 50…\n$ bmi         &lt;dbl&gt; 26.7, 28.6, 28.9, 19.7, 41.7, 35.7, NA, 26.5, 22.0, 20.3, …\n$ sex         &lt;fct&gt; Male, Male, Male, Female, Male, Female, Male, Female, Male…\n$ race        &lt;fct&gt; NH Black, NH White, NH White, NH White, Mexican American, …\n$ WTMEC2YR    &lt;dbl&gt; 13481.04, 24471.77, 57193.29, 65541.87, 25344.99, 61758.65…\n$ SDMVPSU     &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ SDMVSTRA    &lt;dbl&gt; 112, 108, 109, 116, 111, 114, 106, 112, 112, 113, 116, 114…\n\n\nCode\nimp &lt;- mice::mice(mi_dat, m = 5, method = meth, predictorMatrix = pred, seed = 123)\n\n\n\n iter imp variable\n  1   1  bmi\n  1   2  bmi\n  1   3  bmi\n  1   4  bmi\n  1   5  bmi\n  2   1  bmi\n  2   2  bmi\n  2   3  bmi\n  2   4  bmi\n  2   5  bmi\n  3   1  bmi\n  3   2  bmi\n  3   3  bmi\n  3   4  bmi\n  3   5  bmi\n  4   1  bmi\n  4   2  bmi\n  4   3  bmi\n  4   4  bmi\n  4   5  bmi\n  5   1  bmi\n  5   2  bmi\n  5   3  bmi\n  5   4  bmi\n  5   5  bmi\n\n\n\nResults from MICE (pooled imputed dataset):\n\nIn the final analytic dataset consisting of 5,769 participants with 8 variables, with missing values were addressed using Multivariate Imputation by Chained Equations (MICE).\nFive imputations were performed across five iterations each, with BMI imputed conditionally based on other predictors (age, sex, race, and diabetes status).\nThe iterative process showed stable convergence, indicating reliable estimation of missing BMI values for subsequent survey-weighted and Bayesian modeling analyses.\n\n\n\nCode\nfit_mi &lt;- with(imp, {\n  age_c &lt;- as.numeric(scale(age))\n  bmi_c &lt;- as.numeric(scale(bmi))\n  glm(diabetes_dx ~ age_c + bmi_c + sex + race, family = binomial())\n})\npool_mi &lt;- pool(fit_mi)\nsummary(pool_mi)\n\n\n                  term   estimate  std.error  statistic       df       p.value\n1          (Intercept) -2.6895645 0.09941301 -27.054453 5566.204 1.486581e-151\n2                age_c  1.0660265 0.05594733  19.054108 5520.446  1.911564e-78\n3                bmi_c  0.5468538 0.04473386  12.224604 5148.557  6.751227e-34\n4            sexFemale -0.6178297 0.09379129  -6.587282 5551.660  4.892566e-11\n5 raceMexican American  0.8877355 0.13750463   6.456041 5472.583  1.167455e-10\n6   raceOther Hispanic  0.5606621 0.17485537   3.206433 5573.987  1.351505e-03\n7         raceNH Black  0.6809629 0.11981185   5.683602 5576.734  1.385727e-08\n8      raceOther/Multi  0.7476406 0.15300663   4.886328 4749.963  1.061140e-06\n\n\nCode\n## table \n\nmi_or &lt;- summary(pool_mi, conf.int = TRUE, exponentiate = TRUE) %&gt;%\n  dplyr::rename(\n    term = term, OR = estimate, LCL = `2.5 %`, UCL = `97.5 %`, p.value = p.value\n  ) %&gt;%\n  dplyr::filter(term != \"(Intercept)\")\nknitr::kable(mi_or, caption = \"MI pooled odds ratios (per 1 SD)\")\n\n\n\nMI pooled odds ratios (per 1 SD)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nOR\nstd.error\nstatistic\ndf\np.value\nLCL\nUCL\nconf.low\nconf.high\n\n\n\n\n2\nage_c\n2.9038183\n0.0559473\n19.054108\n5520.446\n0.0000000\n2.6021752\n3.2404277\n2.6021752\n3.2404277\n\n\n3\nbmi_c\n1.7278084\n0.0447339\n12.224604\n5148.557\n0.0000000\n1.5827382\n1.8861754\n1.5827382\n1.8861754\n\n\n4\nsexFemale\n0.5391132\n0.0937913\n-6.587282\n5551.660\n0.0000000\n0.4485669\n0.6479368\n0.4485669\n0.6479368\n\n\n5\nraceMexican American\n2.4296216\n0.1375046\n6.456041\n5472.583\n0.0000000\n1.8555327\n3.1813298\n1.8555327\n3.1813298\n\n\n6\nraceOther Hispanic\n1.7518320\n0.1748554\n3.206433\n5573.987\n0.0013515\n1.2434346\n2.4680953\n1.2434346\n2.4680953\n\n\n7\nraceNH Black\n1.9757793\n0.1198118\n5.683602\n5576.734\n0.0000000\n1.5621842\n2.4988753\n1.5621842\n2.4988753\n\n\n8\nraceOther/Multi\n2.1120110\n0.1530066\n4.886328\n4749.963\n0.0000011\n1.5646727\n2.8508138\n1.5646727\n2.8508138\n\n\n\n\n\nAfter addressing missing BMI values using Multivariate Imputation by Chained Equations (MICE), pooled estimates from five imputations were analyzed using a survey-weighted multiple logistic regression model.\n\nAge remained the strongest predictor of diabetes (OR = 2.90, 95% CI: 2.60–3.24, p &lt; 0.001).\nBMI continued to show a significant positive association (OR = 1.73, 95% CI: 1.58–1.89, p &lt; 0.001).\nFemale sex was associated with lower odds of diabetes compared to males (OR = 0.54, 95% CI: 0.45–0.65, p &lt; 0.001).\nCompared to Non-Hispanic Whites, higher odds of diabetes were observed among: Mexican Americans (OR = 2.43, 95% CI: 1.86–3.18) Other Hispanics (OR = 1.75, 95% CI: 1.24–2.47) Non-Hispanic Blacks (OR = 1.98, 95% CI: 1.56–2.50) Other/Multi-racial groups (OR = 2.11, 95% CI: 1.56–2.85)\nAll associations were statistically significant (p &lt; 0.01).\n\n\n\nCode\nlibrary(gt)\n\n# Bayesian Logistic Regression (formula weights) \nadult_imp1 &lt;- complete(imp, 1) %&gt;%\n  dplyr::mutate(\n    age_c  = as.numeric(scale(age)),\n    bmi_c  = as.numeric(scale(bmi)),\n    wt_norm = WTMEC2YR / mean(WTMEC2YR, na.rm = TRUE),\n    # ensure factor refs match survey/mice:\n    race = forcats::fct_relevel(race, \"NH White\"),\n    sex  = forcats::fct_relevel(sex,  \"Male\")\n  ) %&gt;%\n  dplyr::filter(!is.na(diabetes_dx), !is.na(age_c), !is.na(bmi_c),\n                !is.na(sex), !is.na(race)) %&gt;%\n  droplevels()\n\nstopifnot(all(is.finite(adult_imp1$wt_norm)))\n\nglimpse(adult_imp1)\n\n\nRows: 5,592\nColumns: 11\n$ diabetes_dx &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age         &lt;dbl&gt; 69, 54, 72, 73, 56, 61, 42, 56, 65, 26, 76, 33, 32, 38, 50…\n$ bmi         &lt;dbl&gt; 26.7, 28.6, 28.9, 19.7, 41.7, 35.7, 23.6, 26.5, 22.0, 20.3…\n$ sex         &lt;fct&gt; Male, Male, Male, Female, Male, Female, Male, Female, Male…\n$ race        &lt;fct&gt; NH Black, NH White, NH White, NH White, Mexican American, …\n$ WTMEC2YR    &lt;dbl&gt; 13481.04, 24471.77, 57193.29, 65541.87, 25344.99, 61758.65…\n$ SDMVPSU     &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ SDMVSTRA    &lt;dbl&gt; 112, 108, 109, 116, 111, 114, 106, 112, 112, 113, 116, 114…\n$ age_c       &lt;dbl&gt; 1.13241831, 0.27835981, 1.30323001, 1.36016725, 0.39223428…\n$ bmi_c       &lt;dbl&gt; -0.33319172, -0.06755778, -0.02561558, -1.31184309, 1.7639…\n$ wt_norm     &lt;dbl&gt; 0.3393916, 0.6160884, 1.4398681, 1.6500477, 0.6380722, 1.5…\n\n\nCode\nlibrary(tableone)\n\nvars &lt;- c(\"age\", \"bmi\", \"age_c\", \"bmi_c\", \"wt_norm\", \"sex\", \"race\", \"diabetes_dx\")\n\ntable1 &lt;- CreateTableOne(vars = vars, data = adult_imp1, factorVars = c(\"sex\", \"race\", \"diabetes_dx\"))\nprint(table1, showAllLevels = TRUE)\n\n\n                     \n                      level            Overall      \n  n                                     5592        \n  age (mean (SD))                      48.84 (17.57)\n  bmi (mean (SD))                      29.00 (7.11) \n  age_c (mean (SD))                    -0.02 (1.00) \n  bmi_c (mean (SD))                    -0.01 (0.99) \n  wt_norm (mean (SD))                   1.00 (0.79) \n  sex (%)             Male              2669 (47.7) \n                      Female            2923 (52.3) \n  race (%)            NH White          2398 (42.9) \n                      Mexican American   742 (13.3) \n                      Other Hispanic     489 ( 8.7) \n                      NH Black          1141 (20.4) \n                      Other/Multi        822 (14.7) \n  diabetes_dx (%)     0                 4974 (88.9) \n                      1                  618 (11.1) \n\n\n\n\nSummary of Imputed Adult Dataset (N = 5,592)\n\n\nCode\n## correlation matrix\nlibrary(ggplot2)\nlibrary(reshape2)\n\ncorrelation_matrix &lt;- cor(adult_imp1[, c(\"diabetes_dx\", \"age\", \"bmi\")], use = \"complete.obs\", method = \"pearson\")\ncorrelation_melted &lt;- melt(correlation_matrix)\n\nggplot(correlation_melted, aes(Var1, Var2, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0,\n                       limit = c(-1, 1), space = \"Lab\", name = \"Correlation\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Correlation Heatmap\", x = \"Features\", y = \"Features\")\n\n\n\n\n\n\n\n\n\n\n\nVisualization of imputed dataset\nPairwise correlations\nA heatmap visualizing variables: diabetes_dx, age, and bmi show the strength and direction of correlations (Pearson correlation) which measures linear association between variables.\n\n\nCode\n# Class distribution\n\nggplot(adult_imp1, aes(x = factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(\n    title = \"Diabetes Diagnosis Distribution\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nprop.table(table(adult_imp1$diabetes_dx))\n\n\n\n       0        1 \n0.889485 0.110515 \n\n\nCode\n# Visualization of Diabetes vs BMI (adult_data1)\n\nlibrary(ggplot2)\n\n# Create the plot\nggplot(adult_imp1, aes(x = factor(diabetes_dx), y = bmi, fill = factor(diabetes_dx))) +\n  geom_boxplot(alpha = 0.7) +\n  scale_x_discrete(labels = c(\"0\" = \"No Diabetes\", \"1\" = \"Diabetes\")) +\n  labs(\n    x = \"Diabetes Diagnosis\",\n    y = \"BMI\",\n    title = \"BMI Distribution by Diabetes Status\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\n# logistic regression curve\nggplot(adult_imp1, aes(x = bmi, y = diabetes_dx)) +\n  geom_point(aes(y = diabetes_dx), alpha = 0.2, position = position_jitter(height = 0.02)) +\n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = TRUE, color = \"blue\") +\n  labs(\n    x = \"BMI\",\n    y = \"Probability of Diabetes\",\n    title = \"Predicted Probability of Diabetes vs BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save your dataset as CSV\nwrite.csv(adult_imp1, \"adult_imp1.csv\", row.names = FALSE)\n\n\n\nSurvey weights-Normalized MEC exam weights (wt_norm) with mean 1.00 (SD 0.79)\nData readiness for Bayesian logistic regression:\n\nNo missing values remain in selected predictors or outcome.\nContinuous variables are standardized, which facilitates prior specification.\nCategorical variables are correctly re-leveled for reference categories.\nWeights are available for inclusion in the likelihood to account for survey design."
  },
  {
    "objectID": "index.html#bayesian-logistic-regression",
    "href": "index.html#bayesian-logistic-regression",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Bayesian Logistic Regression",
    "text": "Bayesian Logistic Regression\nThe study employs Bayesian logistic regression to estimate associations between predictors and outcome probabilities.\nThe Bayesian framework integrates prior information with observed data to generate posterior distributions, allowing direct probabilistic interpretation of parameters.\nThis approach provides flexibility in model specification, accounts for parameter uncertainty, and produces credible intervals that fully reflect uncertainty in the estimates.\nUnlike traditional frequentist methods, the Bayesian method enables inference through posterior probabilities, supporting more nuanced decision-making and interpretation."
  },
  {
    "objectID": "index.html#summary-of-bayesian-regression-presented-under-following-headings--",
    "href": "index.html#summary-of-bayesian-regression-presented-under-following-headings--",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Summary of Bayesian regression presented under following headings -",
    "text": "Summary of Bayesian regression presented under following headings -\n\nPosterior Predictive Probabilities - Posterior Mean, Median, credible Intervals\nPosterior Probability (Outcome=1) Comparison with External Prevalence (population prevalence)\nPosterior Model Fit Metrics - Prior versus Posterior Coefficient Distributions\nPosterior Predictive Checks - for Uncertainty Quantification"
  },
  {
    "objectID": "index.html#bayesian-logistic-regression-model-equation",
    "href": "index.html#bayesian-logistic-regression-model-equation",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Bayesian Logistic Regression model Equation",
    "text": "Bayesian Logistic Regression model Equation\n\\[ \\text{logit}(P(Y_i=1)) = \\beta_0 + \\beta_1 \\cdot Age_i + \\beta_2 \\cdot BMI_i + \\beta_3 \\cdot Race_i + \\beta_4 \\cdot Gender_i \\] Linear Regression equation: \\[ y_i = \\beta_0 + \\beta_1 X_1 +\\varepsilon_i \\] ## Following headings cover summary and diagnostics for Bayesian Logictic Regression\n- Posterior Predictive Probabilities - Posterior Mean, Median, credible Intervals - Posterior Probability (Outcome=1) Comparison with External Prevalence (population prevalence) - Posterior Model Fit Metrics - Prior versus Posterior Coefficient Distributions - Posterior Predictive Checks - for Uncertainty Quantification - Trace Plots for Markov Chain Monte Carlo Convergence - Posterior Predictive Checks - Residual Analysis - Prior Sensitivity Analysis - Model Fit Assessment - Posterior Predictive Probability Plots - Posterior Interval Coverage Evaluation - Convergence Diagnostics across Chains\n\nStatistical Tool - R packages and libraries are used to import data, perform data\nwrangling and analysis. \n###Data source - NHANES 2-year data (2013-2014) - a cross-sectional weighted data (CenterforHealthStatistics199?) was imported in R ### Data pre-processing Three datasets (demographics, exam, questionnaire in.XPT format files are imported (Haven package) in R. After selecting variables of interest, a merged dataset is created from the original weighted datasets (demographics, exam, questionnaire) and merged using ID to create a single merged dataframe.\n\nMerged dataset\n\n\nResponse Variable: Binary - Type 2 / diagnosed diabetes(excluding gestational diabetes) -“Doctor told you have diabetes?” DIQ010 combined with DIQ050 a secondary variable describing treatment status (insulin use) to exclude those cases.\nPredictor Variables Body Mass Index, factor, 4 levels (underweight (&lt;5th percentile)\no Normal (5th–&lt;85th)\no Overweight (85th–&lt;95th) o Obese (≥95th percentile)). Missing data are kept as it is as categorization provides clinically interpretable groups. Covariates included are Gender (factor, 2 levels): Male: Female, Ethnicity (factor, 5 levels): Mexican American, Non-Hispanic, White Non-Hispanic, Black Other Hispanic, Other Race - Including multi-racial and Age (number, continuous).\n\n\nAdult dataset\n\n\nWe filtered and analyzed population that included &gt; 20 years of age group forming an Adult dataset (presented below are the variables and the summary statistics of the Adult dataset)."
  },
  {
    "objectID": "index.html#diagnostics-for-bayesian-logictic-regression-visualization",
    "href": "index.html#diagnostics-for-bayesian-logictic-regression-visualization",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Diagnostics for Bayesian Logictic Regression Visualization",
    "text": "Diagnostics for Bayesian Logictic Regression Visualization\n\nTrace Plots for Markov Chain Monte Carlo Convergence\nPosterior Predictive Checks\nResidual Analysis\nPrior Sensitivity Analysis\nModel Fit Assessment\nPosterior Predictive Probability Plots\nPosterior Interval Coverage Evaluation\nConvergence Diagnostics across Chains\n\nSince the data has missing values we perform Multiple Imputation by Chained Equations (MICE) to address missing data for predictors while keeping doctor-diagnosed variable (diabetes_dx) as complete. we used for age: Normal regression (norm), bmi: Predictive mean matching (pmm) and for sex & race: Polytomous logistic regression (polyreg) and created 5 imputed datasets reflecting uncertainty from missing values. Survey design variables (auxiliary) are added to aid imputation."
  },
  {
    "objectID": "index.html#training-and-testing",
    "href": "index.html#training-and-testing",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Training and testing",
    "text": "Training and testing\nTo evaluate how well the model learned patterns from the training dataset, and how reliably it will perform on new data in real-world scenarios, we decided to perform Training/Testing on the imputed data\nTesting set to evaluate model performance on unseen data. - Model Accuracy / Performance - Generalizability - Helps check for overfitting or underfitting - Reliability of Predictions - Confidence on model predictions for new individuals - Distribution and Bias Check - to ensure the training and testing sets are representative of the same population\nResults from training and test data- Training (n=4473) & Testing (n=1119) sets: Age ~48 yrs, BMI ~28, bmi_c ~0, wt_norm ~1; ranges similar across sets.\n\n\nCode\n#Code here\n\nimport pandas as pd\n\n# Load the data exported from R\nadult_data_py = pd.read_csv(\"adult_imp1.csv\")  # your R dataset saved as CSV\n\n# Now you can rename it freely in Python\ndf = adult_data_py  # just create a new variable pointing to the same DataFrame\n\n# Check the data\ndf.head()\n\n\n   diabetes_dx  age   bmi     sex  ... SDMVSTRA     age_c     bmi_c   wt_norm\n0            1   69  26.7    Male  ...      112  1.132418 -0.333192  0.339392\n1            1   54  28.6    Male  ...      108  0.278360 -0.067558  0.616088\n2            1   72  28.9    Male  ...      109  1.303230 -0.025616  1.439868\n3            0   73  19.7  Female  ...      116  1.360167 -1.311843  1.650048\n4            0   56  41.7    Male  ...      111  0.392234  1.763918  0.638072\n\n[5 rows x 11 columns]\n\n\nCode\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Optional: rename columns if needed\ndf = df.rename(columns={\"diabetes_dx\": \"diabetes_status\"})\n\n# Separate predictors (X) and outcome (y)\nX = df.drop(columns=[\"diabetes_status\"])\ny = df[\"diabetes_status\"]\n\n# Create 80/20 train-test split, stratifying by outcome to keep class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1234, stratify=y\n)\n\n# Combine X and y if you want full train/test datasets\ntrain_data = pd.concat([X_train, y_train], axis=1)\ntest_data  = pd.concat([X_test, y_test], axis=1)\n\n# Check sizes\nprint(\"Training set:\", train_data.shape)\n\n\nTraining set: (4473, 11)\n\n\nCode\nprint(\"Testing set: \", test_data.shape)\n\n\nTesting set:  (1119, 11)\n\n\nCode\n# Check class balance\nprint(\"\\nTraining set class distribution:\\n\", y_train.value_counts(normalize=True))\n\n\n\nTraining set class distribution:\n diabetes_status\n0    0.88956\n1    0.11044\nName: proportion, dtype: float64\n\n\nCode\nprint(\"\\nTesting set class distribution:\\n\", y_test.value_counts(normalize=True))\n\n\n\nTesting set class distribution:\n diabetes_status\n0    0.889187\n1    0.110813\nName: proportion, dtype: float64\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Combine train and test distributions into a DataFrame\ntrain_dist = pd.DataFrame({'Class': y_train.unique(), \n                           'Proportion': y_train.value_counts(normalize=True).values,\n                           'Set': 'Train'})\n\ntest_dist = pd.DataFrame({'Class': y_test.unique(), \n                          'Proportion': y_test.value_counts(normalize=True).values,\n                          'Set': 'Test'})\n\ndist_df = pd.concat([train_dist, test_dist])\n\n# Plot\nplt.figure(figsize=(8,5))\nsns.barplot(x='Class', y='Proportion', hue='Set', data=dist_df)\nplt.title('Class Distribution in Training and Testing Sets')\nplt.ylabel('Proportion')\nplt.xlabel('Diabetes Status')\nplt.ylim(0,1)\n\n\n(0.0, 1.0)\n\n\nCode\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n# Numeric summaries for predictors\nprint(\"Training set numeric summary:\\n\", X_train.describe())\n\n\nTraining set numeric summary:\n                age          bmi  ...        bmi_c      wt_norm\ncount  4473.000000  4473.000000  ...  4473.000000  4473.000000\nmean     48.926895    28.933736  ...    -0.020899     1.001234\nstd      17.571583     6.935321  ...     0.969609     0.786057\nmin      20.000000    14.100000  ...    -2.094764     0.000000\n25%      34.000000    24.100000  ...    -0.696691     0.477152\n50%      48.000000    27.700000  ...    -0.193384     0.700259\n75%      63.000000    32.300000  ...     0.449729     1.286732\nmax      80.000000    77.500000  ...     6.769021     4.314957\n\n[8 rows x 8 columns]\n\n\nCode\nprint(\"\\nTesting set numeric summary:\\n\", X_test.describe())\n\n\n\nTesting set numeric summary:\n                age          bmi  ...        bmi_c      wt_norm\ncount  1119.000000  1119.000000  ...  1119.000000  1119.000000\nmean     48.475424    29.275782  ...     0.026921     1.002283\nstd      17.568193     7.744067  ...     1.082677     0.785208\nmin      20.000000    15.200000  ...    -1.940976     0.000000\n25%      33.000000    23.900000  ...    -0.724652     0.453099\n50%      47.000000    27.800000  ...    -0.179404     0.697037\n75%      63.000000    32.900000  ...     0.533614     1.378142\nmax      80.000000    82.900000  ...     7.523981     3.877294\n\n[8 rows x 8 columns]\n\n\nTraining (n=4473) & Testing (n=1119) sets: Age ~48 yrs, BMI ~28, bmi_c ~0, wt_norm ~1; ranges similar across sets.\nPrior - We used student_t(3, 0, 10) prior R. V. D. Schoot et al. (2013) - student_t(ν,μ,σ)\nStudent’s t-distribution with: ν=3: degrees of freedom (controls tail heaviness) μ=0: location (center, like the mean) σ=10: scale (spread, like standard deviation) student_t(3, 0, 10) means: It’s centered at 0 It allows large values (± several times 10) It has heavy tails, since ν=3, allows for outliers or unexpected large parameter values Helps the model remain stable, especially with: Small datasets High correlation between predictors Potential outliers in the data\nBayesian Logistic Regression Analysis\n\n\nCode\nlibrary(gt)\n\npriors &lt;- c(\n  set_prior(\"normal(0, 2.5)\", class = \"b\"),\n  set_prior(\"student_t(3, 0, 10)\", class = \"Intercept\") \n)\n\nbayes_fit &lt;- brm(\n  formula = diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race,\n  data    = adult_imp1,\n  family  = bernoulli(link = \"logit\"),\n  prior   = priors,\n  chains  = 4, iter = 2000, seed = 123,\n  control = list(adapt_delta = 0.95),\n  refresh = 0   # quiet Stan output\n)\n\n\nRunning /opt/R/4.4.2/lib/R/bin/R CMD SHLIB foo.c\nusing C compiler: ‘gcc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-2)’\ngcc -I\"/opt/R/4.4.2/lib/R/include\" -DNDEBUG   -I\"/opt/R/4.4.2/lib/R/library/Rcpp/include/\"  -I\"/opt/R/4.4.2/lib/R/library/RcppEigen/include/\"  -I\"/opt/R/4.4.2/lib/R/library/RcppEigen/include/unsupported\"  -I\"/opt/R/4.4.2/lib/R/library/BH/include\" -I\"/opt/R/4.4.2/lib/R/library/StanHeaders/include/src/\"  -I\"/opt/R/4.4.2/lib/R/library/StanHeaders/include/\"  -I\"/opt/R/4.4.2/lib/R/library/RcppParallel/include/\"  -I\"/opt/R/4.4.2/lib/R/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/opt/R/4.4.2/lib/R/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o\nIn file included from /opt/R/4.4.2/lib/R/library/RcppEigen/include/Eigen/Core:19,\n                 from /opt/R/4.4.2/lib/R/library/RcppEigen/include/Eigen/Dense:1,\n                 from /opt/R/4.4.2/lib/R/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22,\n                 from &lt;command-line&gt;:\n/opt/R/4.4.2/lib/R/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory\n  679 | #include &lt;cmath&gt;\n      |          ^~~~~~~\ncompilation terminated.\nmake: *** [/opt/R/4.4.2/lib/R/etc/Makeconf:195: foo.o] Error 1\n\n\nCode\nprior_summary(bayes_fit)\n\n\n               prior     class                coef group resp dpar nlpar lb ub\n      normal(0, 2.5)         b                                                \n      normal(0, 2.5)         b               age_c                            \n      normal(0, 2.5)         b               bmi_c                            \n      normal(0, 2.5)         b raceMexicanAmerican                            \n      normal(0, 2.5)         b         raceNHBlack                            \n      normal(0, 2.5)         b     raceOtherDMulti                            \n      normal(0, 2.5)         b   raceOtherHispanic                            \n      normal(0, 2.5)         b           sexFemale                            \n student_t(3, 0, 10) Intercept                                                \n tag       source\n             user\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n             user\n\n\nCode\nsummary(bayes_fit)            # Bayesian model summary\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race \n   Data: adult_imp1 (Number of observations: 5592) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept              -2.66      0.09    -2.84    -2.50 1.00     4187     3510\nage_c                   1.09      0.06     0.97     1.22 1.00     3012     3098\nbmi_c                   0.63      0.05     0.53     0.72 1.00     3472     3315\nsexFemale              -0.66      0.10    -0.86    -0.46 1.00     4003     3052\nraceMexicanAmerican     0.69      0.18     0.35     1.04 1.00     3526     2843\nraceOtherHispanic       0.43      0.24    -0.07     0.89 1.00     4058     3114\nraceNHBlack             0.54      0.15     0.24     0.82 1.00     3597     3177\nraceOtherDMulti         0.82      0.19     0.45     1.19 1.00     3763     3257\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\nCode\nlibrary(ggplot2)\n\n# adult_imp1 plot \n\n# Convert to long format\nadult_long &lt;- adult_imp1 %&gt;%\n  select(bmi_c, age_c) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Coefficient\", values_to = \"Value\")\n\n# Plot\nggplot(adult_long, aes(x = Value, fill = Coefficient)) +\n  geom_density(alpha = 0.5) +\n  theme_minimal() +\n  labs(title = \"Distributions for Coefficients from adult_imp1 data\",\n       x = \"Coefficient Value\", y = \"Density\") +\n  scale_fill_manual(values = c(\"bmi_c\" = \"skyblue\", \"age_c\" = \"orange\"))\n\n\n\n\n\n\n\n\n\nCode\n## prior draws \n\nprior_draws &lt;- tibble(\n  term = rep(c(\"Age (per 1 SD)\", \"BMI (per 1 SD)\"), each = 4000),\n  value = c(rnorm(4000, 0, 2.5), rnorm(4000, 0, 2.5))\n)\n\n## Plot (prior) (age and bmi) \nggplot(prior_draws, aes(x = value, fill = term)) +\n  geom_density(alpha = 0.5) +\n  theme_minimal() +\n  labs(title = \"Prior Distributions for Coefficients\",\n       x = \"Coefficient Value\", y = \"Density\") +\n  scale_fill_manual(values = c(\"skyblue\", \"orange\"))"
  },
  {
    "objectID": "index.html#comparative-visualizations",
    "href": "index.html#comparative-visualizations",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Comparative Visualizations",
    "text": "Comparative Visualizations\n\nPredicted vs observed - to check how well the model’s predictions align with reality where mean(y_rep) = average predicted probability of diabetes for each individual, across all posterior draws of the parameters. y = the actual observed diabetes status (0 = non-diabetic, 1 = diabetic).\nmcmc plot (dens plots) comparing observed and posterior parameter values (estimates) for bmi_c, age_c, sex_female, and by race categories\nFitted (Predicted) vs observed for bmi using point and error bars\nFitted (Predicted) vs observed for bmi using line plot\n\n\nComparative Visualizations for Model Assessment\nTo evaluate how well the Bayesian model predicts diabetes-related outcomes, we conducted several visual comparisons between observed and posterior-predicted values:\n\nPosterior Parameter Distributions to assess uncertainty and effect sizes of predictors, we extracted posterior draws using as_draws_df(bayes_fit).\n\n\nPlotted density overlays (mcmc_areas) for key predictors: age, BMI, sex, and race categories: shows density plots with distribution of posterior estimates to visualize uncertainty and parameter magnitude.\n\n\nPredicted vs Observed Values to evaluate model fit by comparing predicted outcomes to actual data using fitted(bayes_fit, summary = TRUE).\n\n\nCompared with the observed values for continuous predictors (e.g., BMI and age).\nVisualization in Scatter plots with point estimates and 95% credible intervals as error bars shows Line of perfect agreement (slope = 1, dashed red line) for reference.\nScatter and error bar plots indicate predicted BMI values align with observed BMI across individuals.\nGood alignment along the 45° line suggests reliable predictions; deviations highlight areas where the model may under- or over-predict.\nOverall, these visualizations complement posterior summaries and predictive checks, supporting model validation and interpretation.\n\n\n\nPredicted vs Observed BMI\nTo evaluate model fit at the individual level, we compared observed BMI values to posterior-predicted BMI estimates from the Bayesian model:\n\nData Preparation\n\nA combined comaprative results from observed BMI (bmi) and predicted posterior estimates (predicted_bmi) into a single dataset with 95% credible intervals (lower_ci, upper_ci) from the posterior draws in a Line plot of BMI over observations:\n\nObserved BMI: solid line.\nPredicted BMI: solid line of posterior means.\nShaded ribbon: 95% credible interval around predicted values to visualize uncertainty.\n\n\nInterpretation\n\n\nClose alignment of predicted lines with observed BMI indicates good model fit.\nWider ribbons highlight greater posterior uncertainty for individual predictions.\nSummary statistics for bmi and standardized bmi_c help contextualize the observed range and variability in the sample.\n\n\n\nCode\n# Combine observed and predicted into one data frame\nplot_data &lt;- adult_imp1 %&gt;%\n  mutate(\n    predicted_bmi = predicted[, \"Estimate\"],\n    lower_ci = predicted[, \"Q2.5\"],\n    upper_ci = predicted[, \"Q97.5\"],\n    obs_index = 1:nrow(adult_imp1)  # index for x-axis\n  )\n\n# Line plot\nggplot(plot_data, aes(x = obs_index)) +\n  geom_line(aes(y = bmi, color = \"Observed\")) +               # observed BMI\n  geom_line(aes(y = predicted_bmi, color = \"Predicted\")) +   # predicted BMI\n  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.2) +  # uncertainty\n  labs(x = \"Observation\", y = \"BMI\", color = \"Legend\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nsummary(adult_imp1$bmi)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   14.1    24.1    27.7    29.0    32.4    82.9 \n\n\nCode\nsummary(plot_data$bmi_c)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-2.09476 -0.69669 -0.19338 -0.01133  0.46371  7.52398 \n\n\nCentering for bmi - Summary of original bmi (observed data) and centered version of BMI. - Centering doesn’t change the distribution shape, only shifts it so the mean is zero. - Centering is useful in regression/Bayesian models to improve numerical stability and interpretability of intercepts - Plots showing predicted values of bmi and age (prior vs predicted) and the proportion of diabetes=1 for each draw\n\n\nVisualization on Prior vs Posterior Distributions\n\nTo assess how the Bayesian model updates beliefs from prior information to posterior estimates, we compared prior vs posterior coefficient distributions for key predictors: BMI and age.\n\n\nPrior Draws\n\n\nSimulated from a standard normal distribution (mean = 0, SD = 1) for both BMI and age coefficients. Represent initial beliefs about coefficient values before seeing the data.\n\n\nPosterior Draws\n\n\nExtracted from the fitted model (bayes_fit) for b_bmi_c and b_age_c.\nPivoted to long format and labeled as “Posterior”.\n\n\nVisualization Combined prior and posterior draws\n\n\nPlotted density overlays with facets for BMI and age.\nPosterior distributions are narrower and often shifted from prior, reflecting information gained from the data.\nDifferences between prior and posterior highlight the model’s learning about effect sizes.\nPosterior Predictive Proportions of Diabetes\nComputed the proportion of diabetes cases (diabetes = 1) for each posterior draw (pp_samples).\n\nSummary statistics: - mean(pp_proportion) – average predicted prevalence. - Compared to observed prevalence: Survey-weighted mean: svymean(~diabetes_dx, nhanes_design_adult) - Observed sample mean: mean(adult_imp1$diabetes_dx) - Visualization (Histogram) of posterior proportions shows variability and uncertainty in predicted diabetes prevalence. - Alignment of posterior mean with observed prevalence indicates good predictive performance.\nInterpretaion: - Prior vs posterior plots demonstrate that the Bayesian model updates prior beliefs in a data-informed way. - Posterior predictive proportions closely match observed prevalence, supporting model reliability for inference and prediction.\n\n\nCode\nprior_summary(bayes_fit)\n\n\n               prior     class                coef group resp dpar nlpar lb ub\n      normal(0, 2.5)         b                                                \n      normal(0, 2.5)         b               age_c                            \n      normal(0, 2.5)         b               bmi_c                            \n      normal(0, 2.5)         b raceMexicanAmerican                            \n      normal(0, 2.5)         b         raceNHBlack                            \n      normal(0, 2.5)         b     raceOtherDMulti                            \n      normal(0, 2.5)         b   raceOtherHispanic                            \n      normal(0, 2.5)         b           sexFemale                            \n student_t(3, 0, 10) Intercept                                                \n tag       source\n             user\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n     (vectorized)\n             user\n\n\nCode\nprior_draws &lt;- tibble(\n  term = rep(c(\"BMI (per 1 SD)\", \"Age (per 1 SD)\"), each = 4000),\n  estimate = c(rnorm(4000, 0, 1), rnorm(4000, 0, 1)),\n  type = \"Prior\"\n)\n\npost\n\n\n# A draws_df: 1000 iterations, 4 chains, and 11 variables\n   b_Intercept b_age_c b_bmi_c b_sexFemale b_raceMexicanAmerican\n1         -2.6     1.1    0.70       -0.71                  0.67\n2         -2.7     1.0    0.62       -0.57                  0.65\n3         -2.6     1.1    0.65       -0.76                  0.63\n4         -2.7     1.0    0.65       -0.67                  0.82\n5         -2.6     1.1    0.61       -0.73                  0.75\n6         -2.5     1.0    0.60       -0.77                  0.61\n7         -2.8     1.1    0.66       -0.66                  0.52\n8         -2.8     1.2    0.67       -0.57                  0.94\n9         -2.8     1.1    0.65       -0.52                  0.84\n10        -2.6     1.1    0.67       -0.85                  0.70\n   b_raceOtherHispanic b_raceNHBlack b_raceOtherDMulti\n1                0.605          0.52              0.95\n2                0.338          0.45              0.69\n3                0.566          0.63              0.54\n4                0.453          0.61              0.78\n5                0.090          0.50              0.62\n6                0.015          0.48              0.60\n7                0.736          0.50              0.84\n8                0.913          0.57              1.07\n9                0.570          0.66              0.81\n10               0.467          0.54              0.97\n# ... with 3990 more draws, and 3 more variables\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nCode\nhead(post)\n\n\n# A draws_df: 6 iterations, 1 chains, and 11 variables\n  b_Intercept b_age_c b_bmi_c b_sexFemale b_raceMexicanAmerican\n1        -2.6     1.1    0.70       -0.71                  0.67\n2        -2.7     1.0    0.62       -0.57                  0.65\n3        -2.6     1.1    0.65       -0.76                  0.63\n4        -2.7     1.0    0.65       -0.67                  0.82\n5        -2.6     1.1    0.61       -0.73                  0.75\n6        -2.5     1.0    0.60       -0.77                  0.61\n  b_raceOtherHispanic b_raceNHBlack b_raceOtherDMulti\n1               0.605          0.52              0.95\n2               0.338          0.45              0.69\n3               0.566          0.63              0.54\n4               0.453          0.61              0.78\n5               0.090          0.50              0.62\n6               0.015          0.48              0.60\n# ... with 3 more variables\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nCode\nlibrary(brms)\nlibrary(tidyr)\n\n# Extract posterior draws as dataframe\n\npost &lt;- as_draws_df(bayes_fit) %&gt;%           # bayes_fit = your brms model\n  select(b_bmi_c, b_age_c) %&gt;%               # select your coefficient columns\n  pivot_longer(\n    everything(),\n    names_to = \"term\",\n    values_to = \"estimate\"\n  ) %&gt;%\n  mutate(\n    term = case_when(\n      term == \"b_bmi_c\" ~ \"BMI (per 1 SD)\",\n      term == \"b_age_c\" ~ \"Age (per 1 SD)\"\n    ),\n    type = \"Posterior\"\n  )\n\n## visualization of prior and predicted draws\ncombined_draws &lt;- bind_rows(prior_draws, post) \n\nlibrary(ggplot2)\n\nggplot(combined_draws, aes(x = estimate, fill = type)) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ term, scales = \"free\", ncol = 2) +\n  theme_minimal(base_size = 13) +\n  labs(\n    title = \"Prior vs Posterior Distributions\",\n    x = \"Coefficient estimate\",\n    y = \"Density\",\n    fill = \"\"\n  )\n\n\n\n\n\n\n\n\n\nCode\n# Compute proportion of diabetes=1 for each draw\npp_proportion &lt;- rowMeans(pp_samples)  # proportion of 1's in each posterior draw\n\n# Summary of posterior proportions\nsummary(pp_proportion)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.09478 0.10497 0.10891 0.10941 0.11342 0.13126 \n\n\nCode\n# Optional: visualize the posterior probability distribution\npp_proportion_df &lt;- tibble(proportion = pp_proportion)\n\nggplot(pp_proportion_df, aes(x = proportion)) +\n  geom_histogram(binwidth = 0.01, fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Posterior Distribution of Proportion of Diabetes = 1\",\n    x = \"Proportion of Diabetes = 1\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nsvy_mean &lt;- svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)\n\n\n\n\n\nComparison of Diabetes Prevalence Across Methods\n\n\nMethod\ndiabetes_mean\nSE\n\n\n\n\nSurvey-weighted mean (NHANES)\n0.0890\n0.0048\n\n\nImputed dataset mean\n0.1105\nNA\n\n\nPosterior predictive mean\n0.1094\nNA\n\n\n\n\n\nEach value comes from a posterior predictive draw"
  },
  {
    "objectID": "index.html#propotion-of-diabetes-in-the-posterior-draws",
    "href": "index.html#propotion-of-diabetes-in-the-posterior-draws",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Propotion of diabetes in the posterior draws",
    "text": "Propotion of diabetes in the posterior draws\n\nRepresents the predicted probability of diabetes = 1 in the population according to Bayesian model.\nMin = 0.085 → In some posterior draws, only ~8.5% of the population is predicted to have diabetes. 1st Quartile = 0.105 → 25% of posterior draws predict diabetes prevalence below 10.5%.\nMedian = 0.109 → Half of the simulated draws predict a prevalence below ~10.9%, half above.\nMean = 0.109 → The average predicted prevalence is ~10.9%, very close to the median → roughly symmetric distribution. 3rd Quartile = 0.113 → 75% of draws predict prevalence below ~11.3%.\nMax = 0.128 → The highest predicted prevalence across all draws is ~12.8%.\n\nBayesian model predicts - that about 10–11% of this population has diabetes, with a relatively narrow range across posterior draws, reflects uncertainty in the estimate - while most predictions cluster around 10–11%, the model allows for values as low as 8.5% and as high as 12.8%. - On comparing this with the raw imputed data proportion show that the the model predictions align with the observed/imputed data.\nIts clinical relevance: - predicted proportion can be interpreted as the expected prevalence of diabetes in the target population, accounting for uncertainty in the model and imputed data. - Policy makers or clinicians could plan interventions accordingly anticipating ~1 in 10 adults in this population might have diabetes."
  },
  {
    "objectID": "index.html#translational-research-implications---we-now-use-the-model-to-guide",
    "href": "index.html#translational-research-implications---we-now-use-the-model-to-guide",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Translational Research Implications: - We now use the model to guide",
    "text": "Translational Research Implications: - We now use the model to guide\nprevention or intervention. - Only BMI is a modifiable risk factor here - What must change in BMI, behavior, or lifestyle to achieve a lower risk threshold? In practice, we hold non modifiable predictors as constant (sex, race). Vary modifiable predictors (BMI) until the model predicts the desired probability."
  },
  {
    "objectID": "index.html#internal-validation",
    "href": "index.html#internal-validation",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Internal validation",
    "text": "Internal validation\n\nTo illustrate personalized risk estimation using the Bayesian model, we computed the posterior predicted probability of diabetes for a representative participant.\n\n\nData and Prediction\n\n\nSelected one participant from the dataset (adult[1, ]) including all relevant covariates (age, BMI, sex, race).\nUsed posterior_linpred with transform = TRUE to obtain predicted probabilities for logistic regression.\n\n\nPosterior Predictive Distribution\n\n\nExtracted posterior draws for the individual’s predicted probability.\nComputed 95% credible interval from the posterior draws.\nDensity plot shows the distribution of plausible probabilities given the participant’s covariates.\n\nInterpretation for Targeted Implementation - The density highlights uncertainty around the individual’s predicted diabetes risk. - 95% credible interval provides a range of probable outcomes, not just a point estimate. - This approach allows personalized risk assessment, enabling clinicians or public health practitioners to:\nClinical implementation - Identify high-risk individuals - Tailor preventive interventions (e.g., lifestyle modification, monitoring) - Quantify uncertainty in predictions for decision-making - Posterior predictive distributions enable probabilistic, individualized predictions, supporting targeted intervention strategies beyond population-level summaries.\n\n\nCode\n# Use the first participant \n# using multiple covariates to select someone\nparticipant1_data  &lt;- adult[1, ]\n\n\n# predicted probabilities for patient 1\nphat1 &lt;- posterior_linpred(bayes_fit, newdata = participant1_data, transform = TRUE)\n# 'transform = TRUE' gives probabilities for logistic regression\n\n# Store in a data frame for plotting\npost_pred_df &lt;- data.frame(pred = phat1)\n\n# Compute 95% credible interval\nci_95_participant1 &lt;- quantile(phat1, c(0.025, 0.975))\n\n# Plot\n\nggplot(post_pred_df, aes(x = pred)) + \n  geom_density(color='darkblue', fill='lightblue') +\n  geom_vline(xintercept = ci_95_participant1[1], color='red', linetype='dashed') +\n  geom_vline(xintercept = ci_95_participant1[2], color='red', linetype='dashed') +\n  xlab('Probability of being diabetic (Outcome=1)') +\n  ggtitle('Posterior Predictive Distribution 95% Credible Interval') +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nPredicting Diabetes Risk for a New Participant - To demonstrate the application of the Bayesian model for personalized prediction, we applied the trained model to a new participant not included in the original dataset.\n\nMethod\n\n\nSelected a new participant with specific covariates (age, BMI, sex, race).\nUsed posterior_linpred with transform = TRUE to compute posterior predicted probabilities of diabetes. Generated posterior draws to capture predictive uncertainty.\n\n\nPosterior Predictive Distribution\n\n\nCreated a density plot of predicted probabilities. Computed 95% credible interval to summarize the range of likely outcomes.\nRed dashed lines indicate the lower and upper bounds of the interval.\n\nInterpretation for Targeted Implementation - The distribution shows not only the most probable risk but also the uncertainty around it. - Credible intervals help quantify confidence in individual-level predictions. - Supports personalized decision-making, such as targeted lifestyle interventions, early monitoring, or preventive care. - Bayesian posterior predictive draws allow probabilistic, individualized predictions for new participants, providing both point estimates and uncertainty measures for actionable risk assessment.\n\n\nCode\nlibrary(ggplot2)\n\n\nnew_participant &lt;- data.frame(\n  age_c = 40,\n  bmi_c = 25,\n  sex   = \"Female\",\n  race  = \"Mexican American\"\n)\n\n# Posterior predicted probabilities\nphat_new &lt;- posterior_linpred(bayes_fit, newdata = new_participant, transform = TRUE)\n\n# Convert to numeric vector\nphat_vec &lt;- as.numeric(phat_new)\n\n# Check the range to see if all values are similar\nrange(phat_vec)\n\n\n[1] 1 1\n\n\nCode\n# Store in a data frame\npost_pred_df_new &lt;- data.frame(pred = phat_vec)\n\n# Compute 95% credible interval from the vector\nci_95_new_participant &lt;- quantile(phat_vec, c(0.025, 0.975))\n\n# Plot\nggplot(post_pred_df_new, aes(x = pred)) + \n  geom_density(color='darkblue', fill='lightblue', alpha = 0.6) +\n  geom_vline(xintercept = ci_95_new_participant[1], color='red', linetype='dashed') +\n  geom_vline(xintercept = ci_95_new_participant[2], color='red', linetype='dashed') +\n  xlim(0, 1) +  # ensures you see the curve even if values are close\n  xlab('Probability of being diabetic (Outcome=1)') +\n  ggtitle('Posterior Predictive Distribution (95% Credible Interval)') +\n  theme_bw()"
  },
  {
    "objectID": "index.html#targeted-bmi",
    "href": "index.html#targeted-bmi",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Targeted bmi",
    "text": "Targeted bmi\nIn this analysis, a grid of body mass index (BMI) values is generated to examine the relationship between BMI and the predicted probability of diabetes while holding other covariates (age, sex, and race) constant. - Using the fitted Bayesian logistic regression model, posterior predictive probabilities computed for each BMI value and the mean of posterior draws estimated the average predicted probability of diabetes across the BMI range. - We then tried to identify the BMI value whose predicted probability was closest to a predefined target probability (here, 0.3). - This enabled interpretation of the model in a clinically meaningful way—specifically, by determining the BMI level associated with a 30% predicted probability of diabetes for a given demographic profile. - We were able to link statistical inference to practical health thresholds relevant for risk communication and prevention strategies in translational research."
  },
  {
    "objectID": "index.html#implications",
    "href": "index.html#implications",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Implications",
    "text": "Implications\n\nage and BMI as robust and independent predictors of diabetes, underscore the importance of early targeted interventions in mitigating diabetes risk.\nLongitudinal studies and combining other statistical analytical methods with Bayesian can further enhance and provide better informed precision prevention strategies."
  },
  {
    "objectID": "About.html",
    "href": "About.html",
    "title": "About",
    "section": "",
    "text": "Contributions\n\nAutumn Wilcox – analytic coding, content draft, structured project workflow, collaborated via GitHub.\nNamita Mishra – analytic coding, content draft, developed project plan, collaborated via GitHub.\n\nDr. Namita Mishra is a physician, a Head and Neck surgeon and a public health researcher with a strong foundation in medicine, epidemiology, and data science. She is a graduate student in Data Science (Health Analytics).\nHer work focuses on early detection and prevention of non-communicable diseases (cancer, obesity) and on health disparities at community level. She has researched salivary gland tumors, cardiac implants and community based research on healthy food access. Leveraging skills from Data Science, she integrates statistical modeling and Bayesian methods into her analyses. Her Bioinformatics expertise utilizes geodata visualization tools (3D Maps and GIS) for presentations.Passionate about bridging clinical insight with data-driven approaches, dedicated to advancing sustainable, evidence-based solutions in epidemiology and community health.\nOutside work she explores - gardening, cooking, singing, and sewing.\n📧 Contact: nmishra@uwf.edu\n\n\n\nAutumn S. Wilcox is a U.S. Navy veteran and Data Science graduate student at the University of West Florida, specializing in Analytics and Modeling. She has over nine years of experience in Network Operations and Technical Writing, including her current role at Navy Federal Credit Union, where she supports enterprise technology and process documentation initiatives. Autumn also holds certification in Clinical Research Quality Management (CRQM) and has contributed to quality oversight and compliance efforts in clinical research settings.\nHer background bridges technology, analytics, and healthcare, with a focus on applying data-driven approaches to improve communication and systems reliability. Outside of work, Autumn enjoys traveling, photography, and finding creative inspiration through music.\n📧 Contact: awr12@students.uwf.edu"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "",
    "text": "Body doesn’t make enough insulin or is not used properly → rise in blood sugar\nAffects organs and can lead to multi-organ failure\nUnderstanding risk factors (age, BMI, genetics) allows early intervention"
  },
  {
    "objectID": "slides.html#type-2-diabetes-t2d-a-public-health-concern-worldwide",
    "href": "slides.html#type-2-diabetes-t2d-a-public-health-concern-worldwide",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "",
    "text": "Body doesn’t make enough insulin or is not used properly → rise in blood sugar\nAffects organs and can lead to multi-organ failure\nUnderstanding risk factors (age, BMI, genetics) allows early intervention"
  },
  {
    "objectID": "slides.html#statistical-problem",
    "href": "slides.html#statistical-problem",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Statistical Problem",
    "text": "Statistical Problem\n\nTraditional statistical approaches fail to analyze complex relationships or uncertainty present in healthcare data\nMissing data in survey-collected datasets reduces sample size and may bias estimates"
  },
  {
    "objectID": "slides.html#study-goal",
    "href": "slides.html#study-goal",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Study Goal",
    "text": "Study Goal\n\nAddress statistical challenges where traditional methods fail\nCompare Frequentist and Bayesian methods on NHANES 2013–2014\nIdentify associations between risk factors and diabetes (dichotomous outcome)\nDemonstrate model performance and insights for healthcare data analysis"
  },
  {
    "objectID": "slides.html#methods",
    "href": "slides.html#methods",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Methods",
    "text": "Methods\n\nExploratory Data Analysis (EDA) of weighted NHANES dataset revealed missing values\nMultivariate linear regression on complete cases resulted in reduced sample size\nMultiple Imputation by Chained Equations (MICE) was applied to handle missing data\nBayesian regression was conducted on imputed data after normalizing age and BMI"
  },
  {
    "objectID": "slides.html#bayesian-regression-principles",
    "href": "slides.html#bayesian-regression-principles",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Bayesian Regression Principles",
    "text": "Bayesian Regression Principles\n\nPriors stabilize estimates and reduce extreme values\nHandles uncertainty fully through posterior distributions\nIncorporates prior knowledge for robust inference\nWorks effectively with imputed datasets"
  },
  {
    "objectID": "slides.html#data-source",
    "href": "slides.html#data-source",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Data Source",
    "text": "Data Source\n\nNHANES 2013–2014 (CDC)\n\nFiles merged: demographics (DEMO_H), exam (BMX_H), questionnaire (DIQ_H)\n\nCleaned dataset: n = 10,175 observations, 10 variables\n\n\n\n\nDataset\nKey variables\nDimensions\n\n\n\n\ndemo1\nage, race, gender\n10175 × 47\n\n\nexam1\nBMI\n9813 × 224\n\n\nquest1\nDiabetes\n9813 × 953"
  },
  {
    "objectID": "slides.html#data-exploration",
    "href": "slides.html#data-exploration",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Data Exploration",
    "text": "Data Exploration\n\nSmall sample for certain BMI subgroups (pre-diabetic n=132/9813)\nOnly 14 complete cases across all variables → imbalance\nSurvey-weighted proportions approximate US population (Male:Female ~48.9%:51%)\nPredictor correlations are hierarchical and complex → suitable for Bayesian modeling"
  },
  {
    "objectID": "slides.html#our-question",
    "href": "slides.html#our-question",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Our Question",
    "text": "Our Question\n\nCan Bayesian logistic regression provide more stable and transparent inference than classical MLE for diabetes outcomes in NHANES 2013–2014?"
  },
  {
    "objectID": "slides.html#data-pipeline-reproducible",
    "href": "slides.html#data-pipeline-reproducible",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "Data Pipeline (Reproducible)",
    "text": "Data Pipeline (Reproducible)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEQN\nRIDAGEYR\nRIAGENDR\nRIDRETH1\nSDMVPSU\nSDMVSTRA\nWTMEC2YR\nBMXBMI\nDIQ010\nDIQ050\n\n\n\n\n73557\n69\n1\n4\n1\n112\n13481.04\n26.7\n1\n1\n\n\n73558\n54\n1\n3\n1\n108\n24471.77\n28.6\n1\n1\n\n\n73559\n72\n1\n3\n1\n109\n57193.29\n28.9\n1\n1\n\n\n73560\n9\n1\n3\n2\n109\n55766.51\n17.1\n2\n2\n\n\n73561\n73\n2\n3\n2\n116\n65541.87\n19.7\n2\n2\n\n\n73562\n56\n1\n1\n1\n111\n25344.99\n41.7\n2\n2\n\n\n\n\n\n\nAdults &gt;20 years filtered: n = 5,769\nStandardized predictors: age_c, bmi_c\nOutcome adjusted for pregnancy when female\nNH White set as reference level for race\n\n```"
  },
  {
    "objectID": "slides.html#references",
    "href": "slides.html#references",
    "title": "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "index.html#data-source",
    "href": "index.html#data-source",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Data source",
    "text": "Data source\n\nNHANES 2-year data (2013-2014) - a cross-sectional weighted data (CenterforHealthStatistics199?) was imported in R"
  },
  {
    "objectID": "index.html#exploratory-analysis-of-adult-dataset-20-years",
    "href": "index.html#exploratory-analysis-of-adult-dataset-20-years",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Exploratory Analysis of Adult dataset (> 20 years)",
    "text": "Exploratory Analysis of Adult dataset (&gt; 20 years)\nObservations - 5769 observations Survey design: SDMVPSU, SDMVSTRA, WTMEC2YR Outcome: diabetes_dx (numeric 0/1) Covariates: bmi, age, sex, race, DIQ050 Centered covariates: age_c, bmi_c BMI categories: bmi_cat\nNHANES is a national surveys based on complex sampling designs (oversampling certain groups (e.g., minorities, older adults) to ensure representation. They use multistage sampling to represent the U.S. population, so we apply sampling weights, strata, and PSU (primary sampling units) for valid estimates.\nWe use survey design in regression anlaysis to avoid - - bias prevalence estimates (e.g., mean BMI or diabetes %) - underestimation of standard errors - incorrect inference for population-level parameters.\n\n\nCode\n# data exploration\n\nprint(table(adult$diabetes_dx, useNA = \"ifany\"))\n\n\n\n   0    1 &lt;NA&gt; \n4974  618  177 \n\n\nCode\nprint(table(adult$sex, useNA = \"ifany\"))\n\n\n\n  Male Female \n  2758   3011 \n\n\nCode\nprint(table(adult$race, useNA = \"ifany\"))\n\n\n\n        NH White Mexican American   Other Hispanic         NH Black \n            2472              767              508             1177 \n     Other/Multi \n             845 \n\n\nCode\nif (sum(!is.na(adult$diabetes_dx)) == 0) {\n  stop(\"Too few non-missing outcomes for modeling (n = 0). Check DIQ010 upstream.\")\n}\n\n# (optional plots omitted for brevity)\n\n# save for downstream\nif (!dir.exists(\"data\")) dir.create(\"data\", recursive = TRUE)\nsaveRDS(adult, \"data/adult_cleaned_2013_2014.rds\")\n\n\n\n\nCode\nggplot(adult, aes(x = age)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Age &gt;20 years\",\n    x = \"Age (years)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution in &gt;20 years age group\", x=\"diabetes_dx (0=No, 1=Yes)\", y=\"Count\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(bmi_cat))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution by BMI in &gt;20 years age group\", x=\"bmi_cat\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(diabetes_dx), y = bmi)) +\n  geom_boxplot(fill = \"skyblue\") +\n  labs(\n    title = \"BMI Distribution by Diabetes Diagnosis in &gt;20 years age group\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\n# plots for adult data bmi categories and race categories\n\nggplot(adult, aes(x = factor(race), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by Race in &gt;20 years age group\",\n    x = \"Race/Ethnicity\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(bmi_cat), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by BMI in &gt;20 years age group\",\n    x = \"BMI\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nExploratory data analysis results to understand the distributions, relationships, and patterns of the before modeling\n\nDetects skewness, outliers, and general age patterns.\nGives baseline prevalence in your dataset. - counts of BMI categories.\nCompares BMI across diabetes diagnosis (0 vs 1), to identify patterns whether diabetic patients have higher BMI.\nCounts diabetes cases across race/ethnicity, to check disparities in diabetes prevalence by race."
  },
  {
    "objectID": "index.html#data-pre-processing",
    "href": "index.html#data-pre-processing",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Data pre-processing",
    "text": "Data pre-processing\nThree datasets (demographics, exam, questionnaire in.XPT format files are imported (Haven package) in R. After selecting variables of interest, a merged dataset is created from the original weighted datasets (demographics, exam, questionnaire) and merged using ID to create a single merged dataframe.\n\nMerged dataset\n\n\nResponse Variable: Binary - Type 2 / diagnosed diabetes(excluding gestational diabetes) -“Doctor told you have diabetes?” DIQ010 combined with DIQ050 a secondary variable describing treatment status (insulin use) to exclude those cases.\nPredictor Variables Body Mass Index, factor, 4 levels (underweight (&lt;5th percentile)\no Normal (5th–&lt;85th)\no Overweight (85th–&lt;95th) o Obese (≥95th percentile)). Missing data are kept as it is as categorization provides clinically interpretable groups. Covariates included are Gender (factor, 2 levels): Male: Female, Ethnicity (factor, 5 levels): Mexican American, Non-Hispanic, White Non-Hispanic, Black Other Hispanic, Other Race - Including multi-racial and Age (number, continuous).\n\n\nAdult dataset\n\n\nWe filtered and analyzed population that included &gt; 20 years of age group forming an Adult dataset (presented below are the variables and the summary statistics of the Adult dataset)."
  },
  {
    "objectID": "index.html#data-preparation-population-for-analysis---adults-20-years",
    "href": "index.html#data-preparation-population-for-analysis---adults-20-years",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Data preparation (population for analysis - Adults >20 years)",
    "text": "Data preparation (population for analysis - Adults &gt;20 years)\n\nUsing library(survey) we calculated weighted means and standard deviation of all the variables.\nThe BMI and age were standardized.\nAge categorize, recoded into different variables to include (20-80 years)\nBMI is recoded and categorized as-“18.5,18.5–&lt;25,25–&lt;30,30–&lt;35,35–&lt;40,≥40 years).\nEthnicity is recoded as “Mexican American” = “1”, “Other Hispanic” = “2”, “NH White” = “3”, “NH Black” = “4”, “Other/Multi” = “5”\nSpecial codes are not random, cannot be dropped; the informative missingness if ignored (MAR or MNAR) could introduce bias.\nWe transformed special codes (3,7,) to NA and included all NAs in the analysis. Visualization of missing data is presented below.\nA final analytic dataset created (‘adult’) with “NH White” and “Male” as the reference group for analysis\n\n\n\nCode\n## \n# ---------------- Basic Exploration (adults) ----------------\n\n# Keep adults only and build analysis variables\nadult &lt;- merged_data %&gt;%\n  dplyr::filter(RIDAGEYR &gt;= 20) %&gt;%\n  dplyr::transmute(\n    # --- keep survey design variables so svydesign() can see them ---\n    SDMVPSU, SDMVSTRA, WTMEC2YR,\n\n    # --- outcome: DIQ010 (1 yes, 2 no; 3/7/9 -&gt; NA) ---\n    diabetes_dx = dplyr::case_when(\n      DIQ010 == 1 ~ 1,\n      DIQ010 == 2 ~ 0,\n      DIQ010 %in% c(3, 7, 9) ~ NA_real_,\n      TRUE ~ NA_real_\n    ),\n\n    # --- predictors (raw) ---\n    bmi  = BMXBMI,\n    age  = RIDAGEYR,\n\n    # sex (1=Male, 2=Female)\n    sex  = forcats::fct_recode(factor(RIAGENDR), Male = \"1\", Female = \"2\"),\n\n    # race (5-level)\n    race = forcats::fct_recode(\n      factor(RIDRETH1),\n      \"Mexican American\" = \"1\",\n      \"Other Hispanic\"   = \"2\",\n      \"NH White\"         = \"3\",\n      \"NH Black\"         = \"4\",\n      \"Other/Multi\"      = \"5\"\n    ),\n\n    # keep DIQ050 so we can safely reference it (may be absent/NA in some rows)\n    \n    DIQ050 = DIQ050\n  ) %&gt;%\n  # standardize continuous predictors\n  dplyr::mutate(\n    age_c = as.numeric(scale(age)),\n    bmi_c = as.numeric(scale(bmi)),\n    bmi_cat = cut(\n      bmi,\n      breaks = c(-Inf, 18.5, 25, 30, 35, 40, Inf),\n      labels = c(\"&lt;18.5\",\"18.5–&lt;25\",\"25–&lt;30\",\"30–&lt;35\",\"35–&lt;40\",\"≥40\"),\n      right = FALSE\n    )\n  ) %&gt;%\n  # adjust outcome: if female & DIQ050==1 (\"only when pregnant\"), set to 0 (not diabetes)\n  dplyr::mutate(\n    diabetes_dx = ifelse(sex == \"Female\" & !is.na(DIQ050) & DIQ050 == 1, 0, diabetes_dx)\n  )\n\n# Make NH White the reference level for race (clearer interpretation)\nadult &lt;- adult %&gt;%\n  dplyr::mutate(\n    race = forcats::fct_relevel(race, \"NH White\")\n  )\n\n# --- sanity checks ---\ncat(\"Adults n =\", nrow(adult), \"\\n\")\n\n\nAdults n = 5769 \n\n\nAdult dataset is cleaned for exploratory data analysis to present visualizations for 10175 observations and 10 variables after exploratory analysis on ethnicity (5 levels), age range (20-80 years), gender (male and female), BMI as continuous and Diabetes grouped from (DIQ010 excluding DIQ050).\n\n\n  Variable                                                            Label\n1  SDMVPSU                                      Primary Sampling Unit (PSU)\n2 SDMVSTRA                                  Stratum for variance estimation\n3 WTMEC2YR                               Full sample 2-year MEC exam weight\n4      bmi                                          Body Mass Index (kg/m²)\n5      age                                        Age in years at screening\n6      sex                        Sex of participant (1 = Male, 2 = Female)\n7     race                                                   Race/Ethnicity\n8   DIQ050 Doctor told you have diabetes? (1 = Yes, 2 = No, 3 = Borderline)\n9   DIQ010           Ever told you have prediabetes or borderline diabetes?\n         Type\n1     Integer\n2     Integer\n3     Numeric\n4     Numeric\n5     Numeric\n6 Categorical\n7 Categorical\n8 Categorical\n9 Categorical"
  },
  {
    "objectID": "index.html#visulaization-and-exploratory-data-analysis-adults-20---80-years",
    "href": "index.html#visulaization-and-exploratory-data-analysis-adults-20---80-years",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Visulaization and Exploratory Data Analysis (Adults, 20 - 80 years)",
    "text": "Visulaization and Exploratory Data Analysis (Adults, 20 - 80 years)\nPresented below is the table od Adult dataset (n = 5769) after cleaning and analysis to present visualizations Variables include - ethnicity (5 levels), age range (20-80 years), gender (male and female), BMI as continuous and Diabetes grouped from (DIQ010 excluding DIQ050).\n\n\n  Variable                                                            Label\n1  SDMVPSU                                      Primary Sampling Unit (PSU)\n2 SDMVSTRA                                  Stratum for variance estimation\n3 WTMEC2YR                               Full sample 2-year MEC exam weight\n4      bmi                                          Body Mass Index (kg/m²)\n5      age                                        Age in years at screening\n6      sex                        Sex of participant (1 = Male, 2 = Female)\n7     race                                                   Race/Ethnicity\n8   DIQ050 Doctor told you have diabetes? (1 = Yes, 2 = No, 3 = Borderline)\n9   DIQ010           Ever told you have prediabetes or borderline diabetes?\n         Type\n1     Integer\n2     Integer\n3     Numeric\n4     Numeric\n5     Numeric\n6 Categorical\n7 Categorical\n8 Categorical\n9 Categorical\n\n\n\n\nCode\n# weighted means of each variable                       \n\nlibrary(dplyr)\nlibrary(skimr)\nlibrary(knitr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(forcats)\nlibrary(kableExtra)\n\nstr(adult)\n\n\n'data.frame':   5769 obs. of  12 variables:\n $ SDMVPSU    : num  1 1 1 2 1 1 2 1 2 2 ...\n $ SDMVSTRA   : num  112 108 109 116 111 114 106 112 112 113 ...\n $ WTMEC2YR   : num  13481 24472 57193 65542 25345 ...\n $ diabetes_dx: num  1 1 1 0 0 0 0 0 0 0 ...\n $ bmi        : num  26.7 28.6 28.9 19.7 41.7 35.7 NA 26.5 22 20.3 ...\n $ age        : num  69 54 72 73 56 61 42 56 65 26 ...\n $ sex        : Factor w/ 2 levels \"Male\",\"Female\": 1 1 1 2 1 2 1 2 1 2 ...\n $ race       : Factor w/ 5 levels \"NH White\",\"Mexican American\",..: 4 1 1 1 2 1 3 1 1 1 ...\n $ DIQ050     : num  1 1 1 2 2 2 2 2 2 2 ...\n $ age_c      : num  1.132 0.278 1.303 1.36 0.392 ...\n $ bmi_c      : num  -0.3359 -0.0703 -0.0283 -1.3144 1.761 ...\n $ bmi_cat    : Factor w/ 6 levels \"&lt;18.5\",\"18.5–&lt;25\",..: 3 3 3 2 6 5 NA 3 2 2 ...\n\n\nCode\nplot_str(adult)\nhead(adult)\n\n\n  SDMVPSU SDMVSTRA WTMEC2YR diabetes_dx  bmi age    sex             race DIQ050\n1       1      112 13481.04           1 26.7  69   Male         NH Black      1\n2       1      108 24471.77           1 28.6  54   Male         NH White      1\n3       1      109 57193.29           1 28.9  72   Male         NH White      1\n4       2      116 65541.87           0 19.7  73 Female         NH White      2\n5       1      111 25344.99           0 41.7  56   Male Mexican American      2\n6       1      114 61758.65           0 35.7  61 Female         NH White      2\n      age_c       bmi_c  bmi_cat\n1 1.1324183 -0.33588609   25–&lt;30\n2 0.2783598 -0.07028101   25–&lt;30\n3 1.3032300 -0.02834336   25–&lt;30\n4 1.3601672 -1.31443114 18.5–&lt;25\n5 0.3922343  1.76099614      ≥40\n6 0.6769204  0.92224325   35–&lt;40\n\n\nCode\nplot_intro(adult, title=\"Figure 1 (Adult dataset). Structure of variables and missing observations.\")\n\n\n\n\n\n\n\n\n\nCode\nplot_missing(adult, title=\"Figure 2(Adult dataset). Breakdown of missing observations.\")\n\n\n\n\n\n\n\n\n\nNHANES dataset for analysis: - we have 5769 observations - It is is a national surveys based on complex sampling designs (oversampling certain groups (e.g., minorities, older adults) to ensure representation. - They use multistage sampling to represent the U.S. population, so we apply sampling weights, strata, and PSU (primary sampling units) for valid estimates.\nSurvey design: - We use survey design in regression anlaysis to avoid to avoid bias prevalence estimates (e.g., mean BMI or diabetes %), underestimation of standard errors and incorrect inference for population-level parameters. -It inlcudes auxillary variables: SDMVPSU, SDMVSTRA, WTMEC2YR - Outcome: diabetes_dx (numeric 0/1) Covariates: bmi, age, sex, race, DIQ050 Centered covariates: age_c, bmi_c BMI categories: bmi_cat\n\n\n      mean     SE\nage 47.496 0.3805\n\n\n                mean     SE\ndiabetes_dx 0.089016 0.0048\n\n\n            variance     SE\ndiabetes_dx   4759.9 0.0039\n\n\nEffective sample size for diabetes_dx: 48142 \n\n\nResults from Adult dataset\n- mean, SE and vairance for age, diabetes_dx mean SE age 47.496 0.3805 diabetes_dx 0.089016 0.0048 variance SE diabetes_dx 4759.9 0.0039 Effective sample size for diabetes_dx: 48142\n\nBelow are histogram, bar graph, boxplot that display age, bmi and their association with diabetes status.\n\n\n\nCode\nggplot(adult, aes(x = age)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Age &gt;20 years\",\n    x = \"Age (years)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution in &gt;20 years age group\", x=\"diabetes_dx (0=No, 1=Yes)\", y=\"Count\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(bmi_cat))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution by BMI in &gt;20 years age group\", x=\"bmi_cat\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(diabetes_dx), y = bmi)) +\n  geom_boxplot(fill = \"skyblue\") +\n  labs(\n    title = \"BMI Distribution by Diabetes Diagnosis in &gt;20 years age group\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\n# plots for adult data bmi categories and race categories\n\nggplot(adult, aes(x = factor(race), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by Race in &gt;20 years age group\",\n    x = \"Race/Ethnicity\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(bmi_cat), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by BMI in &gt;20 years age group\",\n    x = \"BMI\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "index.html#analytic-data-adults-20-years",
    "href": "index.html#analytic-data-adults-20-years",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Analytic Data (Adults >20 years)",
    "text": "Analytic Data (Adults &gt;20 years)\n\nAnalytic Data (Adults &gt; 20 years)\n\n\n\n\n\n\n\nStep\nDescription\n\n\n\n\nWeighting\nUsed the survey package to calculate weighted means and standard deviations for all variables.\n\n\nStandardization\nStandardized BMI and age variables for analysis.\n\n\nAge Categorization\nRecoded into intervals: 20–&lt;30, 30–&lt;40, 40–&lt;50, 50–&lt;60, 60–&lt;70, and 70–80 years.\n\n\nBMI Categorization\nRecoded and categorized as: &lt;18.5 (Underweight), 18.5–&lt;25 (Normal), 25–&lt;30 (Overweight), 30–&lt;35 (Obesity I), 35–&lt;40 (Obesity II), ≥40 (Obesity III).\n\n\nEthnicity Recoding\nRecoded as: 1 = Mexican American, 2 = Other Hispanic, 3 = Non-Hispanic White, 4 = Non-Hispanic Black, 5 = Other/Multi.\n\n\nSpecial Codes\nSpecial codes (e.g., 3, 7) were transformed to NA. These codes are not random and could introduce bias if ignored (MAR or MNAR).\n\n\nMissing Data\nMissing values were retained and visualized to assess their pattern and informativeness.\n\n\nFinal Dataset\nCreated a cleaned analytic dataset (adult) using Non-Hispanic White and Male as reference groups for analysis.\n\n\n\n\n\nCode\n## \n# ---------------- Basic Exploration (adults) ----------------\n\n# Keep adults only and build analysis variables\nadult &lt;- merged_data %&gt;%\n  dplyr::filter(RIDAGEYR &gt;= 20) %&gt;%\n  dplyr::transmute(\n    # --- keep survey design variables so svydesign() can see them ---\n    SDMVPSU, SDMVSTRA, WTMEC2YR,\n\n    # --- outcome: DIQ010 (1 yes, 2 no; 3/7/9 -&gt; NA) ---\n    diabetes_dx = dplyr::case_when(\n      DIQ010 == 1 ~ 1,\n      DIQ010 == 2 ~ 0,\n      DIQ010 %in% c(3, 7, 9) ~ NA_real_,\n      TRUE ~ NA_real_\n    ),\n\n    # --- predictors (raw) ---\n    bmi  = BMXBMI,\n    age  = RIDAGEYR,\n\n    # sex (1=Male, 2=Female)\n    sex  = forcats::fct_recode(factor(RIAGENDR), Male = \"1\", Female = \"2\"),\n\n    # race (5-level)\n    race = forcats::fct_recode(\n      factor(RIDRETH1),\n      \"Mexican American\" = \"1\",\n      \"Other Hispanic\"   = \"2\",\n      \"NH White\"         = \"3\",\n      \"NH Black\"         = \"4\",\n      \"Other/Multi\"      = \"5\"\n    ),\n\n    # keep DIQ050 so we can safely reference it (may be absent/NA in some rows)\n    \n    DIQ050 = DIQ050\n  ) %&gt;%\n  # standardize continuous predictors\n  dplyr::mutate(\n    age_c = as.numeric(scale(age)),\n    bmi_c = as.numeric(scale(bmi)),\n    bmi_cat = cut(\n      bmi,\n      breaks = c(-Inf, 18.5, 25, 30, 35, 40, Inf),\n      labels = c(\"&lt;18.5\",\"18.5–&lt;25\",\"25–&lt;30\",\"30–&lt;35\",\"35–&lt;40\",\"≥40\"),\n      right = FALSE\n    )\n  ) %&gt;%\n  # adjust outcome: if female & DIQ050==1 (\"only when pregnant\"), set to 0 (not diabetes)\n  dplyr::mutate(\n    diabetes_dx = ifelse(sex == \"Female\" & !is.na(DIQ050) & DIQ050 == 1, 0, diabetes_dx)\n  )\n\n# Make NH White the reference level for race (clearer interpretation)\nadult &lt;- adult %&gt;%\n  dplyr::mutate(\n    race = forcats::fct_relevel(race, \"NH White\")\n  )\n\n# --- sanity checks ---\ncat(\"Adults n =\", nrow(adult), \"\\n\")\n\n\nAdults n = 5769"
  },
  {
    "objectID": "index.html#abnormalities-detected-in-adult-analytic-dataset",
    "href": "index.html#abnormalities-detected-in-adult-analytic-dataset",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Abnormalities detected in Adult analytic dataset",
    "text": "Abnormalities detected in Adult analytic dataset\n\nMissingness and MICE\n\nOnly 1.3% of individual data points are missing across the dataset, reflecting minimal missingness.\nNo column is entirely missing (0%), indicating all variables have at least some observed data.\nOverall missingness: ~4% → low, but non-trivial given the small number of variables involved.\nMissingness is not completely at random (MNAR or MAR) - If the probability of missingness depends on other observed variables (e.g., older adults missing BMI due to illness), imputation helps reduce bias. It is possible and should consider MICE and test with logistic regression of missingness indicators\nMissingness affects outcome or key covariates - Even small missingness in important variables can bias posterior estimates. Since BMI and diabetes are central we should perform MICE\nSufficient auxiliary variables available - MICE works best when you have other correlated variables to inform imputation (e.g., age, sex, race, WTMEC2YR).\n\nBayesian model assumes complete data - Standard Bayesian logistic models (e.g., brms, rstanarm) cannot directly handle NAs — you must impute or model missingness."
  },
  {
    "objectID": "index.html#comaprison-of-prior-and-predicted-draws-for-both-age-and-bmi",
    "href": "index.html#comaprison-of-prior-and-predicted-draws-for-both-age-and-bmi",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Comaprison of Prior and Predicted draws for both Age and BMI",
    "text": "Comaprison of Prior and Predicted draws for both Age and BMI\n\nPlot shows the posterior distributions are much more concentrated around ~0.5 (example) than the priors indicating the data provided strong evidence about the effect size of these covariates.\nThe priors were diffuse, showing initial uncertainty\nThe posteriors are precise, showing learning from the data."
  },
  {
    "objectID": "index.html#posterior-predicted-proportion-of-diabetes-vs-nhanes-prevalence-of-diabetes-in-the-population",
    "href": "index.html#posterior-predicted-proportion-of-diabetes-vs-nhanes-prevalence-of-diabetes-in-the-population",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Posterior predicted proportion of Diabetes vs NHANES prevalence of Diabetes in the population",
    "text": "Posterior predicted proportion of Diabetes vs NHANES prevalence of Diabetes in the population\n\n\nCode\nlibrary(tidyverse)\n\n# Posterior predicted proportion vector\n# pp_proportion &lt;- rowMeans(pp_samples)  # if not already done\n\nknown_prev &lt;- 0.089   # NHANES prevalence\n\n# Posterior summary\nposterior_mean &lt;- mean(pp_proportion)\nposterior_ci &lt;- quantile(pp_proportion, c(0.025, 0.975))  # 95% credible interval\n\n# Create a data frame for plotting\npp_df &lt;- tibble(proportion = pp_proportion)\n\n# Plot\nggplot(pp_df, aes(x = proportion)) +\n  geom_histogram(binwidth = 0.005, fill = \"skyblue\", color = \"black\") +\n  geom_vline(xintercept = known_prev, color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = posterior_mean, color = \"blue\", linetype = \"solid\", size = 1) +\n  geom_rect(aes(xmin = posterior_ci[1], xmax = posterior_ci[2], ymin = 0, ymax = Inf),\n            fill = \"blue\", alpha = 0.1, inherit.aes = FALSE) +\n  labs(\n    title = \"Posterior Predicted Diabetes Proportion vs NHANES Prevalence\",\n    subtitle = paste0(\"Red dashed = NHANES prevalence (\", known_prev, \n                      \"), Blue solid = Posterior mean (\", round(posterior_mean,3), \")\"),\n    x = \"Proportion of Diabetes = 1\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nPosterior Predicted Diabetes Proportion vs Observed Prevalence\nTo evaluate the Bayesian model’s predictive accuracy for diabetes prevalence, we compared the posterior predicted proportion of diabetes cases to the known NHANES prevalence:\n\nPosterior Predictions - Calculated the proportion of diabetes = 1 for each posterior draw (pp_proportion). Derived posterior mean and 95% credible interval to summarize predictive uncertainty.\nVisualization - Histogram of posterior predicted proportions illustrates the variability in model predictions.\n\nRed dashed line: NHANES observed prevalence (0.089). Blue solid line: Posterior mean predicted prevalence. Shaded blue region: 95% credible interval around the posterior mean.\nInterpretation - Close alignment of the posterior mean and credible interval with the observed NHANES prevalence indicates that the model accurately captures the population-level prevalence of diabetes. - This visualization complements prior vs posterior and predicted vs observed checks, supporting overall model validity.\n\n\nCode\nlibrary(dplyr)\n\n# Posterior predicted proportion\n\nposterior_mean &lt;- mean(pp_proportion)\nposterior_ci &lt;- quantile(pp_proportion, c(0.025, 0.975))  # 95% credible interval\n\n# NHANES prevalence with SE from survey::svymean\n# Suppose you already have:\n# svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)\nknown_prev &lt;- 0.089        # Mean prevalence\nknown_se   &lt;- 0.0048       # Standard error from survey\n\n# Calculate 95% confidence interval\nknown_ci &lt;- c(\n  known_prev - 1.96 * known_se,\n  known_prev + 1.96 * known_se\n)\n\n# Print results\ndata.frame(\n  Type = c(\"Posterior Prediction\", \"NHANES Prevalence\"),\n  Mean = c(posterior_mean, known_prev),\n  Lower_95 = c(posterior_ci[1], known_ci[1]),\n  Upper_95 = c(posterior_ci[2], known_ci[2])\n)\n\n\n                     Type      Mean   Lower_95  Upper_95\n2.5% Posterior Prediction 0.1094142 0.09861856 0.1213385\n        NHANES Prevalence 0.0890000 0.07959200 0.0984080\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Create a data frame for plotting\nci_df &lt;- data.frame(\n  Type = c(\"Posterior Prediction\", \"NHANES Prevalence\"),\n  Mean = c(0.1096674, 0.089),\n  Lower_95 = c(0.09772443, 0.079592),\n  Upper_95 = c(0.1210658, 0.098408)\n)\n\n# Plot\nggplot(ci_df, aes(x = Type, y = Mean, color = Type)) +\n  geom_point(size = 4) +\n  geom_errorbar(aes(ymin = Lower_95, ymax = Upper_95), width = 0.2) +\n  ylim(0, max(ci_df$Upper_95) + 0.02) +\n  labs(\n    title = \"Comparison of Posterior Predicted Diabetes Proportion vs NHANES Prevalence\",\n    y = \"Proportion of Diabetes\",\n    x = \"\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\n# --- Load libraries ---\nlibrary(survey)\nlibrary(tibble)\nlibrary(ggplot2)\n\n# --- 1. Survey-weighted (Population) prevalence ---\npop_est &lt;- svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)\npop_prev &lt;- as.numeric(pop_est)\npop_se &lt;- as.numeric(SE(pop_est))\npop_ci &lt;- c(pop_prev - 1.96 * pop_se, pop_prev + 1.96 * pop_se)\n\n# --- 2. Bayesian posterior prevalence ---\n# bayes_pred = matrix of posterior draws (iterations × individuals)\npp_proportion &lt;- rowMeans(pp_samples)             # prevalence per posterior draw\npost_prev &lt;- mean(pp_proportion)                  # posterior mean prevalence\npost_ci &lt;- quantile(pp_proportion, c(0.025, 0.975))  # 95% credible interval\n\n# --- 3. Combine into one data frame ---\nbar_df &lt;- tibble(\n  Source     = c(\"Survey-weighted (Population)\", \"Bayesian Posterior\"),\n  Prevalence = c(pop_prev, post_prev),\n  CI_low     = c(pop_ci[1], post_ci[1]),\n  CI_high    = c(pop_ci[2], post_ci[2])\n)\n\n# --- 4. Plot ---\nggplot(bar_df, aes(x = Source, y = Prevalence, fill = Source)) +\n  geom_col(alpha = 0.85, width = 0.6) +\n  geom_errorbar(\n    aes(ymin = CI_low, ymax = CI_high),\n    width = 0.15,\n    color = \"black\",\n    linewidth = 0.8\n  ) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Population vs Posterior Diabetes Prevalence\",\n    subtitle = \"Survey-weighted estimate (design-based) vs Bayesian (model-based)\",\n    y = \"Prevalence (Proportion with Diabetes)\",\n    x = NULL\n  ) +\n  theme_minimal(base_size = 13)\n\n\n\n\n\n\n\n\n\nComparison of Posterior Predicted Diabetes Prevalence vs Population Estimates\nTo assess the Bayesian model’s accuracy at the population level, we compared the posterior predicted diabetes prevalence to the survey-weighted NHANES prevalence.\n\nSurvey-Weighted (Population) Prevalence\n\n\nCalculated using svymean(~diabetes_dx, nhanes_design_adult).\nProvided a mean prevalence and 95% confidence interval accounting for survey design.\nMean = 0.089, SE = 0.0048 → 95% CI = 0.080–0.098.\n\n\nBayesian Posterior Predicted Prevalence\n\n\nComputed from posterior draws (pp_samples) as the proportion of diabetes cases per draw.\nSummarized by posterior mean and 95% credible interval.\nPosterior mean = 0.110, 95% CrI = 0.098–0.121.\n\n\nVisualization\n\n\nBar plot comparing population vs posterior prevalence.\nError bars: 95% CI (survey) or 95% credible interval (Bayesian).\nSubplots/alternative plots show points and intervals for direct comparison.\n\nInterpretation - Posterior mean slightly higher than survey-weighted prevalence but largely overlaps with the population 95% CI. - Indicates that the Bayesian model reliably reproduces population-level diabetes prevalence, supporting both predictive accuracy and model validity.\n\nSurvey-Weighted Prevalence (8.9%)\n\nRepresentative estimate of diabetes prevalence in the population, as it adjusts for NHANES’ complex sampling design. It’s slightly lower because survey weights give less influence to overrepresented groups (e.g., those with higher diabetes prevalence).\n\n\n\nImputed (Unweighted) Prevalence (11.1%)\n\nReflects the diabetes proportion from the imputed dataset. It’s unweighted, it doesn’t correct for sampling bias, so it might overrepresent some subgroups (e.g., older or overweight participants).\n\n\n\nPosterior Predictive Mean (10.9%)\n\nBayesian model replicates the imputed data mean, suggesting good model calibration.\nThe model “learned” the sample pattern correctly — no over- or underestimation relative to the data.\nit’s close to the imputed value but slightly below it shows the posterior distribution pulled toward the population-level mean, consistent with Bayesian shrinkage.\n\n\n\nSummarizing\nImputed (11.1%) ≈ Posterior Predictive (10.9%) &gt; Survey-Weighted (8.9%). The posterior predictive estimate sits between the two — balancing sample data and uncertainty.\nComparison result - Survey-weighted (NHANES) 0.089 (0.0796, 0.0984) - Bayesian Posterior 0.110 (0.098, 0.121) - The Bayesian estimate isslightly higher than the survey-based one. - This could indicate that the Bayesian model (after adjusting for predictors) predicts more undiagnosed or latent diabetes risk than captured by self-reports or current screening. It suggests potential under-detection in the survey population — prompting more active screening in certain subgroups\nImplications - Health departments can estimate diabetes burden at the state or county level using Bayesian small-area estimation. - Clinicians and public health researchers can plan targeted screening where predicted prevalence is higher than observed. - Epidemiologists can validate disease models before applying them to regions without survey data."
  },
  {
    "objectID": "index.html#mcmc-autocorrelation-for-key-parameters",
    "href": "index.html#mcmc-autocorrelation-for-key-parameters",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "MCMC Autocorrelation for Key Parameters",
    "text": "MCMC Autocorrelation for Key Parameters\n\nTo evaluate the independence of posterior samples and ensure reliable Bayesian inference, we examined autocorrelation of MCMC chains for key predictors: age and BMI.\nExtracted MCMC draws from the fitted model (bayes_fit) as a draws array (as_draws_array).\nPlotted autocorrelation functions (mcmc_acf) for b_age_c and b_bmi_c.\n\nInterpretation - Autocorrelation plots show how each MCMC sample is related to previous iterations. - Low autocorrelation (quick decay to zero) indicates good chain mixing and independent samples. - High autocorrelation suggests slower mixing and may require more iterations or tuning.\n\nOutcome\n\n\nVisual inspection of autocorrelation for age and BMI confirms adequate independence of posterior draws, supporting the reliability of parameter estimates and subsequent inference.\nbayes_fit is the fitted Bayesian model (brms or rstanarm).\nas_draws_array() converts the posterior samples into a 3-dimensional array (iterations × chains × parameters). If we ran 4 chains with 2000 iterations each, and your model has 5 parameters, the array shape will be (2000, 4, 5).\nmcmc_acf() - produces autocorrelation plots for the posterior samples of specified parameters (b_age_c and b_bmi). Autocorrelation measures how correlated a sample is with previous samples in the Markov Chain and checks the quality of MCMC sampling:\n\nHigh autocorrelation → the chain moves slowly and is not exploring the posterior efficiently.\nLow autocorrelation → the chain is mixing well (as in the model)."
  },
  {
    "objectID": "index.html#targeted-bmi-analysis-for-predicted-diabetes-risk",
    "href": "index.html#targeted-bmi-analysis-for-predicted-diabetes-risk",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Targeted BMI Analysis for Predicted Diabetes Risk",
    "text": "Targeted BMI Analysis for Predicted Diabetes Risk\nThis analysis examines the relationship between BMI and the predicted probability of diabetes, holding other covariates (age, sex, race) constant, using the fitted Bayesian logistic regression model.\n\nGenerated a grid of BMI values (e.g., 18–40 kg/m²) for a specific demographic profile:\n\nAge = 40 Sex = Female Race = Mexican American Computed posterior predicted probabilities of diabetes for each BMI value. Averaged across posterior draws to obtain the mean predicted probability per BMI.\n\nTarget Probability Approach Defined a target probability of diabetes (e.g., 0.3). Identified the BMI value whose predicted probability is closest to the target. This enables inverse prediction, linking statistical inference to clinically meaningful thresholds.\nVisualization Line plot of predicted probability vs BMI. Red dashed horizontal line: target probability (0.3). Red dotted vertical line: BMI corresponding to the target probability (~closest BMI). Annotated to highlight the BMI threshold.\nInterpretation Provides a practical guideline: the BMI at which an individual with a given profile reaches a predefined diabetes risk. Supports personalized risk communication and preventive interventions. Translates model output into actionable, clinically relevant thresholds, bridging research findings with public health application. This approach demonstrates how Bayesian posterior predictions can be used for targeted, individualized risk assessment, informing precision prevention strategies based on modifiable risk factors like BMI."
  },
  {
    "objectID": "index.html#following-heading-cover-summary-and-diagnostics-for-bayesian-logictic-regression",
    "href": "index.html#following-heading-cover-summary-and-diagnostics-for-bayesian-logictic-regression",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Following heading cover summary and diagnostics for Bayesian Logictic Regression",
    "text": "Following heading cover summary and diagnostics for Bayesian Logictic Regression\n\nPosterior Predictive Probabilities - Posterior Mean, Median, credible Intervals\nPosterior Probability (Outcome=1) Comparison with External Prevalence (population prevalence)\nPosterior Model Fit Metrics - Prior versus Posterior Coefficient Distributions\nPosterior Predictive Checks - for Uncertainty Quantification\nTrace Plots for Markov Chain Monte Carlo Convergence\nPosterior Predictive Checks\nResidual Analysis\nPrior Sensitivity Analysis\nModel Fit Assessment\nPosterior Predictive Probability Plots\nPosterior Interval Coverage Evaluation\nConvergence Diagnostics across Chains"
  },
  {
    "objectID": "index.html#data-summary-and-abnormalities-detected-in-adult-analytic-dataset",
    "href": "index.html#data-summary-and-abnormalities-detected-in-adult-analytic-dataset",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Data summary and abnormalities detected in Adult analytic dataset",
    "text": "Data summary and abnormalities detected in Adult analytic dataset\n\nAge: Participants are fairly evenly distributed across adult age groups, with no sharp skewness.\nSex: The sample includes a higher proportion of females than males.\nBMI: Most participants have BMI values within the normal to overweight range, with fewer in the obese category.\nBMI by Diabetes Status: Individuals diagnosed with diabetes tend to have higher BMI values compared to non-diabetics.\nDiabetes Prevalence by Age Group: The proportion of diabetes increases with advancing age, highlighting age as a strong risk factor.\nDiabetes Prevalence by Race/Ethnicity: Differences are observed across racial/ethnic groups, with some showing higher prevalence rates than others.\nMissing Data Overview\nDiscrete vs Continuous Columns: 25% of columns are discrete (categorical) while 75% are continuous, indicating that the dataset primarily contains continuous measurements such as age and BMI.\nMissing Columns: No column is entirely missing (0%), indicating all variables have at least some observed data.\nComplete Rows: 92.7% of rows have complete information for all variables, meaning most participants have fully observed data across predictors and outcomes.\nMissing Observations: Only 1.3% of individual data points are missing across the dataset, reflecting minimal missingness."
  },
  {
    "objectID": "index.html#model-structure",
    "href": "index.html#model-structure",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Model Structure",
    "text": "Model Structure\n\nBayesian logistic regression is a probabilistic modeling framework used to estimate the relationship between one or more predictors (continuous or categorical) and a binary outcome (e.g., presence/absence of disease).\n\nIt extends classical logistic regression by combining it with Bayesian inference, treating model parameters as random variables with probability distributions rather than fixed point estimates.\n\nThe logistic model relates the probability of an outcome ( Y = 1 ) to a linear combination of predictors through the logit link function:\n[ (P(Y = 1)) = _0 + _1 X_1 + _2 X_2 + + _k X_k ]\nlogit(pi)=β0+j=1∑pβjxij\np_i: the probability of the event (e.g., having diabetes) for individual i. “logit”(p_i)=log⁡(p_i/(1-p_i )): the log-odds of the event. β_0: the intercept — the log-odds of the event when all predictors x_ij=0. β_j: the coefficient for predictor x_j, representing the change in log-odds for a one-unit increase in x_ij, holding other variables constant. ∑_(j=1)^p β_j x_ij: the combined linear effect of all predictors.\nIn the Bayesian framework, the coefficients ( ) are assigned prior distributions, which are updated in light of the observed data to yield posterior distributions."
  },
  {
    "objectID": "index.html#bayesian-approach",
    "href": "index.html#bayesian-approach",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Bayesian Approach",
    "text": "Bayesian Approach\n\nThe Bayesian approach naturally incorporates uncertainty in all model parameters.\n\nIt combines prior beliefs with observed data to produce posterior distributions according to Bayes’ theorem:\n[ ]\nLikelihood: Represents the probability of the observed data given the model parameters (as in classical logistic regression).\n\nPrior: Encodes prior knowledge or beliefs about parameter values before observing the data.\n\nPosterior: Represents updated beliefs about parameters after observing the data.\n\n\nPrior Specification\nA weakly informative Student’s t-distribution prior, student_t(3, 0, 10), was used for regression coefficients (van de Schoot et al., 2013).\nThis prior:\n- Has 3 degrees of freedom (( = 3 )), producing heavy tails that allow for occasional large effects.\n- Is centered at 0 (( = 0 )), reflecting no initial bias toward positive or negative associations.\n- Has a scale parameter of 10 (( = 10 )), allowing broad variation in possible coefficient values.\nSuch priors improve stability in models with small sample sizes, high collinearity, or potential outliers."
  },
  {
    "objectID": "index.html#advantages-of-bayesian-logistic-regression",
    "href": "index.html#advantages-of-bayesian-logistic-regression",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Advantages of Bayesian Logistic Regression",
    "text": "Advantages of Bayesian Logistic Regression\n\nUncertainty quantification: Produces full posterior distributions instead of single-point estimates.\n\nCredible intervals: Provide the range within which a parameter lies with a specified probability (e.g., 95%).\n\nFlexible priors: Allow incorporation of expert knowledge or results from previous studies.\n\nProbabilistic predictions: Posterior predictive distributions yield direct probabilities for future observations.\n\nComprehensive model checking: Posterior predictive checks (PPCs) evaluate how well simulated outcomes reproduce observed data."
  },
  {
    "objectID": "index.html#posterior-predictions",
    "href": "index.html#posterior-predictions",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Posterior Predictions",
    "text": "Posterior Predictions\nPosterior distributions of the coefficients are used to estimate the probability of the outcome for given predictor values.\nThis enables statements such as:\n&gt; “Given the predictors, the probability of the outcome lies between X% and Y%.”\nPosterior predictions incorporate two sources of uncertainty:\n- Parameter uncertainty: Variability in estimated model coefficients.\n- Predictive uncertainty: Variability in future outcomes given those parameters."
  },
  {
    "objectID": "index.html#model-evaluation-and-diagnostics",
    "href": "index.html#model-evaluation-and-diagnostics",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Model Evaluation and Diagnostics",
    "text": "Model Evaluation and Diagnostics\nModel quality and convergence were assessed using standard Bayesian diagnostics:\n\nConvergence diagnostics: Markov Chain Monte Carlo (MCMC) performance was evaluated using ( ) (R-hat) and effective sample size (ESS).\n\nAutocorrelation checks: Ensured independence between successive MCMC draws.\n\nPosterior predictive checks (PPC): Compared simulated data from posterior distributions to observed outcomes.\n\nBayesian R²: Quantified the proportion of variance explained by the predictors, incorporating uncertainty.\n\nIn Bayesian analysis, every unknown parameter — such as a regression coefficient, mean, or variance — is treated as a random variable with a probability distribution that expresses uncertainty given the observed data."
  },
  {
    "objectID": "index.html#data-variables",
    "href": "index.html#data-variables",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Data Variables",
    "text": "Data Variables\nResponse Variable: Binary Type 2 / diagnosed diabetes(excluding gestational diabetes) diabetes_dx created combining - DIQ010 - Doctor told you have diabetes - DIQ050- excluded (a secondary variable describing treatment status (insulin use)). Predictor Variables - Body Mass Index, factor, 4 levels\nCovariates - Gender (factor, 2 levels) - Ethnicity (factor, 5 levels) - Age (continuous 20-80years)\n\n\n\nVariable Descriptions: Adult Dataset\n\n\nVariable\nDescription\nType\n\n\n\n\ndiabetes_dx\nDiabetes diagnosis (1 = Yes, 0 = No) based on medical questionnaire.\nCategorical\n\n\nage\nAge of participant in years.\nContinuous\n\n\nbmi\nBody Mass Index (BMI) in kilograms per square meter (kg/m²), calculated from measured height and weight.\nContinuous\n\n\nsex\nSex of participant (Male or Female).\nCategorical\n\n\nrace\nRace/Ethnicity (e.g., Non-Hispanic White, Non-Hispanic Black, Mexican American, etc.).\nCategorical\n\n\nWTMEC2YR\nExamination sample weight for MEC (Mobile Examination Center) participants.\nWeight\n\n\nSDMVPSU\nPrimary Sampling Unit (PSU) used for variance estimation in complex survey design.\nDesign\n\n\nSDMVSTRA\nStratum variable used to define strata for complex survey design.\nDesign\n\n\nage_c\nAge variable centered and standardized (z-score).\nContinuous\n\n\nbmi_c\nBMI variable centered and standardized (z-score).\nContinuous\n\n\nwt_norm\nNormalized survey weight (WTMEC2YR divided by its mean, for model weighting).\nWeight"
  },
  {
    "objectID": "index.html#analytic-adults-dataset-20---80-years",
    "href": "index.html#analytic-adults-dataset-20---80-years",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Analytic Adults Dataset (20 - 80 years)",
    "text": "Analytic Adults Dataset (20 - 80 years)\n\n\n\n\n\n\n\nStep\nDescription\n\n\n\n\nWeighting\nUsed the survey package to calculate weighted means and standard deviations for all variables.\n\n\nStandardization\nStandardized BMI and age variables for analysis.\n\n\nAge Categorization\nRecoded into intervals: 20–&lt;30, 30–&lt;40, 40–&lt;50, 50–&lt;60, 60–&lt;70, and 70–80 years.\n\n\nBMI Categorization\nRecoded and categorized as: &lt;18.5 (Underweight), 18.5–&lt;25 (Normal), 25–&lt;30 (Overweight), 30–&lt;35 (Obesity I), 35–&lt;40 (Obesity II), ≥40 (Obesity III).\n\n\nEthnicity Recoding\nRecoded as: 1 = Mexican American, 2 = Other Hispanic, 3 = Non-Hispanic White, 4 = Non-Hispanic Black, 5 = Other/Multi.\n\n\nSpecial Codes\nSpecial codes (e.g., 3, 7) were transformed to NA. These codes are not random and could introduce bias if ignored (MAR or MNAR).\n\n\nMissing Data\nMissing values were retained and visualized to assess their pattern and informativeness.\n\n\nFinal Dataset\nCreated a cleaned analytic dataset (adult) using Non-Hispanic White and Male as reference groups for analysis.\n\n\n\n\n\nCode\n## \n# ---------------- Basic Exploration (adults) ----------------\n\n# Keep adults only and build analysis variables\nadult &lt;- merged_data %&gt;%\n  dplyr::filter(RIDAGEYR &gt;= 20) %&gt;%\n  dplyr::transmute(\n    # --- keep survey design variables so svydesign() can see them ---\n    SDMVPSU, SDMVSTRA, WTMEC2YR,\n\n    # --- outcome: DIQ010 (1 yes, 2 no; 3/7/9 -&gt; NA) ---\n    diabetes_dx = dplyr::case_when(\n      DIQ010 == 1 ~ 1,\n      DIQ010 == 2 ~ 0,\n      DIQ010 %in% c(3, 7, 9) ~ NA_real_,\n      TRUE ~ NA_real_\n    ),\n\n    # --- predictors (raw) ---\n    bmi  = BMXBMI,\n    age  = RIDAGEYR,\n\n    # sex (1=Male, 2=Female)\n    sex  = forcats::fct_recode(factor(RIAGENDR), Male = \"1\", Female = \"2\"),\n\n    # race (5-level)\n    race = forcats::fct_recode(\n      factor(RIDRETH1),\n      \"Mexican American\" = \"1\",\n      \"Other Hispanic\"   = \"2\",\n      \"NH White\"         = \"3\",\n      \"NH Black\"         = \"4\",\n      \"Other/Multi\"      = \"5\"\n    ),\n\n    # keep DIQ050 so we can safely reference it (may be absent/NA in some rows)\n    \n    DIQ050 = DIQ050\n  ) %&gt;%\n  # standardize continuous predictors\n  dplyr::mutate(\n    age_c = as.numeric(scale(age)),\n    bmi_c = as.numeric(scale(bmi)),\n    bmi_cat = cut(\n      bmi,\n      breaks = c(-Inf, 18.5, 25, 30, 35, 40, Inf),\n      labels = c(\"&lt;18.5\",\"18.5–&lt;25\",\"25–&lt;30\",\"30–&lt;35\",\"35–&lt;40\",\"≥40\"),\n      right = FALSE\n    )\n  ) %&gt;%\n  # adjust outcome: if female & DIQ050==1 (\"only when pregnant\"), set to 0 (not diabetes)\n  dplyr::mutate(\n    diabetes_dx = ifelse(sex == \"Female\" & !is.na(DIQ050) & DIQ050 == 1, 0, diabetes_dx)\n  )\n\n# Make NH White the reference level for race (clearer interpretation)\nadult &lt;- adult %&gt;%\n  dplyr::mutate(\n    race = forcats::fct_relevel(race, \"NH White\")\n  )\n\n# --- sanity checks ---\ncat(\"Adults n =\", nrow(adult), \"\\n\")\n\n\nAdults n = 5769"
  },
  {
    "objectID": "index.html#exploratory-data-analysis-adults-20---80-years",
    "href": "index.html#exploratory-data-analysis-adults-20---80-years",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Exploratory Data Analysis (Adults, 20 - 80 years)",
    "text": "Exploratory Data Analysis (Adults, 20 - 80 years)\nSurvey design: - It is a national survey based on complex sampling designs (oversampling certain groups (e.g., minorities, older adults) to ensure representation. - They use multistage sampling to represent the U.S. population, so we apply sampling weights, strata, and PSU (primary sampling units) for valid estimates. - We use survey design in regression anlaysis to avoid to avoid bias prevalence estimates (e.g., mean BMI or diabetes %), underestimation of standard errors and incorrect inference for population-level parameters. - It includes auxillary variables: SDMVPSU, SDMVSTRA, WTMEC2YR - Outcome: diabetes_dx (numeric 0/1) Covariates: bmi, age, sex, race, DIQ050 Centered covariates: age_c, bmi_c BMI categories: bmi_cat\n\n\nCode\n#| label: survey design\n#| echo: false\n# survey design\n# ---------------- Survey Design ----------------\n# Use exam weights because BMI (BMXBMI) is an MEC variable\n\nnhanes_design_adult &lt;- survey::svydesign(\n  id = ~SDMVPSU,\n  strata = ~SDMVSTRA,\n  weights = ~WTMEC2YR,\n  nest = TRUE,\n  data = adult\n)\n\n# quick weighted checks\nsurvey::svymean(~age, nhanes_design_adult, na.rm = TRUE)\n\n\n      mean     SE\nage 47.496 0.3805\n\n\nCode\nsurvey::svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)\n\n\n                mean     SE\ndiabetes_dx 0.089016 0.0048\n\n\nCode\n# Calculate effective sample size for diabetes\n\n# Variance ignoring survey design (i.e., assuming SRS)\nv &lt;- svyvar(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)\np &lt;- mean(adult$diabetes_dx, na.rm = TRUE)\nv_srs &lt;- p * (1 - p) / nrow(adult)\n\n# Design effect = actual variance / SRS variance\ndeff &lt;- v / v_srs\ndeff  # design effect\n\n\n            variance     SE\ndiabetes_dx   4759.9 0.0039\n\n\nCode\nn_total &lt;- sum(weights(nhanes_design_adult))\ness &lt;- n_total / deff\ncat(\"Effective sample size for diabetes_dx:\", round(ess), \"\\n\")\n\n\nEffective sample size for diabetes_dx: 48142 \n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(skimr)\nlibrary(knitr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(forcats)\nlibrary(kableExtra)\n\nstr(adult)\n\n\n'data.frame':   5769 obs. of  12 variables:\n $ SDMVPSU    : num  1 1 1 2 1 1 2 1 2 2 ...\n $ SDMVSTRA   : num  112 108 109 116 111 114 106 112 112 113 ...\n $ WTMEC2YR   : num  13481 24472 57193 65542 25345 ...\n $ diabetes_dx: num  1 1 1 0 0 0 0 0 0 0 ...\n $ bmi        : num  26.7 28.6 28.9 19.7 41.7 35.7 NA 26.5 22 20.3 ...\n $ age        : num  69 54 72 73 56 61 42 56 65 26 ...\n $ sex        : Factor w/ 2 levels \"Male\",\"Female\": 1 1 1 2 1 2 1 2 1 2 ...\n $ race       : Factor w/ 5 levels \"NH White\",\"Mexican American\",..: 4 1 1 1 2 1 3 1 1 1 ...\n $ DIQ050     : num  1 1 1 2 2 2 2 2 2 2 ...\n $ age_c      : num  1.132 0.278 1.303 1.36 0.392 ...\n $ bmi_c      : num  -0.3359 -0.0703 -0.0283 -1.3144 1.761 ...\n $ bmi_cat    : Factor w/ 6 levels \"&lt;18.5\",\"18.5–&lt;25\",..: 3 3 3 2 6 5 NA 3 2 2 ...\n\n\nCode\nplot_str(adult)\nhead(adult)\n\n\n  SDMVPSU SDMVSTRA WTMEC2YR diabetes_dx  bmi age    sex             race DIQ050\n1       1      112 13481.04           1 26.7  69   Male         NH Black      1\n2       1      108 24471.77           1 28.6  54   Male         NH White      1\n3       1      109 57193.29           1 28.9  72   Male         NH White      1\n4       2      116 65541.87           0 19.7  73 Female         NH White      2\n5       1      111 25344.99           0 41.7  56   Male Mexican American      2\n6       1      114 61758.65           0 35.7  61 Female         NH White      2\n      age_c       bmi_c  bmi_cat\n1 1.1324183 -0.33588609   25–&lt;30\n2 0.2783598 -0.07028101   25–&lt;30\n3 1.3032300 -0.02834336   25–&lt;30\n4 1.3601672 -1.31443114 18.5–&lt;25\n5 0.3922343  1.76099614      ≥40\n6 0.6769204  0.92224325   35–&lt;40\n\n\nCode\nplot_intro(adult, title=\"Figure 1 (Adult dataset). Structure of variables and missing observations.\")\n\n\n\n\n\n\n\n\n\nCode\nplot_missing(adult, title=\"Figure 2(Adult dataset). Breakdown of missing observations.\")"
  },
  {
    "objectID": "index.html#adult-population-nhanes-description",
    "href": "index.html#adult-population-nhanes-description",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Adult population (NHANES) description",
    "text": "Adult population (NHANES) description\n\nThe table presents Adult dataset (n = 5769) after cleaning and analysis\nVariables - ethnicity (5 levels), age range (20-80 years), gender (male and female), BMI as continuous and Diabetes grouped from (DIQ010 excluding DIQ050).\nNumber of observations = 5769\nDiscrete vs Continuous Columns: 25% of columns are discrete (categorical) while 75% are continuous, indicating that the dataset primarily contains continuous measurements such as age and BMI.\nComplete Rows: 92.7% of rows have complete information for all variables, meaning most participants have fully observed data across predictors and outcomes.\nBelow are histogram, bar graph, boxplot that display age, bmi and their association with diabetes status.\nPlot shows males and females with and without diabetes (including missing data) across different racial groups. Bars are side by side for each sex, with counts displayed on top\nMean, SE and vairance for age, diabetes_dx mean SE age 47.496 0.3805 diabetes_dx 0.089016 0.0048 variance SE diabetes_dx 4759.9 0.0039\nEffective sample size = diabetes_dx: 48142\nAge: Participants are fairly evenly distributed across adult age groups, with no sharp skewness.\nSex: sample includes a higher proportion of females than males.\nBMI: Most participants have BMI values within the normal to overweight range, with fewer in the obese category.\nBMI by Diabetes Status: Individuals diagnosed with diabetes tend to have higher BMI values compared to non-diabetics.\nDiabetes Prevalence by Age Group: The proportion of diabetes increases with advancing age, highlighting age as a strong risk factor.\nDiabetes Prevalence by Race/Ethnicity: Differences are observed across racial/ethnic groups, with some showing higher prevalence rates than others.\n\n\n\nCode\nggplot(adult, aes(x = age)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Age &gt;20 years\",\n    x = \"Age (years)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution in &gt;20 years age group\", x=\"diabetes_dx (0=No, 1=Yes)\", y=\"Count\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(bmi_cat))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution by BMI in &gt;20 years age group\", x=\"bmi_cat\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(diabetes_dx), y = bmi)) +\n  geom_boxplot(fill = \"skyblue\") +\n  labs(\n    title = \"BMI Distribution by Diabetes Diagnosis in &gt;20 years age group\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\n# plots for adult data bmi categories and race categories\n\nggplot(adult, aes(x = factor(race), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by Race in &gt;20 years age group\",\n    x = \"Race/Ethnicity\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(bmi_cat), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by BMI in &gt;20 years age group\",\n    x = \"BMI\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Example: create your dataset\nadult1 &lt;- data.frame(\n  race = rep(c(\"NH White\",\"Mexican American\",\"Other Hispanic\",\"NH Black\",\"Other/Multi\"), each = 6),\n  sex = rep(c(\"Male\",\"Male\",\"Male\",\"Female\",\"Female\",\"Female\"), times = 5),\n  diabetes_dx = rep(c(0,1,NA,0,1,NA), times = 5),\n  count = c(\n    1019,119,38,1164,96,36,\n    304,60,14,329,49,11,\n    183,26,10,255,25,9,\n    461,100,19,515,65,17,\n    351,46,8,393,32,15\n  )\n)\n\n# Clean NA for plotting or convert to \"Missing\"\nadult1$diabetes_dx &lt;- as.character(adult1$diabetes_dx)\nadult1$diabetes_dx[is.na(adult1$diabetes_dx)] &lt;- \"Missing\"\n\n# Plot grouped bar chart\nggplot(adult1, aes(x = diabetes_dx, y = count, fill = sex)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~race) +\n  labs(title = \"Diabetes Diagnosis by Sex and Race\",\n       x = \"Diabetes Diagnosis\",\n       y = \"Count\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"skyblue\", \"orange\"))"
  },
  {
    "objectID": "index.html#multiple-imputation-pooled-logistic-regression",
    "href": "index.html#multiple-imputation-pooled-logistic-regression",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Multiple Imputation Pooled Logistic Regression",
    "text": "Multiple Imputation Pooled Logistic Regression\n\n\nCode\nfit_mi &lt;- with(imp, {\n  age_c &lt;- as.numeric(scale(age))\n  bmi_c &lt;- as.numeric(scale(bmi))\n  glm(diabetes_dx ~ age_c + bmi_c + sex + race, family = binomial())\n})\npool_mi &lt;- pool(fit_mi)\nsummary(pool_mi)\n\n\n                  term   estimate  std.error  statistic       df       p.value\n1          (Intercept) -2.6895645 0.09941301 -27.054453 5566.204 1.486581e-151\n2                age_c  1.0660265 0.05594733  19.054108 5520.446  1.911564e-78\n3                bmi_c  0.5468538 0.04473386  12.224604 5148.557  6.751227e-34\n4            sexFemale -0.6178297 0.09379129  -6.587282 5551.660  4.892566e-11\n5 raceMexican American  0.8877355 0.13750463   6.456041 5472.583  1.167455e-10\n6   raceOther Hispanic  0.5606621 0.17485537   3.206433 5573.987  1.351505e-03\n7         raceNH Black  0.6809629 0.11981185   5.683602 5576.734  1.385727e-08\n8      raceOther/Multi  0.7476406 0.15300663   4.886328 4749.963  1.061140e-06\n\n\nCode\n## table \n\nmi_or &lt;- summary(pool_mi, conf.int = TRUE, exponentiate = TRUE) %&gt;%\n  dplyr::rename(\n    term = term, OR = estimate, LCL = `2.5 %`, UCL = `97.5 %`, p.value = p.value\n  ) %&gt;%\n  dplyr::filter(term != \"(Intercept)\")\nknitr::kable(mi_or, caption = \"MI pooled odds ratios (per 1 SD)\")\n\n\n\nMI pooled odds ratios (per 1 SD)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nOR\nstd.error\nstatistic\ndf\np.value\nLCL\nUCL\nconf.low\nconf.high\n\n\n\n\n2\nage_c\n2.9038183\n0.0559473\n19.054108\n5520.446\n0.0000000\n2.6021752\n3.2404277\n2.6021752\n3.2404277\n\n\n3\nbmi_c\n1.7278084\n0.0447339\n12.224604\n5148.557\n0.0000000\n1.5827382\n1.8861754\n1.5827382\n1.8861754\n\n\n4\nsexFemale\n0.5391132\n0.0937913\n-6.587282\n5551.660\n0.0000000\n0.4485669\n0.6479368\n0.4485669\n0.6479368\n\n\n5\nraceMexican American\n2.4296216\n0.1375046\n6.456041\n5472.583\n0.0000000\n1.8555327\n3.1813298\n1.8555327\n3.1813298\n\n\n6\nraceOther Hispanic\n1.7518320\n0.1748554\n3.206433\n5573.987\n0.0013515\n1.2434346\n2.4680953\n1.2434346\n2.4680953\n\n\n7\nraceNH Black\n1.9757793\n0.1198118\n5.683602\n5576.734\n0.0000000\n1.5621842\n2.4988753\n1.5621842\n2.4988753\n\n\n8\nraceOther/Multi\n2.1120110\n0.1530066\n4.886328\n4749.963\n0.0000011\n1.5646727\n2.8508138\n1.5646727\n2.8508138\n\n\n\n\n\nResults from Multiple Imputation Pooled Logistic Regression (survey-weighted multiple logistic regression model)\nAfter addressing missing BMI values using Multivariate Imputation by Chained Equations (MICE), pooled estimates from five imputations were analyzed using a survey-weighted multiple logistic regression model.\n\nAge remained the strongest predictor of diabetes (OR = 2.90, 95% CI: 2.60–3.24, p &lt; 0.001).\nBMI continued to show a significant positive association (OR = 1.73, 95% CI: 1.58–1.89, p &lt; 0.001).\nFemale sex was associated with lower odds of diabetes compared to males (OR = 0.54, 95% CI: 0.45–0.65, p &lt; 0.001).\nCompared to Non-Hispanic Whites, higher odds of diabetes were observed among: Mexican Americans (OR = 2.43, 95% CI: 1.86–3.18) Other Hispanics (OR = 1.75, 95% CI: 1.24–2.47) Non-Hispanic Blacks (OR = 1.98, 95% CI: 1.56–2.50) Other/Multi-racial groups (OR = 2.11, 95% CI: 1.56–2.85)\nAll associations were statistically significant (p &lt; 0.01).\n\n\n\nCode\nlibrary(gt)\n\n# Bayesian Logistic Regression (formula weights) \nadult_imp1 &lt;- complete(imp, 1) %&gt;%\n  dplyr::mutate(\n    age_c  = as.numeric(scale(age)),\n    bmi_c  = as.numeric(scale(bmi)),\n    wt_norm = WTMEC2YR / mean(WTMEC2YR, na.rm = TRUE),\n    # ensure factor refs match survey/mice:\n    race = forcats::fct_relevel(race, \"NH White\"),\n    sex  = forcats::fct_relevel(sex,  \"Male\")\n  ) %&gt;%\n  dplyr::filter(!is.na(diabetes_dx), !is.na(age_c), !is.na(bmi_c),\n                !is.na(sex), !is.na(race)) %&gt;%\n  droplevels()\n\nstopifnot(all(is.finite(adult_imp1$wt_norm)))\n\nglimpse(adult_imp1)\n\n\nRows: 5,592\nColumns: 11\n$ diabetes_dx &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age         &lt;dbl&gt; 69, 54, 72, 73, 56, 61, 42, 56, 65, 26, 76, 33, 32, 38, 50…\n$ bmi         &lt;dbl&gt; 26.7, 28.6, 28.9, 19.7, 41.7, 35.7, 23.6, 26.5, 22.0, 20.3…\n$ sex         &lt;fct&gt; Male, Male, Male, Female, Male, Female, Male, Female, Male…\n$ race        &lt;fct&gt; NH Black, NH White, NH White, NH White, Mexican American, …\n$ WTMEC2YR    &lt;dbl&gt; 13481.04, 24471.77, 57193.29, 65541.87, 25344.99, 61758.65…\n$ SDMVPSU     &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ SDMVSTRA    &lt;dbl&gt; 112, 108, 109, 116, 111, 114, 106, 112, 112, 113, 116, 114…\n$ age_c       &lt;dbl&gt; 1.13241831, 0.27835981, 1.30323001, 1.36016725, 0.39223428…\n$ bmi_c       &lt;dbl&gt; -0.33319172, -0.06755778, -0.02561558, -1.31184309, 1.7639…\n$ wt_norm     &lt;dbl&gt; 0.3393916, 0.6160884, 1.4398681, 1.6500477, 0.6380722, 1.5…\n\n\nCode\nlibrary(tableone)\n\nvars &lt;- c(\"age\", \"bmi\", \"age_c\", \"bmi_c\", \"wt_norm\", \"sex\", \"race\", \"diabetes_dx\")\n\ntable1 &lt;- CreateTableOne(vars = vars, data = adult_imp1, factorVars = c(\"sex\", \"race\", \"diabetes_dx\"))\nprint(table1, showAllLevels = TRUE)\n\n\n                     \n                      level            Overall      \n  n                                     5592        \n  age (mean (SD))                      48.84 (17.57)\n  bmi (mean (SD))                      29.00 (7.11) \n  age_c (mean (SD))                    -0.02 (1.00) \n  bmi_c (mean (SD))                    -0.01 (0.99) \n  wt_norm (mean (SD))                   1.00 (0.79) \n  sex (%)             Male              2669 (47.7) \n                      Female            2923 (52.3) \n  race (%)            NH White          2398 (42.9) \n                      Mexican American   742 (13.3) \n                      Other Hispanic     489 ( 8.7) \n                      NH Black          1141 (20.4) \n                      Other/Multi        822 (14.7) \n  diabetes_dx (%)     0                 4974 (88.9) \n                      1                  618 (11.1) \n\n\n\nSummary of Imputed Adult Dataset (N = 5,592)\nOutcome: diabetes_dx (binary) - Diabetes prevalence: 11.1% (618/5,592) - Non-diabetic: 88.9% (4,974/5,592) Continuous predictors (standardized for modeling): - Age: mean 48.84 (SD 17.57), standardized as age_c (mean ≈ 0, SD ≈ 1) - BMI: mean 29.00 (SD 7.11), standardized as bmi_c (mean ≈ 0, SD ≈ 1) Categorical predictors: - Sex: Male 47.7%, Female 52.3% - Race/ethnicity: NH White 42.9% (reference), NH Black 20.4%, Mexican American 13.3%, Other Hispanic 8.7%, Other/Multi 14.7%\n\n\nCode\n## correlation matrix\nlibrary(ggplot2)\nlibrary(reshape2)\n\ncorrelation_matrix &lt;- cor(adult_imp1[, c(\"diabetes_dx\", \"age\", \"bmi\")], use = \"complete.obs\", method = \"pearson\")\ncorrelation_melted &lt;- melt(correlation_matrix)\n\nggplot(correlation_melted, aes(Var1, Var2, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0,\n                       limit = c(-1, 1), space = \"Lab\", name = \"Correlation\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Correlation Heatmap\", x = \"Features\", y = \"Features\")\n\n\n\n\n\n\n\n\n\n\n\nPairwise correlations\nA heatmap visualizing variables: diabetes_dx, age, and bmi show the strength and direction of correlations (Pearson correlation) which measures linear association between variables.\n\n\nCode\n# Class distribution\n\nggplot(adult_imp1, aes(x = factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(\n    title = \"Diabetes Diagnosis Distribution\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nprop.table(table(adult_imp1$diabetes_dx))\n\n\n\n       0        1 \n0.889485 0.110515 \n\n\nCode\n# Visualization of Diabetes vs BMI (adult_data1)\n\nlibrary(ggplot2)\n\n# Create the plot\nggplot(adult_imp1, aes(x = factor(diabetes_dx), y = bmi, fill = factor(diabetes_dx))) +\n  geom_boxplot(alpha = 0.7) +\n  scale_x_discrete(labels = c(\"0\" = \"No Diabetes\", \"1\" = \"Diabetes\")) +\n  labs(\n    x = \"Diabetes Diagnosis\",\n    y = \"BMI\",\n    title = \"BMI Distribution by Diabetes Status\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\n# logistic regression curve\nggplot(adult_imp1, aes(x = bmi, y = diabetes_dx)) +\n  geom_point(aes(y = diabetes_dx), alpha = 0.2, position = position_jitter(height = 0.02)) +\n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = TRUE, color = \"blue\") +\n  labs(\n    x = \"BMI\",\n    y = \"Probability of Diabetes\",\n    title = \"Predicted Probability of Diabetes vs BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save your dataset as CSV\nwrite.csv(adult_imp1, \"adult_imp1.csv\", row.names = FALSE)\n\n\nSurvey weights-Normalized MEC exam weights (wt_norm) with mean 1.00 (SD 0.79) Data readiness for Bayesian logistic regression: - No missing values remain in selected predictors or outcome. - Continuous variables are standardized, which facilitates prior specification. - Categorical variables are correctly re-leveled for reference categories. - Weights are available for inclusion in the likelihood to account for survey design."
  },
  {
    "objectID": "index.html#exploratory-data-analysis-adult-20---80-years",
    "href": "index.html#exploratory-data-analysis-adult-20---80-years",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Exploratory Data Analysis (Adult, 20 - 80 years)",
    "text": "Exploratory Data Analysis (Adult, 20 - 80 years)\n\nDiscrete vs Continuous Columns: 25% of columns are discrete (categorical) while 75% are continuous, indicating that the dataset primarily contains continuous measurements such as age and BMI.\nComplete Rows: 92.7% of rows have complete information for all variables, meaning most participants have fully observed data across predictors and outcomes.\n\nSurvey design: - It is a national survey based on complex sampling designs (oversampling certain groups (e.g., minorities, older adults) to ensure representation. - They use multistage sampling to represent the U.S. population, so we apply sampling weights, strata, and PSU (primary sampling units) for valid estimates. - We use survey design in regression anlaysis to avoid to avoid bias prevalence estimates (e.g., mean BMI or diabetes %), underestimation of standard errors and incorrect inference for population-level parameters. - It includes auxillary variables: SDMVPSU, SDMVSTRA, WTMEC2YR - - Diabetes grouped from (DIQ010 excluding DIQ050): diabetes_dx (numeric 0/1) - Covariates: ethnicity (5 levels), age range (20-80 years), gender (male and female), BMI as continuous - Centered covariates: age_c, bmi_c BMI categories: bmi_cat - Presented here is the mean, standard error and variance of the survey weighted data\n\n\n\n\n\n\n\nStep\nDescription\n\n\n\n\nWeighting\nUsed the survey package to calculate weighted means and standard deviations for all variables.\n\n\nStandardization\nStandardized BMI and age variables for analysis.\n\n\nAge Categorization\nRecoded into intervals: 20–&lt;30, 30–&lt;40, 40–&lt;50, 50–&lt;60, 60–&lt;70, and 70–80 years.\n\n\nBMI Categorization\nRecoded and categorized as: &lt;18.5 (Underweight), 18.5–&lt;25 (Normal), 25–&lt;30 (Overweight), 30–&lt;35 (Obesity I), 35–&lt;40 (Obesity II), ≥40 (Obesity III).\n\n\nEthnicity Recoding\nRecoded as: 1 = Mexican American, 2 = Other Hispanic, 3 = Non-Hispanic White, 4 = Non-Hispanic Black, 5 = Other/Multi.\n\n\nSpecial Codes\nSpecial codes (e.g., 3, 7) were transformed to NA. These codes are not random and could introduce bias if ignored (MAR or MNAR).\n\n\nMissing Data\nMissing values were retained and visualized to assess their pattern and informativeness.\n\n\nFinal Dataset\nCreated a cleaned analytic dataset (adult) using Non-Hispanic White and Male as reference groups for analysis.\n\n\n\n\n\nCode\n## \n# ---------------- Basic Exploration (adults) ----------------\n\n# Keep adults only and build analysis variables\nadult &lt;- merged_data %&gt;%\n  dplyr::filter(RIDAGEYR &gt;= 20) %&gt;%\n  dplyr::transmute(\n    # --- keep survey design variables so svydesign() can see them ---\n    SDMVPSU, SDMVSTRA, WTMEC2YR,\n\n    # --- outcome: DIQ010 (1 yes, 2 no; 3/7/9 -&gt; NA) ---\n    diabetes_dx = dplyr::case_when(\n      DIQ010 == 1 ~ 1,\n      DIQ010 == 2 ~ 0,\n      DIQ010 %in% c(3, 7, 9) ~ NA_real_,\n      TRUE ~ NA_real_\n    ),\n\n    # --- predictors (raw) ---\n    bmi  = BMXBMI,\n    age  = RIDAGEYR,\n\n    # sex (1=Male, 2=Female)\n    sex  = forcats::fct_recode(factor(RIAGENDR), Male = \"1\", Female = \"2\"),\n\n    # race (5-level)\n    race = forcats::fct_recode(\n      factor(RIDRETH1),\n      \"Mexican American\" = \"1\",\n      \"Other Hispanic\"   = \"2\",\n      \"NH White\"         = \"3\",\n      \"NH Black\"         = \"4\",\n      \"Other/Multi\"      = \"5\"\n    ),\n\n    # keep DIQ050 so we can safely reference it (may be absent/NA in some rows)\n    \n    DIQ050 = DIQ050\n  ) %&gt;%\n  # standardize continuous predictors\n  dplyr::mutate(\n    age_c = as.numeric(scale(age)),\n    bmi_c = as.numeric(scale(bmi)),\n    bmi_cat = cut(\n      bmi,\n      breaks = c(-Inf, 18.5, 25, 30, 35, 40, Inf),\n      labels = c(\"&lt;18.5\",\"18.5–&lt;25\",\"25–&lt;30\",\"30–&lt;35\",\"35–&lt;40\",\"≥40\"),\n      right = FALSE\n    )\n  ) %&gt;%\n  # adjust outcome: if female & DIQ050==1 (\"only when pregnant\"), set to 0 (not diabetes)\n  dplyr::mutate(\n    diabetes_dx = ifelse(sex == \"Female\" & !is.na(DIQ050) & DIQ050 == 1, 0, diabetes_dx)\n  )\n\n# Make NH White the reference level for race (clearer interpretation)\nadult &lt;- adult %&gt;%\n  dplyr::mutate(\n    race = forcats::fct_relevel(race, \"NH White\")\n  )\n\n# --- sanity checks ---\ncat(\"Adults n =\", nrow(adult), \"\\n\")\n\n\nAdults n = 5769 \n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(skimr)\nlibrary(knitr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(forcats)\nlibrary(kableExtra)\n\nstr(adult)\n\n\n'data.frame':   5769 obs. of  12 variables:\n $ SDMVPSU    : num  1 1 1 2 1 1 2 1 2 2 ...\n $ SDMVSTRA   : num  112 108 109 116 111 114 106 112 112 113 ...\n $ WTMEC2YR   : num  13481 24472 57193 65542 25345 ...\n $ diabetes_dx: num  1 1 1 0 0 0 0 0 0 0 ...\n $ bmi        : num  26.7 28.6 28.9 19.7 41.7 35.7 NA 26.5 22 20.3 ...\n $ age        : num  69 54 72 73 56 61 42 56 65 26 ...\n $ sex        : Factor w/ 2 levels \"Male\",\"Female\": 1 1 1 2 1 2 1 2 1 2 ...\n $ race       : Factor w/ 5 levels \"NH White\",\"Mexican American\",..: 4 1 1 1 2 1 3 1 1 1 ...\n $ DIQ050     : num  1 1 1 2 2 2 2 2 2 2 ...\n $ age_c      : num  1.132 0.278 1.303 1.36 0.392 ...\n $ bmi_c      : num  -0.3359 -0.0703 -0.0283 -1.3144 1.761 ...\n $ bmi_cat    : Factor w/ 6 levels \"&lt;18.5\",\"18.5–&lt;25\",..: 3 3 3 2 6 5 NA 3 2 2 ...\n\n\nCode\nplot_str(adult)\nhead(adult)\n\n\n  SDMVPSU SDMVSTRA WTMEC2YR diabetes_dx  bmi age    sex             race DIQ050\n1       1      112 13481.04           1 26.7  69   Male         NH Black      1\n2       1      108 24471.77           1 28.6  54   Male         NH White      1\n3       1      109 57193.29           1 28.9  72   Male         NH White      1\n4       2      116 65541.87           0 19.7  73 Female         NH White      2\n5       1      111 25344.99           0 41.7  56   Male Mexican American      2\n6       1      114 61758.65           0 35.7  61 Female         NH White      2\n      age_c       bmi_c  bmi_cat\n1 1.1324183 -0.33588609   25–&lt;30\n2 0.2783598 -0.07028101   25–&lt;30\n3 1.3032300 -0.02834336   25–&lt;30\n4 1.3601672 -1.31443114 18.5–&lt;25\n5 0.3922343  1.76099614      ≥40\n6 0.6769204  0.92224325   35–&lt;40\n\n\nCode\nplot_intro(adult, title=\"Figure 1 (Adult dataset). Structure of variables and missing observations.\")\n\n\n\n\n\n\n\n\n\nCode\nplot_missing(adult, title=\"Figure 2(Adult dataset). Breakdown of missing observations.\")"
  },
  {
    "objectID": "index.html#study-population-adult-nhanes",
    "href": "index.html#study-population-adult-nhanes",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Study population (Adult, NHANES)",
    "text": "Study population (Adult, NHANES)\n\nNumber of participants in Adult dataset (n = 5769) after cleaning and analysis Variables mean SE age 47.496 0.3805 mean SE diabetes_dx 0.089016 0.0048 variance SE diabetes_dx 4759.9 0.0039 Effective sample size for diabetes_dx: 48142\n\n\nPopulation characterisitcs\n\nAge: Participants are fairly evenly distributed across adult age groups, with no sharp skewness.\nSex: sample includes a higher proportion of females than males.\nBMI: Most participants have BMI values within the normal to overweight range, with fewer in the obese category.\nBMI by Diabetes Status: Individuals diagnosed with diabetes tend to have higher BMI values compared to non-diabetics.\nDiabetes Prevalence by Age Group: The proportion of diabetes increases with advancing age, highlighting age as a strong risk factor.\nDiabetes Prevalence by Race/Ethnicity: Differences are observed across racial/ethnic groups, with some showing higher prevalence rates than others.\n\nVisualization - Below are histogram, bar graph, boxplot to display age, bmi and their association with diabetes status. Plot below shows males and females with and without diabetes (including missing data) across different racial groups. Bars are side by side for each sex, with counts displayed on top\n\n\nCode\nggplot(adult, aes(x = age)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Age &gt;20 years\",\n    x = \"Age (years)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution in &gt;20 years age group\", x=\"diabetes_dx (0=No, 1=Yes)\", y=\"Count\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(factor(bmi_cat))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title=\"Diabetes Outcome Distribution by BMI in &gt;20 years age group\", x=\"bmi_cat\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(diabetes_dx), y = bmi)) +\n  geom_boxplot(fill = \"skyblue\") +\n  labs(\n    title = \"BMI Distribution by Diabetes Diagnosis in &gt;20 years age group\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\n# plots for adult data bmi categories and race categories\n\nggplot(adult, aes(x = factor(race), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by Race in &gt;20 years age group\",\n    x = \"Race/Ethnicity\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nCode\nggplot(adult, aes(x = factor(bmi_cat), fill = factor(diabetes_dx))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Diagnosis by BMI in &gt;20 years age group\",\n    x = \"BMI\",\n    y = \"Count\",\n    fill = \"Diabetes Diagnosis\\n(0 = No, 1 = Yes)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Example: create your dataset\nadult1 &lt;- data.frame(\n  race = rep(c(\"NH White\",\"Mexican American\",\"Other Hispanic\",\"NH Black\",\"Other/Multi\"), each = 6),\n  sex = rep(c(\"Male\",\"Male\",\"Male\",\"Female\",\"Female\",\"Female\"), times = 5),\n  diabetes_dx = rep(c(0,1,NA,0,1,NA), times = 5),\n  count = c(\n    1019,119,38,1164,96,36,\n    304,60,14,329,49,11,\n    183,26,10,255,25,9,\n    461,100,19,515,65,17,\n    351,46,8,393,32,15\n  )\n)\n\n# Clean NA for plotting or convert to \"Missing\"\nadult1$diabetes_dx &lt;- as.character(adult1$diabetes_dx)\nadult1$diabetes_dx[is.na(adult1$diabetes_dx)] &lt;- \"Missing\"\n\n# Plot grouped bar chart\nggplot(adult1, aes(x = diabetes_dx, y = count, fill = sex)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~race) +\n  labs(title = \"Diabetes Diagnosis by Sex and Race\",\n       x = \"Diabetes Diagnosis\",\n       y = \"Count\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"skyblue\", \"orange\"))"
  },
  {
    "objectID": "index.html#abnormalities-detected-in-adult-dataset",
    "href": "index.html#abnormalities-detected-in-adult-dataset",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Abnormalities detected in Adult dataset",
    "text": "Abnormalities detected in Adult dataset\n\nMissingness\n\nOnly 1.3% of individual data points are missing across the dataset, reflecting minimal missingness.\nNo column is entirely missing (0%), indicating all variables have at least some observed data.\nOverall missingness: ~4% → low, but non-trivial given the small number of variables involved.\nMissingness is not completely at random (MNAR or MAR) - If the probability of missingness depends on other observed variables (e.g., older adults missing BMI due to illness), imputation helps reduce bias. It is possible and should consider MICE and test with logistic regression of missingness indicators\nMissingness affects outcome or key covariates - Even small missingness in important variables can bias posterior estimates. Since BMI and diabetes are central we should perform MICE\nSufficient auxiliary variables available - MICE works best when you have other correlated variables to inform imputation (e.g., age, sex, race, WTMEC2YR).\n\nBayesian model assumes complete data - Standard Bayesian logistic models (e.g., brms, rstanarm) cannot directly handle NAs — you must impute or model missingness."
  },
  {
    "objectID": "index.html#multivariate-imputation-by-chained-equations-pooled-logistic-regression",
    "href": "index.html#multivariate-imputation-by-chained-equations-pooled-logistic-regression",
    "title": "Bayesian Logistic Regression - Application in Probability Prediction of disease (Diabetes)",
    "section": "Multivariate Imputation by Chained Equations (Pooled Logistic Regression)",
    "text": "Multivariate Imputation by Chained Equations (Pooled Logistic Regression)\n\nWe conducted MICE to manage missiging data as an alternative to the Bayesian Approach Buuren and Groothuis-Oudshoorn (2011)\nFlatness of the density, heavy tails, non-zero peakedness, skewness and multimodality do not hamper the good performance of multiple imputation for the mean structure in samples n &gt; 400 even for high percentages (75%) of missing data in one variable Van Buuren and Van Buuren (2012).\nMultiple Imputation (MI) can be performed using mice package in R\nIterative mice imputes missing values of one variable at a time, using regression models based on the other variables in the dataset.\nIn the chain process, each imputed variable become a predictor for the subsequent imputation, and the entire process is repeated multiple times to create several complete datasets, each reflecting different possibilities for the missing data.\n\n\n\nCode\n# ----- Multiple Imputation (predictors only) \nmi_dat &lt;- adult %&gt;%\n  dplyr::select(diabetes_dx, age, bmi, sex, race, WTMEC2YR, SDMVPSU, SDMVSTRA)\n\nmeth &lt;- mice::make.method(mi_dat)\npred &lt;- mice::make.predictorMatrix(mi_dat)\n\n# Do not impute outcome\nmeth[\"diabetes_dx\"] &lt;- \"\"\npred[\"diabetes_dx\", ] &lt;- 0\npred[,\"diabetes_dx\"] &lt;- 1\n\n# Imputation methods\nmeth[\"age\"]  &lt;- \"norm\"\nmeth[\"bmi\"]  &lt;- \"pmm\"\nmeth[\"sex\"]  &lt;- \"polyreg\"\nmeth[\"race\"] &lt;- \"polyreg\"\n\n# Survey design vars as auxiliaries only\nmeth[c(\"WTMEC2YR\",\"SDMVPSU\",\"SDMVSTRA\")] &lt;- \"\"\npred[, c(\"WTMEC2YR\",\"SDMVPSU\",\"SDMVSTRA\")] &lt;- 1\n\nglimpse(mi_dat)\n\n\nRows: 5,769\nColumns: 8\n$ diabetes_dx &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age         &lt;dbl&gt; 69, 54, 72, 73, 56, 61, 42, 56, 65, 26, 76, 33, 32, 38, 50…\n$ bmi         &lt;dbl&gt; 26.7, 28.6, 28.9, 19.7, 41.7, 35.7, NA, 26.5, 22.0, 20.3, …\n$ sex         &lt;fct&gt; Male, Male, Male, Female, Male, Female, Male, Female, Male…\n$ race        &lt;fct&gt; NH Black, NH White, NH White, NH White, Mexican American, …\n$ WTMEC2YR    &lt;dbl&gt; 13481.04, 24471.77, 57193.29, 65541.87, 25344.99, 61758.65…\n$ SDMVPSU     &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ SDMVSTRA    &lt;dbl&gt; 112, 108, 109, 116, 111, 114, 106, 112, 112, 113, 116, 114…\n\n\nCode\nimp &lt;- mice::mice(mi_dat, m = 5, method = meth, predictorMatrix = pred, seed = 123)\n\n\n\n iter imp variable\n  1   1  bmi\n  1   2  bmi\n  1   3  bmi\n  1   4  bmi\n  1   5  bmi\n  2   1  bmi\n  2   2  bmi\n  2   3  bmi\n  2   4  bmi\n  2   5  bmi\n  3   1  bmi\n  3   2  bmi\n  3   3  bmi\n  3   4  bmi\n  3   5  bmi\n  4   1  bmi\n  4   2  bmi\n  4   3  bmi\n  4   4  bmi\n  4   5  bmi\n  5   1  bmi\n  5   2  bmi\n  5   3  bmi\n  5   4  bmi\n  5   5  bmi\n\n\n\nResults from MICE (pooled imputed dataset):\n\nIn the final analytic dataset consisting of 5,769 participants with 8 variables, with missing values were addressed using Multivariate Imputation by Chained Equations (MICE).\nFive imputations were performed across five iterations each, with BMI imputed conditionally based on other predictors (age, sex, race, and diabetes status).\nThe iterative process showed stable convergence, indicating reliable estimation of missing BMI values for subsequent survey-weighted and Bayesian modeling analyses.\n\n\n\nCode\nfit_mi &lt;- with(imp, {\n  age_c &lt;- as.numeric(scale(age))\n  bmi_c &lt;- as.numeric(scale(bmi))\n  glm(diabetes_dx ~ age_c + bmi_c + sex + race, family = binomial())\n})\npool_mi &lt;- pool(fit_mi)\nsummary(pool_mi)\n\n\n                  term   estimate  std.error  statistic       df       p.value\n1          (Intercept) -2.6895645 0.09941301 -27.054453 5566.204 1.486581e-151\n2                age_c  1.0660265 0.05594733  19.054108 5520.446  1.911564e-78\n3                bmi_c  0.5468538 0.04473386  12.224604 5148.557  6.751227e-34\n4            sexFemale -0.6178297 0.09379129  -6.587282 5551.660  4.892566e-11\n5 raceMexican American  0.8877355 0.13750463   6.456041 5472.583  1.167455e-10\n6   raceOther Hispanic  0.5606621 0.17485537   3.206433 5573.987  1.351505e-03\n7         raceNH Black  0.6809629 0.11981185   5.683602 5576.734  1.385727e-08\n8      raceOther/Multi  0.7476406 0.15300663   4.886328 4749.963  1.061140e-06\n\n\nCode\n## table \n\nmi_or &lt;- summary(pool_mi, conf.int = TRUE, exponentiate = TRUE) %&gt;%\n  dplyr::rename(\n    term = term, OR = estimate, LCL = `2.5 %`, UCL = `97.5 %`, p.value = p.value\n  ) %&gt;%\n  dplyr::filter(term != \"(Intercept)\")\nknitr::kable(mi_or, caption = \"MI pooled odds ratios (per 1 SD)\")\n\n\n\nMI pooled odds ratios (per 1 SD)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nOR\nstd.error\nstatistic\ndf\np.value\nLCL\nUCL\nconf.low\nconf.high\n\n\n\n\n2\nage_c\n2.9038183\n0.0559473\n19.054108\n5520.446\n0.0000000\n2.6021752\n3.2404277\n2.6021752\n3.2404277\n\n\n3\nbmi_c\n1.7278084\n0.0447339\n12.224604\n5148.557\n0.0000000\n1.5827382\n1.8861754\n1.5827382\n1.8861754\n\n\n4\nsexFemale\n0.5391132\n0.0937913\n-6.587282\n5551.660\n0.0000000\n0.4485669\n0.6479368\n0.4485669\n0.6479368\n\n\n5\nraceMexican American\n2.4296216\n0.1375046\n6.456041\n5472.583\n0.0000000\n1.8555327\n3.1813298\n1.8555327\n3.1813298\n\n\n6\nraceOther Hispanic\n1.7518320\n0.1748554\n3.206433\n5573.987\n0.0013515\n1.2434346\n2.4680953\n1.2434346\n2.4680953\n\n\n7\nraceNH Black\n1.9757793\n0.1198118\n5.683602\n5576.734\n0.0000000\n1.5621842\n2.4988753\n1.5621842\n2.4988753\n\n\n8\nraceOther/Multi\n2.1120110\n0.1530066\n4.886328\n4749.963\n0.0000011\n1.5646727\n2.8508138\n1.5646727\n2.8508138\n\n\n\n\n\nMultivariate Imputation by Chained Equations (MICE) results from the pooled estimates using a survey-weighted multiple logistic regression model.\n\nAge remained the strongest predictor of diabetes (OR = 2.90, 95% CI: 2.60–3.24, p &lt; 0.001).\nBMI continued to show a significant positive association (OR = 1.73, 95% CI: 1.58–1.89, p &lt; 0.001).\nFemale sex was associated with lower odds of diabetes compared to males (OR = 0.54, 95% CI: 0.45–0.65, p &lt; 0.001).\nCompared to Non-Hispanic Whites, higher odds of diabetes were observed among: Mexican Americans (OR = 2.43, 95% CI: 1.86–3.18) Other Hispanics (OR = 1.75, 95% CI: 1.24–2.47) Non-Hispanic Blacks (OR = 1.98, 95% CI: 1.56–2.50) Other/Multi-racial groups (OR = 2.11, 95% CI: 1.56–2.85)\nAll associations were statistically significant (p &lt; 0.01).\n\n\n\nCode\nlibrary(gt)\n\n# Bayesian Logistic Regression (formula weights) \nadult_imp1 &lt;- complete(imp, 1) %&gt;%\n  dplyr::mutate(\n    age_c  = as.numeric(scale(age)),\n    bmi_c  = as.numeric(scale(bmi)),\n    wt_norm = WTMEC2YR / mean(WTMEC2YR, na.rm = TRUE),\n    # ensure factor refs match survey/mice:\n    race = forcats::fct_relevel(race, \"NH White\"),\n    sex  = forcats::fct_relevel(sex,  \"Male\")\n  ) %&gt;%\n  dplyr::filter(!is.na(diabetes_dx), !is.na(age_c), !is.na(bmi_c),\n                !is.na(sex), !is.na(race)) %&gt;%\n  droplevels()\n\nstopifnot(all(is.finite(adult_imp1$wt_norm)))\n\nglimpse(adult_imp1)\n\n\nRows: 5,592\nColumns: 11\n$ diabetes_dx &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age         &lt;dbl&gt; 69, 54, 72, 73, 56, 61, 42, 56, 65, 26, 76, 33, 32, 38, 50…\n$ bmi         &lt;dbl&gt; 26.7, 28.6, 28.9, 19.7, 41.7, 35.7, 23.6, 26.5, 22.0, 20.3…\n$ sex         &lt;fct&gt; Male, Male, Male, Female, Male, Female, Male, Female, Male…\n$ race        &lt;fct&gt; NH Black, NH White, NH White, NH White, Mexican American, …\n$ WTMEC2YR    &lt;dbl&gt; 13481.04, 24471.77, 57193.29, 65541.87, 25344.99, 61758.65…\n$ SDMVPSU     &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ SDMVSTRA    &lt;dbl&gt; 112, 108, 109, 116, 111, 114, 106, 112, 112, 113, 116, 114…\n$ age_c       &lt;dbl&gt; 1.13241831, 0.27835981, 1.30323001, 1.36016725, 0.39223428…\n$ bmi_c       &lt;dbl&gt; -0.33319172, -0.06755778, -0.02561558, -1.31184309, 1.7639…\n$ wt_norm     &lt;dbl&gt; 0.3393916, 0.6160884, 1.4398681, 1.6500477, 0.6380722, 1.5…\n\n\nCode\nlibrary(tableone)\n\nvars &lt;- c(\"age\", \"bmi\", \"age_c\", \"bmi_c\", \"wt_norm\", \"sex\", \"race\", \"diabetes_dx\")\n\ntable1 &lt;- CreateTableOne(vars = vars, data = adult_imp1, factorVars = c(\"sex\", \"race\", \"diabetes_dx\"))\nprint(table1, showAllLevels = TRUE)\n\n\n                     \n                      level            Overall      \n  n                                     5592        \n  age (mean (SD))                      48.84 (17.57)\n  bmi (mean (SD))                      29.00 (7.11) \n  age_c (mean (SD))                    -0.02 (1.00) \n  bmi_c (mean (SD))                    -0.01 (0.99) \n  wt_norm (mean (SD))                   1.00 (0.79) \n  sex (%)             Male              2669 (47.7) \n                      Female            2923 (52.3) \n  race (%)            NH White          2398 (42.9) \n                      Mexican American   742 (13.3) \n                      Other Hispanic     489 ( 8.7) \n                      NH Black          1141 (20.4) \n                      Other/Multi        822 (14.7) \n  diabetes_dx (%)     0                 4974 (88.9) \n                      1                  618 (11.1) \n\n\n\n\nCode\n## correlation matrix\nlibrary(ggplot2)\nlibrary(reshape2)\n\ncorrelation_matrix &lt;- cor(adult_imp1[, c(\"diabetes_dx\", \"age\", \"bmi\")], use = \"complete.obs\", method = \"pearson\")\ncorrelation_melted &lt;- melt(correlation_matrix)\n\nggplot(correlation_melted, aes(Var1, Var2, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0,\n                       limit = c(-1, 1), space = \"Lab\", name = \"Correlation\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Correlation Heatmap\", x = \"Features\", y = \"Features\")\n\n\n\n\n\n\n\n\n\n\n\nVisualization of imputed dataset\nPairwise correlations - A heatmap visualizing variables: diabetes_dx, age, and bmi show the strength and direction of correlations (Pearson correlation) which measures linear association between variables.\n\n\nCode\n# Class distribution\n\nggplot(adult_imp1, aes(x = factor(diabetes_dx))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(\n    title = \"Diabetes Diagnosis Distribution\",\n    x = \"Diabetes Diagnosis (0 = No, 1 = Yes)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nprop.table(table(adult_imp1$diabetes_dx))\n\n\n\n       0        1 \n0.889485 0.110515 \n\n\nCode\n# Visualization of Diabetes vs BMI (adult_data1)\n\nlibrary(ggplot2)\n\n# Create the plot\nggplot(adult_imp1, aes(x = factor(diabetes_dx), y = bmi, fill = factor(diabetes_dx))) +\n  geom_boxplot(alpha = 0.7) +\n  scale_x_discrete(labels = c(\"0\" = \"No Diabetes\", \"1\" = \"Diabetes\")) +\n  labs(\n    x = \"Diabetes Diagnosis\",\n    y = \"BMI\",\n    title = \"BMI Distribution by Diabetes Status\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\n# logistic regression curve\nggplot(adult_imp1, aes(x = bmi, y = diabetes_dx)) +\n  geom_point(aes(y = diabetes_dx), alpha = 0.2, position = position_jitter(height = 0.02)) +\n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = TRUE, color = \"blue\") +\n  labs(\n    x = \"BMI\",\n    y = \"Probability of Diabetes\",\n    title = \"Predicted Probability of Diabetes vs BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save your dataset as CSV\nwrite.csv(adult_imp1, \"adult_imp1.csv\", row.names = FALSE)\n\n\nBelow are the rows and column numbers from the three datasets created\n\nRows: 10175 and Columns: 10 (survey-weighted, merged data)\nRows: 5,769 and Columns: 12 (filtered data, adult)\nRows: 5,592 and Columns: 11 (imputed data, adult_imp1)\n\nData readiness for Bayesian logistic regression:\n\nSurvey weights-Normalized MEC exam weights (wt_norm) with mean 1.00 (SD 0.79)\nNo missing values remain in selected predictors or outcome.\nContinuous variables are standardized, which facilitates prior specification.\nCategorical variables are correctly re-leveled for reference categories.\nWeights are available for inclusion in the likelihood to account for survey design."
  }
]