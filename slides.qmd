---
title: "Bayesian Logistic Regression for Diabetes Risk Prediction (NHANES 2013 - 2014)"
subtitle: "Capstone Presentation"
author:
  - "**Namita Mishra**"
  - "**Autumn Wilcox**"
advisor: "Dr. Ashraf Cohen"
format:
  revealjs:
    theme: simple
    slide-number: true
    transition: slide
    css: docs/slides.css
    incremental: false
    code-fold: true
    code-summary: "Show the code"
bibliography: references.bib
execute:
  warning: false
  message: false
  echo: false
---

```{=html}
<style>
.reveal {
  font-size: 28px; /* Change all slide text */
}
.reveal h1 {
  font-size: 40px; /* Title font */
}
</style>
```

::: panel-tabset
### Aim

-   Early identification of risk factors is key to diabetes diagnosis and prevention.

-   Predict diabetes using Bayesian logistic regression.

### Frequentist Methods

-   Maximum likelihood estimation is unstable with missing data, quasi-separation, or small samples.
-   Probability is interpreted as long-run relative frequency.
-   Parameter is an unknown constant.

### Bayesian Approach

-   We model uncertainty with a probability distribution ![](images/clipboard-2228883614.png){width="37" height="20"}, called the prior distribution.
-   Probability represents a degree of belief.
-   It represents the statisticians belief about before observing the data.
-   Parameter is not known but is considered random variable

**Benefits**

-   Model is flexible and regularizes estimates.
-   Quantifies uncertainty under missingness or imputation (Baldwin & Larson, 2017; Kruschke & Liddell, 2017).
-   Incorporates priors
-   Provides credible intervals via MCMC to predict patient health outcomes.
-   Supports model checking, variable selection, and uncertainty quantification
:::

------------------------------------------------------------------------

### Bayesian Model

#### Bayes‚Äô Theorm is based on conditional probability.

::: panel-tabset
### Bayesian Inference

Bayesian inference estimates the **posterior probability** of a parameter:

$$
P(\theta \mid D) = \frac{P(D \mid \theta)\, P(\theta)}{P(D)}
$$

Bayesian Inference in the Model

**In the Model**

-   **Œ∏ (Parameters):**\
    Regression coefficients (eg:age, BMI, sex, and race)

-   **D (Data):**\
    Data (eg:NHANES) with the observed disease status (eg: diabetes) and covariates

------------------------------------------------------------------------

### Baye's Interpretation

-   **Prior P(Œ∏):**\
    Prior beliefs about effect sizes before seeing data\
    (weakly informative priors centered around ‚Äúno effect‚Äù).

-   **Likelihood P(D**\\Œ∏):\
    Probability of the observed disease outcomes *given* the parameter values\
    (logistic regression model).

-   **Marginal Likelihood P(D):**\
    Normalizing constant ensuring the posterior is a valid probability distribution

-   **Posterior P(Œ∏/D):**\
    Updated probability distribution for predictor effects (eg: age, BMI, sex, and race) *after observing the data* ‚Äî This is **brms** model estimates

    ![](images/clipboard-3708975756.png){width="250"}
:::

------------------------------------------------------------------------

### Bayesian Regression and Coefficient Estimation

::: panel-tabset
#### Logistic Link Function

-   Logistic link function used for binary outcomes.
-   logit (ùëÉ(ùëå=1))= (intercept) + ùõΩage_ùëê + ùõΩbmi_ùëê + ùõΩsex + ùõΩrace

Logistic link transforms the linear predictor into a probability between (0 and 1)

**Eg: log odds = 0.69**

![](images/clipboard-431380092.png)

![](images/clipboard-1636913343.png)

-   Converts changes in predictors into changes in **log-odds** of the outcome.
-   In Model: links age, BMI, sex, and race to the probability of having diabetes.

#### Prior

**Intercept prior: student_t(3, 0, 10)** ‚Äî (Van de Schoot et al., 2013)\
- **df = 3 (degrees of freedom):** **heavy tails**- allow for occasional extreme values.\
- **location = 0:** Centered at 0, so the prior expects the parameter to be near 0\
- **scale = 10:** Controls spread out the distribution (Larger scale ‚Üí wider spread).\
**Prior for Regression coefficient : normal(0, 2.5)** (Van de Schoot et al., 2021)\
- weakly informative with **Mean = 0, Standard deviation = 2.5**\
- probability of very large or very small parameter values is very low and **stabilizes the model**

![](images/clipboard-3802967430.png){width="313"}
:::

------------------------------------------------------------------------

### Data Source

::: panel-tabset
### Data

**National Health and Nutrition Examination Survey (NHANES) 2013‚Äì2014**\
**Design:** Complex multistage probability sampling; survey weights applied

**Response Variable (diabetes_dx : binary)**

-   Based on **DIQ010**: ‚ÄúHas a doctor told you that you have diabetes?‚Äù

-   Excluded **DIQ050 (insulin use)** to avoid clinical confounding.

**Predictor Variables**

-   **RIDAGEYR ‚Äî Age (continuous)** - adults 20‚Äì80 years (per 1 SD)

-   **BMXBMI ‚Äî Body Mass Index (continuous)** 1 SD increase

-   **RIAGENDR ‚Äî Sex (factor)**

-   **RIDRETH1 ‚Äî Race/Ethnicity (factor)**\

    -   *Mexican American*, *Other Hispanic*, *Non-Hispanic White*, *Non-Hispanic Black*, *Other/Multi-racial*

### Data view

![](images/clipboard-4180967765.png){width="604"}
:::

------------------------------------------------------------------------

### Missing Data Analysis {.panel-tabset}

::: panel-tabset
### Plot

![](images/clipboard-2873800077.png){width="427"}

### Abnormalities

-   Missing Data Assessment - Overall missingness ‚âà 4%
-   No variable is completely missing
-   Missingness likely MAR (Missing At Random)
-   Clustered mainly in BMI (4.3%) and diabetes_dx (3.1%).

### Complete Case Analysis

#### Survey-Weighted Diabetes Risk (U.S. Adults)

**diabetes_dx‚àºage_c + bmi_c + sex + race**

Interpretation

-   Model was estimated using svyglm(),**quasibinomial family** for binary outcome for NHANES design.
-   Design-adjusted coefficient estimates, standard errors, and odds ratios reflect population-representative associations for U.S. adults.
-   Complete case analysis (n= 5348)
-   Age (per 1 SD ‚Üë): OR ‚âà 3.03 ‚ÜíOlder adults \~3√ó higher odds
-   BMI (per 1 SD ‚Üë): OR ‚âà 1.88 ‚Üí Higher BMI increases risk
-   Sex (Female vs Male): OR ‚âà 0.53 ‚Üí Females \~47% lower odds
-   Race (vs NH White): - Mexican American: OR ‚âà 2.04
-   Other Hispanic: OR ‚âà 1.59 - NH Black: OR ‚âà 1.67
-   Other/Multi-racial: OR ‚âà 2.33

Age and BMI are strongest predictors Females have lower risk Certain racial/ethnic groups have higher odds

### Code

``` r
form_cc <- diabetes_dx ~ age_c + bmi_c + sex + race
svy_fit <- survey::svyglm(formula = form_cc, design = des_cc, family = quasibinomial())
```
:::

------------------------------------------------------------------------

### Bayesian Logistic Regression

::: panel-tabset
### Data (Adults)

-   Raw imported: **10175 obs**\
-   Survey-weighted (Filtered = Adult): **5,769 (\~7%)**\
-   Complete Case Analysis: **5348** (with no missing values)\
-   Imputed dataset (adult_imp1): **5,592**\

**Bayesian models assume complete data.**

### MICE

**Multivariate Imputation by Chained Equation**\
*van Buuren & Groothuis-Oudshoorn, 2011; van Buuren, 2012*\
- Iteratively imputes incomplete variables using regression models.\
- MICE run 5 iterations for each of the 5 imputed datasets to ensure stability and convergence and provides multiple realistic versions of missing data\
- Use PMM method for continuous (*Predictive Mean Matching)* to fill missing values with the observed values ‚Äúclosest‚Äù to predicted values)\
- Use logistic regression for binary variables.\
- Rubin‚Äôs rule finds pooled Estimates from across posterior distributions to yield full posterior\
**Posterior (parameters + missing data uncertainty)**

### Bayesian Logistic Regression Model

Model is fitted to each imputed dataset in **R** using brms **(Stan backend)**, 2000 itirations\

**Formula**\

diabetes_dx \| weights(wt_norm) \~ age_c + bmi_c + sex + race\

**Prior**

-   **normal(0, 2.5)** for coefficients
-   **student_t(3, 0, 10)** for Intercept

**Data set**: Pooled Imputed dataset-1\
**Bernoulli family**\
**Chains = 4, Iteration = 2000, seed = 123**

### Code

``` r
library(gt)
priors <- c(
  set_prior("normal(0, 2.5)", class = "b"),
  set_prior("student_t(3, 0, 10)", class = "Intercept")
)

bayes_fit <- brm(
  formula = diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race,
  data    = adult_imp1,
  family  = bernoulli(link = "logit"),
  prior   = priors,
  chains  = 4, iter = 2000, seed = 123,
  control = list(adapt_delta = 0.95),
  refresh = 0
)
```

### Result
**warmup= 1000**\
**total draws = 4000**

![](images/clipboard-2724235725.png)
:::


------------------------------------------------------------------------

### MCMC (Markov Chain Monte Carlo)

::: panel-tabset
### Markov Process

-   Gibbs sampler produces a sequence of random vectors ![](images/clipboard-1640325740.png){width="90" height="35"}

-   Each sample depends on the past only through the most recent one.

-   The samples are not just random but are drawn in a way that the long-term distribution of the samples matches the target posterior distribution.

-   It uses a burn in period.

-   The random vectors are sequentially dependent. Retain one parameter vector every n iterations, and discard the rest.

    ![](images/clipboard-1907802712.png)

### Code

``` r
post <- posterior_summary(bayes_fit, robust = FALSE) %>%  as_tibble(rownames = "term")
# Extract convergence diagnostics
diag <- rstan::monitor(as.array(bayes_fit$fit), print = FALSE) %>%
  as_tibble(rownames = "term") %>%
  select(term, Rhat, n_eff = Bulk_ESS)

bayes_results <- post %>%  left_join(diag, by = "term") %>%  mutate(
    OR       = exp(Estimate),
    OR_LCL   = exp(Q2.5),
    OR_UCL   = exp(Q97.5)
  ) %>%  select(term,    Estimate,Est.Error,Q2.5, Q97.5,Rhat, n_eff, OR,  OR_LCL,  OR_UCL )
```

:::

------------------------------------------------------------------------

### Model Diagnostics (**MCMC Convergence**)

R-hat ‚âà 1 ‚Üí good chain mixing\
Effective sample size\
Trace Autocorrelation plots: for convergence (no drift across iterations). Well-mixed chains without trends show convergence and stable posterior estimates.

::: panel-tabset
### Trace Plots

-   precise estimates with high uncertainty narrow distributions,
-   smooth and unimodal ‚Üí no multimodality confirming stable posteriors.
-   histogram is the distribution of sampled coefficient values after convergence across all MCMC draws

![](images/clipboard-3030610644.png){width="344"}

### Autocorrelation Plot

![](images/clipboard-2853565372.png){width="313"}\
Assess chain mixing, convergence, and correlation of each draw with its lagged values across iterations

**Sampling shows**: Well mixing, draws are relatively independent, adequate, and stable, valid inference\
- Rapid decay of autocorrelation toward zero\
- Age and BMI coefficients exhibited low autocorrelation\
- Does not show relationships between parameters
:::

------------------------------------------------------------------------

### Posterior Draws

Posterior draws = 4000 (4 chains √ó 1000 iterations) for posterior predictive checks

-   The distribution of predictors after seeing the data.
-   The posterior is the conditional distribution of the parameter given the data
-   Subjectivity is present when it is based on the prior distribution which influences the conclusions.
-   The influence of the prior goes to zero as the sample size increases.

------------------------------------------------------------------------

### Posterior Results

::: panel-tabset
### Posterior Estimates

![](images/clipboard-1727290712.png)

### Posterior Distribution

![](images/clipboard-2417602744.png)

### Interpretation

**Posterior Coefficients**

Age (per 1 SD): strong positive effect (‚âà +1.1, 80% CrI ‚âà 0.9‚Äì1.3).

BMI (per 1 SD): positive association (‚âà +0.6, 80% CrI ‚âà 0.45‚Äì0.75).

**Female: slightly protective (‚âà ‚Äì0.2, CrI spans slightly below zero).**

Mexican American: small positive effect (‚âà +0.25, wide CrI).

Other Hispanic: moderate positive effect (‚âà +0.35, wide CrI).

Non-Hispanic Black: clear positive effect (‚âà +0.75, CrI ‚âà 0.6‚Äì0.9).

Other/Multi: small positive effect (‚âà +0.3, wide CrI).
:::

------------------------------------------------------------------------

### Model Diagnostics

#### Prior and Posterior Predictive Distribution (age and BMI)

::: panel-tabset
### Plot

Prior vs Posterior Distributions ![](images/clipboard-1978292710.png){width="466"}

### Interpretation

-   Strong positive relationship between age, BMI, and diabetes probability.

-   **Posterior predictive checks** confirm good model fit.

-   Imputation reduced bias and improved robustness.

### Code

``` r
library(ggplot2)

ggplot(combined_draws, aes(x = estimate, fill = type)) +
  geom_density(alpha = 0.4) +
  facet_wrap(~ term, scales = "free", ncol = 2) +
  theme_minimal(base_size = 13) +
  labs(
    title = "Prior vs Posterior Distributions",
    x = "Coefficient estimate",
    y = "Density",
    fill = ""
  )
```
:::

------------------------------------------------------------------------

### Model Diagnostics

#### Posterior Predictive Checks

500 draws: predicted outcomes for each observation compare ( observed data vs predeicted outcomes: binary outcome with 0 or 1 simulated

::: panel-tabset
### Code

``` r
pp_samples \<- posterior_predict(bayes_fit, ndraws = 500) 
# 500 draws 

# Check dimensions dim(pp_samples) \# rows = draws, cols = observations ppc_bars(y = adult_imp1\$diabetes_dx, yrep = pp_samples\[1:500, \]) 
```

### Compare outcome

Predicted vs observed outcome ![](images/clipboard-2418526955.png){width="274"}

### Proportion

![](images/clipboard-122565288.png){width="273"}

### Mean

![](images/clipboard-2726352750.png){width="340"}

### SD

![](images/clipboard-1023519991.png){width="331"}
:::

------------------------------------------------------------------------

### Model Diagnostics

#### Diabetes Prevalence (Survey weighted NHANES vs Predicted)

::: panel-tabset
### Result and Visualization

![](images/clipboard-4013951629.png){width="576"}\| ![](images/clipboard-3433503019.png){width="466"}

### Interpretation

**Prevalence of diabetes** (Posterior-predicted vs NHANES survey-weighted)

-   NHANES survey-weighted estimate (8.9%, SE = 0.0048).
-   The predicted posterior mean was 10.95%, with a 95% credible interval of 8.5%‚Äì12.8%.
-   Although the model predicts slightly higher prevalence, the credible interval overlaps the NHANES estimate.

**Model is well-calibrated, with NHANES falling near the lower end of the posterior distribution but still within a plausible range**
:::

------------------------------------------------------------------------

### Model Diagnostics

#### Observed vs. Predicted Average diabetes outcome across individuals

::: panel-tabset
### Plot

![](images/clipboard-2608056459.png){width="287"}

-   Each point = one observation (an individual)
-   **x-axis = observed value** (`0` or `1` in your binary diabetes variable)
-   **y-axis = average predicted posterior probability** for that same individual across simulated datasets
-   Points near (0, 0) or (1, 1) ‚Üí good prediction

### Plot

![](images/clipboard-2167517988.png){width="340"}

-   Each point represents an individual‚Äôs observed BMI versus the model‚Äôs predicted mean.
-   Error bars indicate the 95% credible intervals of the predictions.
-   The plot demonstrates that the model‚Äôs predictions generally align with the observed data

### Code

``` r
# PP checks with bayesplot options
color_scheme_set("blue")
ppc_scatter_avg(y = adult_imp1$diabetes_dx, yrep = pp_samples[1:100, ]) +
labs(title = "Observed vs Predicted (Avg) Posterior Predictive at individual level")
```
:::

------------------------------------------------------------------------

### Model Diagnostics

#### Model Comparison Across methods

(1) **Survey-weighted maximum likelihood estimation (MLE)**
(2) **Bayesian regression**

``` r
svy_tbl   <- svy_or   %>% mutate(Model = "Survey-weighted MLE")
bayes_tbl <- bayes_or %>% mutate(Model = "Bayesian")
```

![](images/clipboard-329828759.png){width="363"}

-   **Age and BMI: strong risk factors in both models for diabetes predictors**.
-   The Bayesian model complements frequentist approaches by providing stable, interpretable, and uncertainty-quantified estimates, while broadly reproducing population-level prevalence.
-   The Bayesian model used normalized weights, which approximates the effect of survey weights but does not fully account for stratification, clustering, or design-based variance adjustments.

------------------------------------------------------------------------

### Model Diagnostics

::: panel-tabset
### Plot pairwise correlation

![](images/clipboard-1737198687.png){width="521"}

### Code

``` r
# Extract posterior draws
post <- as_draws_df(bayes_fit)
# Select numeric parameters of interest
post_subset <- post %>% 
  dplyr::select(b_age_c, b_bmi_c, b_sexFemale, 
                b_raceMexicanAmerican, b_raceNHBlack)
# Compute correlation matrix
cor_matrix <- cor(post_subset)
# Visualize
mcmc_pairs(as_draws_array(bayes_fit), 
           pars = c("b_age_c", "b_bmi_c", "b_sexFemale"),
           off_diag_args = list(size = 1.5, alpha = 0.4))
```

### Interpretation

-   The absence of strong linear relationships between age, BMI, and sex
-   Independently contribute to the prediction of diabetes status.
-   The smooth, unimodal histograms along the diagonals confirmed stable model convergence and well-behaved posterior samples.
-   A mild negative tilt between b_age_c and b_sexFemale: a slight negative correlation:
-   As the posterior estimate for age increases, the effect of being female slightly decreases.

**Weak correlation: confirms both predictors contribute distinct information to the diabetes outcome**.
:::

------------------------------------------------------------------------

### Model Diagnostics

#### Predicted Diabetes Prevalence vs. NHANES Prevalence

::: panel-tabset
### Plot

![](images/clipboard-2142249375.png){width="329"}

### Interpretation

-   We compared the Bayesian posterior-predicted diabetes prevalence with the NHANES survey-weighted estimate (8.9%, SE = 0.0048).
-   The model‚Äôs posterior mean was 10.95%, with a 95% credible interval of 8.5%‚Äì12.8%. Although the model predicts slightly higher prevalence, the credible interval overlaps the NHANES estimate.
-   This indicates that the model is reasonably well-calibrated, with NHANES falling near the lower end of the posterior distribution but still within a plausible range.

### Code

``` r
# pp_proportion <- rowMeans(pp_samples)  # if not already done
known_prev <- 0.089   # NHANES prevalence
posterior_mean <- mean(pp_proportion)
posterior_ci <- quantile(pp_proportion, c(0.025, 0.975))  # 95% credible interval
pp_df <- tibble(proportion = pp_proportion)
ggplot(pp_df, aes(x = proportion)) +
  geom_histogram(binwidth = 0.005, fill = "skyblue", color = "black") +
  geom_vline(xintercept = known_prev, color = "red", linetype = "dashed", size = 1) +
  geom_vline(xintercept = posterior_mean, color = "blue", linetype = "solid", size = 1) +
  labs(
    title = "Posterior Predicted Diabetes Proportion vs NHANES Prevalence",
    subtitle = paste0("Red dashed = NHANES prevalence (", known_prev, 
                      "), Blue solid = Posterior mean (", round(posterior_mean,3), ")"),
    x = "Proportion of Diabetes = 1",
    y = "Frequency"
  ) +
  theme_minimal()
```
:::

------------------------------------------------------------------------

### Model Diagnostics

#### R Square

``` r
Model fit: bayes_R2(bayes_fit)
```

![](images/clipboard-2402173436.png)

Interpretation

-   Explains about 13% of the variability in diabetes status, with credible uncertainty bounds suggesting reasonable but modest explanatory power.
-   but other factors (e.g., genetics, lifestyle, environment) also contribute to outcome variability.

------------------------------------------------------------------------

### Assumptions for Bayesian Logistic Regression

-   Data Binary outcome
-   Independent observations
-   Relationship Linear in logit
-   No perfect collinearity
-   Priors Properly chosen: informative enough
-   Posterior Proper and convergent Fit
-   No complete separation
-   Good predictive checks

------------------------------------------------------------------------

### Translational Perspective

::: panel-tabset
### Validation

#### Personalized Risk Estimation

-   Model enables individualized diabetes risk prediction using age, BMI, sex, race and outputs can guide actionable thresholds (e.g., risk \>30%)
-   BMI is modifiable- interventions can lower risk while sex and race remain constant.
-   Selected one participant (adult\[1, \]) with all covariates (age, BMI, sex, race) obtain predicted probabilities from the logistic regression model. **posterior_linpred(transform = TRUE)**
-   Posterior draws: calculate the 95% credible interval for the predicted probability

### Code

``` r
participant1_data  <- adult[1, ]
phat1 <- posterior_linpred(bayes_fit, newdata = participant1_data, transform = TRUE)
post_pred_df <- data.frame(pred = phat1)
ci_95_participant1 <- quantile(phat1, c(0.025, 0.975))

ggplot(post_pred_df, aes(x = pred)) + 
  geom_density(color='darkblue', fill='lightblue') +
  geom_vline(xintercept = ci_95_participant1[1], color='red', linetype='dashed') +
  geom_vline(xintercept = ci_95_participant1[2], color='red', linetype='dashed') +
  xlab('Probability of being diabetic (Outcome=1)') +
  ggtitle('Posterior Predictive Distribution 95% Credible Interval') +
  theme_bw()
```

### Internal Validation

![](images/clipboard-2754134965.png){width="196"}\
Posterior Predictive for Individual (Outcome = 1): Median predicted probability ‚âà 0.25, with a 95% credible interval of 0.20‚Äì0.31, indicating a \~1 in 4 chance of diabetes.

### External Validation

![](images/clipboard-2142022257.png){width="166"}\
Using the Bayesian model, we computed the posterior predicted probability for a new participant based on age, BMI, sex, and race. The density plot with 95% credible intervals captures both the most likely risk and uncertainty, supporting individualized preventive care.\

X-axis: Predicted probability of diabetes (Outcome = 1)\
Y-axis: Density of predicted probabilities\
Blue curve: Posterior predictive distribution for this individual\
Shaded area: High probability values near 1, indicating high diabetes risk\
Red dashed line: Upper bound of 95% credible interval\
Peak: Most likely predicted probability ‚âà 1
:::

------------------------------------------------------------------------

### Reverse Prediction

**Targeted BMI Estimation for Predicted Diabetes Risk**

::: panel-tabset
### Plot

![](images/clipboard-3125514674.png)

### Interpretation

X-axis: BMI values (centered or raw, depending on the model).\
Y-axis: Predicted probability of diabetes for a representative individual (Age = 40, Female, Mexican American).\
Blue curve: predicted probability of diabetes across the BMI range; consistently high (‚âà1) for most BMI values.\
Red horizontal line: Target probability of diabetes = 0.3.\
Red vertical line is the targeted BMI: when the predicted probability of diabetes is closest to the target bmi probability (‚âà18).\

### Code

``` r
bmi_seq <- seq(18, 40, by = 0.5)

newdata_grid <- data.frame(
  age_c = 40,
  bmi_c = bmi_seq,
  sex   = "Female",
  race  = "Mexican American"
)
```

### Practical Implications

**This is the inverse prediction‚Äîthe BMI needed to reach a 30% diabetes risk**.\

For this demographic profile, even a relatively low BMI (\~18) is associated with a 30% diabetes risk\
Indicating that other factors (age, sex, race) and the model‚Äôs coefficients contribute strongly to predicted diabetes risk.
:::

------------------------------------------------------------------------

### Limitations

-   **Cross-sectional** NHANES design limits causal inference.

-   Multiple **imputation** assumes MAR; MNAR may bias results.

-   Residual **confounding** from unmeasured factors (diet, activity, SES, genetics).

-   Bayesian estimates may be influenced by **prior choices**.

-   **BMI measured once**; may not capture long-term exposure.

-   **Self-reported** variables may introduce recall/reporting bias.

-   **Interaction effects** (e.g., age √ó BMI) not tested. :::

------------------------------------------------------------------------

### Conclusion

Bayesian logistic regression effectively models uncertainty.

MICE improved data completeness and reliability.

Posterior predictions provide interpretable probabilities of diabetes risk.

Framework adaptable to other outcomes (e.g., hypertension, obesity).

------------------------------------------------------------------------

### References

van Buuren, S. & Groothuis-Oudshoorn, K. (2011). MICE: Multivariate Imputation by Chained Equations in R.

Gelman, A. & Hill, J. (2007). Data Analysis Using Regression and Multilevel/Hierarchical Models.

McElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan.

NHANES Data Documentation (CDC).

Van de Schoot, R. et al. (2013, 2021). Weakly Informative Priors in Bayesian Regression.

------------------------------------------------------------------------

### **Thank You**

**Dr. Ashraf Cohen, PhD, MS**

-   University of West Florida
-   Department of Mathematics and Statistics

------------------------------------------------------------------------
