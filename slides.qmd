---
title: "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013â€“2014)"
subtitle: "Capstone Presentation"
author:
  - "Namita Mishra"
  - "Autumn Wilcox"
advisor: "Dr. Ashraf Cohen"
format:
  revealjs:
    theme: simple
    slide-number: true
    transition: slide
    css: docs/slides.css
    incremental: true
    code-fold: true
    code-summary: "Show the code"
bibliography: references.bib
execute:
  warning: false
  message: false
  echo: false
---

```{=html}
<style>
.reveal {
  font-size: 34px; /* Change all slide text */
}
.reveal h1 {
  font-size: 48px; /* Title font */
}
</style>
```

### Aim

-   Early identification of risk factors is key to diabetes diagnosis and prevention.

-   Predict diabetes using Bayesian logistic regression.

### Frequentist Methods

-   Maximum likelihood estimation is unstable with missing data, quasi-separation, or small samples.

-   Probability is interpreted as long-run relative frequency.

------------------------------------------------------------------------

### Bayesian Approach

-   Flexible and regularizes estimates.

-   Quantifies uncertainty under missingness or imputation (Baldwin & Larson, 2017; Kruschke & Liddell, 2017).

-   Incorporates priors and provides credible intervals via MCMC to predict patient health outcomes.

-   Supports model checking, variable selection, and uncertainty quantification.

-   Probability represents a degree of belief.

------------------------------------------------------------------------

### Bayesian Model

::: panel-tabset
### Bayesâ€™ theorem

**Bayesâ€™ theorem** is based on conditional probability.

Coefficients estimated using posterior means and 95% credible intervals.

Logistic link function used for binary outcomes.

### Bayesian Logistic Regression

logit (ğ‘ƒ(ğ‘Œ=1))=ğ›½0+ğ›½1age ğ‘ + ğ›½ 2 bmi ğ‘ + ğ›½ 3 sex + ğ›½ 4 race

Intercept prior: student_t(3, 0, 10) â€” heavy tails for flexibility (Van de Schoot et al., 2013).

Regression coefficients prior: normal(0, 2.5) â€” weakly informative, constraining extreme values (Van de Schoot et al., 2021).
:::

------------------------------------------------------------------------

**Bayesian Logistic Regression**

In **R** using brms **(Stan backend)**

Posterior draws = 4000 (4 chains Ã— 1000 iterations).

``` r
library(gt)
priors <- c(
  set_prior("normal(0, 2.5)", class = "b"),
  set_prior("student_t(3, 0, 10)", class = "Intercept")
)

bayes_fit <- brm(
  formula = diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race,
  data    = adult_imp1,
  family  = bernoulli(link = "logit"),
  prior   = priors,
  chains  = 4, iter = 2000, seed = 123,
  control = list(adapt_delta = 0.95),
  refresh = 0
)
```

------------------------------------------------------------------------

### Data Source

### **NHANES 2013â€“2014 (Survey weighted)**

::::::: panel-tabset
### Exploratory data analysis

Response Variable: diabetes_dx (binary) : Type 2 diabetes diagnosis DIQ010 (â€œDoctor told you have diabetesâ€), excluding DIQ050 (insulin use) to prevent confounding.

Predictor Variables:BMXBMI â€“ Body Mass Index (kg/m\^2): continuous with six levels (bmi_cat). RIDAGEYR: Age (continuous, 20â€“80 years) RIAGENDR: Sex (factor, two levels) RIDRETH1 â€“ Ethnicity (factor, five levels)

![](images/clipboard-3274096863.png){width="795"}

------------------------------------------------------------------------

### Missing data analysis {.panel-tabset}

:::::: columns
::: column
Plot

![](images/clipboard-2873800077.png){width="427"}
:::

:::: column
::: nonincremental
Abnormalities:

-   Missing Data Assessment - Overall missingness â‰ˆ 4%
-   No variable is completely missing
-   Missingness likely MAR (Missing At Random)
-   Clustered mainly in BMI (4.3%) and diabetes_dx (3.1%).
:::
::::
::::::
:::::::

------------------------------------------------------------------------

### Multiple Imputation by Chained Equations (MICE)

::: nonincremental
Handling Missing Data *(van Buuren & Groothuis-Oudshoorn, 2011; van Buuren, 2012*)

**Fit logistic regression model**

MICE performed on imputed datasets and pool estimates:

``` r
fit_mi <- with(data = imp, exp = glm(diabetes_dx ~ age_c + bmi_c + sex + race, family = binomial()))
pool_mi <- pool(fit_mi)
```

-   Iteratively imputes incomplete variables using regression models.
-   PMM for continuous; logistic regression for binary variables.
-   5 imputations Ã— 10 iterations ensure stability and convergence.
-   Estimates pooled using Rubinâ€™s rules.
:::

------------------------------------------------------------------------

### Bayesian Model Diagnostics

:::: panel-tabset
### MCMC

-   Trace plots indicate convergence (no drift across iterations).
-   Rhat â‰ˆ 1 â†’ good chain mixing.
-   Effective sample size is adequate across parameters.

### Posterior Estimates

::: nonincremental
-   Intercept -2.66 \[-2.84, -2.50\] Baseline log-odds
-   Age_c 1.09 \[0.97, 1.22\] â†‘ Age increases diabetes risk
-   BMI_c 0.88 \[0.76, 1.01\] Higher BMI predicts diabetes
-   All predictors show positive associations.
-   Narrow credible intervals â†’ precise estimates (Predictor Estimate 95% CI )
-   CIs exclude zero â†’ statistically significant effects.
:::
::::

------------------------------------------------------------------------

### Posterior Predictive Distribution

::::: panel-tabset
### code

``` r
library(ggplot2)

ggplot(combined_draws, aes(x = estimate, fill = type)) +
  geom_density(alpha = 0.4) +
  facet_wrap(~ term, scales = "free", ncol = 2) +
  theme_minimal(base_size = 13) +
  labs(
    title = "Prior vs Posterior Distributions",
    x = "Coefficient estimate",
    y = "Density",
    fill = ""
  )
```

### Plot

![](images/clipboard-1978292710.png){width="466"}

### Interpretation

:::: nonincremental
-   Strong positive relationship between age, BMI, and diabetes probability.

-   **Posterior predictive checks** confirm good model fit.

-   Imputation reduced bias and improved robustness.

::: nonincremental
```         
Model fit: bayes_R2(bayes_fit)
```
:::

```         
        Estimate        Est.Error       Q2.5        Q97.5 
        R2 0.1313342    0.01265055    0.1064607     0.156078
```
::::
:::::

------------------------------------------------------------------------

### Assumptions for Bayesian Logistic Regression

::: nonincremental
-   Data Binary outcome
-   independent observations
-   Relationship Linear in logit
-   no perfect collinearity
-   Priors Properly chosen: informative enough
-   Posterior Proper and convergent Fit
-   No complete separation
-   good predictive checks
:::

------------------------------------------------------------------------

::: panel-tabset
### Code

Posterior pairwise correlation plot

``` r

# Extract posterior draws
post <- as_draws_df(bayes_fit)

# Select numeric parameters of interest
post_subset <- post %>% 
  dplyr::select(b_age_c, b_bmi_c, b_sexFemale, 
                b_raceMexicanAmerican, b_raceNHBlack)

# Compute correlation matrix
cor_matrix <- cor(post_subset)

# Visualize
mcmc_pairs(as_draws_array(bayes_fit), 
           pars = c("b_age_c", "b_bmi_c", "b_sexFemale"),
           off_diag_args = list(size = 1.5, alpha = 0.4))
           
```

### Plot

![](images/clipboard-1737198687.png)

### Interpretation

The absence of strong linear relationships among parameters suggests that age, BMI, and sex independently contributed to the prediction of diabetes status. The smooth, unimodal histograms along the diagonals confirmed stable model convergence and well-behaved posterior samples.
:::

------------------------------------------------------------------------

### Limitations

:::: nonincremental
::: nonincremental
-   NHANES is cross-sectional â†’ cannot infer causality

-   Role of Potential unmeasured confounding factors (diet, activity)

-   Limited predictors simplify model structure

-   Imputation assumes MAR â†’ violation may bias estimates
:::
::::

------------------------------------------------------------------------

### Conclusion

Bayesian logistic regression effectively models uncertainty.

MICE improved data completeness and reliability.

Posterior predictions provide interpretable probabilities of diabetes risk.

Framework adaptable to other outcomes (e.g., hypertension, obesity).

------------------------------------------------------------------------

### References

::: nonincremental
van Buuren, S. & Groothuis-Oudshoorn, K. (2011). MICE: Multivariate Imputation by Chained Equations in R.

-   Gelman, A. & Hill, J. (2007). Data Analysis Using Regression and Multilevel/Hierarchical Models.

-   McElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan.

-   NHANES Data Documentation (CDC).

-   Van de Schoot, R. et al. (2013, 2021). Weakly Informative Priors in Bayesian Regression.
:::

------------------------------------------------------------------------

:::: panel-tabset
### **Thank You**

### Dr. Ashraf Cohen, PhD, MS

::: nonincremental
-   University of West Florida
-   Department of Mathematics and Statistics
-   Thanks for the guidance
:::

------------------------------------------------------------------------
::::
